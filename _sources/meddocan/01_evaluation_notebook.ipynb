{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379276ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myst_nb import glue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96eecf2",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddcde44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from typing import List, Iterable, Tuple\n",
    "import base64\n",
    "import tempfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "from meddocan.evaluation.classes import BratAnnotation, EvaluateSubtrack1, EvaluateSubtrack2, EvaluateSubtrack2merged, Evaluate, Span\n",
    "\n",
    "\n",
    "base = \"https://api.github.com/repos/PlanTL-GOB-ES/MEDDOCAN-Evaluation-Script/contents\"\n",
    "# The api where the text can be reach.\n",
    "\n",
    "def get_sample(base: str, name: str) -> str:\n",
    "    # Get sample content from the folder located at https://github.com/PlanTL-GOB-ES/MEDDOCAN-Evaluation-Script/tree/master/gold/brat/sample via the Github api.\n",
    "    # Use the Stackoverflow reponse: https://stackoverflow.com/questions/38491722/reading-a-github-file-using-python-returns-html-tags\n",
    "    url = \"/\".join([base, name])\n",
    "    req = requests.get(url)\n",
    "    if req.status_code == requests.codes.ok:\n",
    "        req = req.json() # the response is JSON\n",
    "        # req is now a dict with keys: name, encoding, url, size ...\n",
    "        # and content. But it is encoded with base64.\n",
    "        content = base64.b64decode(req['content'])\n",
    "        return content.decode(\"utf-8\")\n",
    "    else:\n",
    "        print('Content was not found')\n",
    "\n",
    "@contextmanager\n",
    "def write_text_to_tempdir(seq_file_text: Iterable[Tuple[str, str]]) -> Path:\n",
    "    # Context manager that write a sequence of (filename, text content) tuple\n",
    "    # to a temporary directory and return the directory name.\n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        root = Path(tmpdirname)\n",
    "        for loc, content in seq_file_text:\n",
    "            (root / loc).write_text(content)\n",
    "        yield  Path(tmpdirname)\n",
    "\n",
    "def get_brat_annotation_from_github(file: str) -> BratAnnotation:\n",
    "    ann = Path(file).with_suffix(\".ann\")\n",
    "    txt = Path(file).with_suffix(\".txt\")\n",
    "\n",
    "    seq_file_text = ((loc.name, get_sample(base, str(loc))) for loc in [ann, txt])\n",
    "\n",
    "    with write_text_to_tempdir(seq_file_text) as dir_loc:\n",
    "        gold_annotation = BratAnnotation(dir_loc / Path(ann).name)\n",
    "        return gold_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5772fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meddocan.evaluation.classes import BratAnnotation, EvaluateSubtrack1, EvaluateSubtrack2, EvaluateSubtrack2merged, Evaluate, Span\n",
    "\n",
    "gold_annotation = get_brat_annotation_from_github(\"gold/brat/sample/S0004-06142005000700014-1.ann\")\n",
    "sys_annotation = get_brat_annotation_from_github(\"system/brat/subtrack2/sample/baseline/S0004-06142005000700014-1.ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030ac4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'freeling/sentence_splitted/S0004-06142005000700014-1.ann' not found.\n",
      "                                                                      \n",
      "Report (tmp57ygromi):\n",
      "------------------------------------------------------------\n",
      "Subtrack 1 [NER]                   Measure        Micro               \n",
      "------------------------------------------------------------\n",
      "Total (1 docs)                     Leak           NA                  \n",
      "                                   Precision      0.2941              \n",
      "                                   Recall         0.2                 \n",
      "                                   F1             0.2381              \n",
      "------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = EvaluateSubtrack1({sys_annotation.id: sys_annotation}, {gold_annotation.id: gold_annotation})\n",
    "e.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd711d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'freeling/sentence_splitted/S0004-06142005000700014-1.ann' not found.\n",
      "\n",
      "\n",
      "Report (tmp57ygromi):\n",
      "------------------------------------------------------------\n",
      "Document ID                        Measure        Micro               \n",
      "------------------------------------------------------------\n",
      "S0004-06142005000700014-1          Leak           NA                  \n",
      "                                   Precision      0.2941              \n",
      "                                   Recall         0.2                 \n",
      "                                   F1             0.2381              \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e = EvaluateSubtrack1({sys_annotation.id: sys_annotation}, {gold_annotation.id: gold_annotation})\n",
    "e.print_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d650de",
   "metadata": {},
   "source": [
    "Extraemos los distintos objetos que contienen la información a detectar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d0e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = sorted(Evaluate.get_tagset_ner(gold_annotation), key=lambda a: a.start)\n",
    "span = sorted(Evaluate.get_tagset_span(gold_annotation), key=lambda a: a.start)\n",
    "span_merged = sorted(Evaluate.get_tagset_span_merged(gold_annotation), key=lambda a: a.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d3af0",
   "metadata": {},
   "source": [
    "Podemos visualizar un ejemplo al azar para hacerse una idea de las características que se debe detectar en cada variante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5a590f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NER</th>\n",
       "      <th>SPAN</th>\n",
       "      <th>SPAN MERGED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>START</th>\n",
       "      <td>47</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>END</th>\n",
       "      <td>62</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAG</th>\n",
       "      <td>NOMBRE_SUJETO_ASISTENCIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            NER  SPAN  SPAN MERGED\n",
       "START                        47  47.0         47.0\n",
       "END                          62  62.0         62.0\n",
       "TAG    NOMBRE_SUJETO_ASISTENCIA   NaN          NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import zip_longest\n",
    "\n",
    "df = pd.DataFrame(zip_longest((ner[1][i] for i in [1,2,0]), span[1], span_merged[1]), columns=[\"NER\", \"SPAN\", \"SPAN MERGED\"], index=[\"START\", \"END\", \"TAG\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165065e",
   "metadata": {},
   "source": [
    "Para entender las diferencias, pongamos un ejemplo ilustrativo donde span y spam merged son distintos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dc45c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TAG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SPAN MERGED</th>\n",
       "      <th>1</th>\n",
       "      <td>3576</td>\n",
       "      <td>3635</td>\n",
       "      <td>'Carretera de Toledo km 12,500 28905 Getafe - Madrid (España'</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NER</th>\n",
       "      <th>1</th>\n",
       "      <td>3576</td>\n",
       "      <td>3605</td>\n",
       "      <td>'Carretera de Toledo km 12,500'</td>\n",
       "      <td>CALLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3606</td>\n",
       "      <td>3611</td>\n",
       "      <td>'28905'</td>\n",
       "      <td>TERRITORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3612</td>\n",
       "      <td>3618</td>\n",
       "      <td>'Getafe'</td>\n",
       "      <td>TERRITORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3621</td>\n",
       "      <td>3627</td>\n",
       "      <td>'Madrid'</td>\n",
       "      <td>TERRITORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3629</td>\n",
       "      <td>3635</td>\n",
       "      <td>'España'</td>\n",
       "      <td>PAIS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 START   END  \\\n",
       "Track       Num                \n",
       "SPAN MERGED 1     3576  3635   \n",
       "NER         1     3576  3605   \n",
       "            2     3606  3611   \n",
       "            3     3612  3618   \n",
       "            4     3621  3627   \n",
       "            5     3629  3635   \n",
       "\n",
       "                                                                          TEXT  \\\n",
       "Track       Num                                                                  \n",
       "SPAN MERGED 1    'Carretera de Toledo km 12,500 28905 Getafe - Madrid (España'   \n",
       "NER         1                                  'Carretera de Toledo km 12,500'   \n",
       "            2                                                          '28905'   \n",
       "            3                                                         'Getafe'   \n",
       "            4                                                         'Madrid'   \n",
       "            5                                                         'España'   \n",
       "\n",
       "                        TAG  \n",
       "Track       Num              \n",
       "SPAN MERGED 1          None  \n",
       "NER         1         CALLE  \n",
       "            2    TERRITORIO  \n",
       "            3    TERRITORIO  \n",
       "            4    TERRITORIO  \n",
       "            5          PAIS  "
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "evaluation_subtrack_comparison"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "diff = set(span_merged) - set(span)  # difference between merge span and span\n",
    "\n",
    "for i, _diff in enumerate(diff):\n",
    "\n",
    "    indexes: List[Tuple[str, int]] = []\n",
    "    span_merged_array = (_diff.start, _diff.end, f\"{gold_annotation.text[_diff.start: _diff.end]!r}\", None)\n",
    "    indexes.append((\"SPAN MERGED\", i+1))\n",
    "\n",
    "    ner_array: List[List[int]] = []  # List of ner object \"include\" in span_merged\n",
    "\n",
    "    cpt = 0\n",
    "    for _ner in ner:\n",
    "        if _ner.end <= _diff.end and _ner.start >= _diff.start:\n",
    "            cpt += 1\n",
    "            ner_array.append((_ner.start, _ner.end, f\"{gold_annotation.text[_ner.start: _ner.end]!r}\", _ner.tag))\n",
    "            indexes.append([\"NER\", cpt])\n",
    "        else:\n",
    "            cpt = 0\n",
    "\n",
    "    df_index = pd.DataFrame(indexes, columns=[\"Track\", \"Num\"])\n",
    "    df = pd.DataFrame(\n",
    "        [span_merged_array] + ner_array,\n",
    "        columns=[\"START\", \"END\", \"TEXT\", \"TAG\"],\n",
    "        index=pd.MultiIndex.from_frame(df_index)\n",
    "    )\n",
    "\n",
    "    with pd.option_context(\n",
    "        \"display.min_rows\", 50, \"display.max_rows\", 100, \\\n",
    "        \"display.max_columns\", 15, 'display.max_colwidth', 150):\n",
    "        glue(\"evaluation_subtrack_comparison\", df)\n",
    "        pass\n",
    "    print(\"\\n\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8f22f",
   "metadata": {},
   "source": [
    "Obtain the ner annotation in common between gold and sys doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d30e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ner = set(Evaluate.get_tagset_ner(sys_annotation))\n",
    "sys_ner = set(Evaluate.get_tagset_ner(gold_annotation))\n",
    "\n",
    "fp = sys_ner - gold_ner  # Annotation detected that are not in the gold standard Annotation set.\n",
    "tp = gold_ner.intersection(sys_ner)\n",
    "fn = gold_ner - sys_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62710e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29411764705882354"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = len(tp) / (len(tp) + len(fn))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd5681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0896e10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "source_map": [
   15,
   17,
   21,
   70,
   77,
   82,
   85,
   89,
   93,
   97,
   103,
   107,
   144,
   148,
   157,
   162,
   166
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}