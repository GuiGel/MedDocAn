{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dfea9a2-5b8e-48fd-967a-b884a58997dd",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "from meddocan.data import meddocan_zip, ArchiveFolder\n",
    "from meddocan.data.containers import BratAnnotations, BratFilesPair, BratSpan\n",
    "from meddocan.data.docs_iterators import GsDocs\n",
    "from meddocan.language.pipeline import meddocan_pipeline\n",
    "from meddocan.data import meddocan_url, meddocan_zip, ArchiveFolder\n",
    "from meddocan.data.docs_iterators import BratAnnotations, GsDocs\n",
    "from meddocan.data.utils import set_ents_from_brat_spans\n",
    "from meddocan.data.corpus import MEDDOCAN\n",
    "from presentation.utils import get_brat_annotation_from_github, glue_iob_label, display_script\n",
    "from meddocan.evaluation.classes import EvaluateSubtrack1, EvaluateSubtrack2, EvaluateSubtrack2merged, Evaluate, Span\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from typing import Optional\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def visualize_conll03(doc: Doc, nb_lines: Optional[int] = None):\n",
    "    assert doc._.is_meddocan_doc, f\"The doc must be a meddocan document!\"\n",
    "\n",
    "    if nb_lines is None:\n",
    "        nb_lines = 100000000000000\n",
    "\n",
    "    with TemporaryDirectory() as td:\n",
    "        pth = Path(td, \"file.txt\")\n",
    "        doc._.to_connl03(pth)\n",
    "        for i, line in enumerate(pth.read_text().split(\"\\n\")):\n",
    "            print(line)\n",
    "            if i == nb_lines:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf83e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# MEDDOCAN: Anonimización aplicada al ámbito médico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a949a-0c2e-4863-909f-363d9afc3a72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae0d6c74-ebb6-483f-aff6-94e8f677173a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* Medical Document Anonymization Track (track 9 of the <abbr title=\"Iberian Languages Evaluation Forum 2019\"> [IberLEF 2019](http://ceur-ws.org/Vol-2421/)).</abbr>.\n",
    "\n",
    "    Detectar automáticamente la información sanitaria protegida (PHI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4d75e-7c63-4cb2-b09a-8e1ddf95bb7b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* ¿Como?\n",
    "\n",
    "    Name Entity Recognition con métodos de **Transfer Learning** basados en los **Transformers**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04d87f-5fef-4f02-9576-db32356f87d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00ff69-fda8-4c4e-8c5a-196e9db66683",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Visualización de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcb590d-cb12-4899-b812-3923041075a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![Figure 1: An example of MEDDOCAN annotation visualized using the BRAT annotation interface.](https://temu.bsc.es/meddocan/wp-content/uploads/2019/03/image-1-1024x922.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab097cf6",
   "metadata": {},
   "source": [
    "- Los datos son anotados con la herramienta **brat** y son almacenados al **formato standoff**. \n",
    "- Las anotaciones se almacenan separadas del texto del documento anotado.\n",
    "- A cada documento de texto del sistema le corresponde un fichero de anotaciones. Ambos están asociados por la convención de que su nombre base (nombre de fichero sin sufijo) es el mismo: por ejemplo, el fichero DOC-1000.ann contiene anotaciones para el fichero DOC-1000.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd88820-eeeb-4489-a84f-31bb1da73796",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Numero de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f7817-21de-4a75-b61d-c2e454f466bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "| corpus | Train | Dev | Test |\n",
    "| ------ | ----- | --- | ---- |\n",
    "| Qt     | 500   | 250 | 250  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933058bb-a60c-4616-bb48-268ff621a059",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Distribución del tipo de entidad entre los juegos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e960ec-8db5-43c5-9b0c-87241840525d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "|               Tipo               | Train | Dev | Test | Total |\n",
    "| :------------------------------: | :---: | :-: | :--: | :---: |\n",
    "|            TERRITORIO            | 1875  | 987 | 956  | 3818  |\n",
    "|              FECHAS              | 1231  | 724 | 611  | 2566  |\n",
    "|      EDAD SUJETO ASISTENCIA      | 1035  | 521 | 518  | 2074  |\n",
    "|     NOMBRE SUJETO ASISTENCIA     | 1009  | 503 | 502  | 2014  |\n",
    "|    NOMBRE PERSONAL SANITARIO     | 1000  | 497 | 501  | 1998  |\n",
    "|      SEXO SUJETO ASISTENCIA      |  925  | 455 | 461  | 1841  |\n",
    "|              CALLE               |  862  | 434 | 413  | 1709  |\n",
    "|               PAIS               |  713  | 347 | 363  | 1423  |\n",
    "|       ID SUJETO ASISTENCIA       |  567  | 292 | 283  | 1142  |\n",
    "|        CORREO ELECTRONICO        |  469  | 241 | 249  |  959  |\n",
    "| ID TITULACION PERSONAL SANITARIO |  471  | 226 | 234  |  931  |\n",
    "|         ID ASEGURAMIENTO         |  391  | 194 | 198  |  783  |\n",
    "|             HOSPITAL             |  255  | 140 | 130  |  525  |\n",
    "|   FAMILIARES SUJETO ASISTENCIA   |  243  | 92  |  81  |  416  |\n",
    "|           INSTITUCION            |  98   | 72  |  67  |  237  |\n",
    "|     ID CONTACTO ASISTENCIAL      |  77   | 32  |  39  |  148  |\n",
    "|         NUMERO TELEFONO          |  58   | 25  |  26  |  109  |\n",
    "|            PROFESION             |  24   |  4  |  9   |  37   |\n",
    "|            NUMERO FAX            |  15   |  6  |  7   |  28   |\n",
    "|     OTROS SUJETO ASISTENCIA      |   9   |  6  |  7   |  22   |\n",
    "|           CENTRO SALUD           |   6   |  2  |  6   |  14   |\n",
    "|   ID EMPLEO PERSONAL SANITARIO   |   0   |  1  |  0   |   1   |\n",
    "| IDENTIF VEHICULOS NRSERIE PLACAS |   0   |  0  |  0   |   0   |\n",
    "|   IDENTIF DISPOSITIVOS NRSERIE   |   0   |  0  |  0   |   0   |\n",
    "|     NUMERO BENEF PLAN SALUD      |   0   |  0  |  0   |   0   |\n",
    "|             URL WEB              |   0   |  0  |  0   |   0   |\n",
    "|       DIREC PROT INTERNET        |   0   |  0  |  0   |   0   |\n",
    "|        IDENTF BIOMETRICOS        |   0   |  0  |  0   |   0   |\n",
    "|       OTRO NUMERO IDENTIF        |   0   |  0  |  0   |   0   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b8a39-2d59-4007-b772-5641cf15bee2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a66d7d-0520-4c74-b546-fec00aa785e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El paquete ``meddocan.data`` proporciona clases y funciones para tratar con los conjuntos de datos originales de\n",
    "meddocan en la web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9624-ce45-43f7-a714-56707a04647c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- `meddocan.data.meddocan_url` contiene el enlace url para llegar a las carpetas de datos comprimidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28fbd97-e635-475e-8f57-d5617521f488",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeddocanUrl(sample='http://temu.bsc.es/meddocan/wp-content/uploads/2019/03/sample-set.zip', train='http://temu.bsc.es/meddocan/wp-content/uploads/2019/03/train-set.zip', dev='http://temu.bsc.es/meddocan/wp-content/uploads/2019/04/dev-set-1.zip', test='http://temu.bsc.es/meddocan/wp-content/uploads/2019/05/test-set.zip', background='http://temu.bsc.es/meddocan/wp-content/uploads/2019/10/background-set.zip', base='http://temu.bsc.es/meddocan/wp-content/uploads/2019')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meddocan_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ecdd9-3507-4159-a9b5-03d5e0ddfb02",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* `meddocan.data.meddocan_zip` obtiene el par de archivos brat para\n",
    "una carpeta determinada del conjunto de datos en caché a través de su método ``brat_files``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f594e89b-31b4-444d-b5de-8aed56e1e7cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brat_files_pairs = meddocan_zip.brat_files(ArchiveFolder.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba6a040-6838-413f-b108-57fa99d0ec1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brat_files_pair = next(brat_files_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4f3fea-5455-4de7-9eeb-49fd8501abff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/wave/.meddocan/datasets/meddocan/train-set.zip', 'train/brat/S0004-06142005000500011-1.txt')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brat_files_pair.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd7ed04-8fae-4b2e-83a5-88c93a678263",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/wave/.meddocan/datasets/meddocan/train-set.zip', 'train/brat/S0004-06142005000500011-1.ann')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brat_files_pair.ann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e0146-e2c3-4344-a548-9f5a55bbd784",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Visualizamos los datos brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22c7f69-9166-4bec-afce-029650074cae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brat_annotations = BratAnnotations.from_brat_files(brat_files_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d25a00-1abb-43ad-9a44-aa2c911d874c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "- El texto\n",
    "\n",
    "> :pencil: Vamos a coger este texto como ejemplo a lo largo de la presentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d27b4eb-704e-4556-bb41-7b74250cefba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos del paciente.\n",
      "Nombre:  Ernesto.\n",
      "Apellidos: Rivera Bueno.\n",
      "NHC: 368503.\n",
      "NASS: 26 63514095.\n",
      "Domicilio:  Calle Miguel Benitez 90.\n",
      "Localidad/ Provincia: Madrid.\n",
      "CP: 28016.\n",
      "Datos asistenciales.\n",
      "Fecha de nacimiento: 03/03/1946.\n",
      "País: España.\n",
      "Edad: 70 años Sexo: H.\n",
      "Fecha de Ingreso: 12/12/2016.\n",
      "Médico:  Ignacio Navarro Cuéllar NºCol: 28 28 70973.\n",
      "Informe clínico del paciente: Paciente de 70 años de edad, minero jubilado, sin alergias medicamentosas conocidas, que presenta como antecedentes personales: accidente laboral antiguo con fracturas vertebrales y costales; intervenido de enfermedad de Du\n"
     ]
    }
   ],
   "source": [
    "text = brat_annotations.text\n",
    "print(text[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0462a-b0e4-4e08-a515-f024f306f6f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "- Las anotaciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8c6d9a",
   "metadata": {},
   "source": [
    "Las anotaciones siguen la misma estructura básica:   \n",
    "Cada línea contiene una anotación, y cada anotación recibe un ID que aparece en primer lugar en la línea, separado del resto de la anotación por un único carácter TAB. El resto de la estructura varía según el tipo de anotación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91388f5c-6bf1-4bb8-88b6-5be823a893cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1\tFECHAS 215 225\t03/03/1946\n",
      "T2\tCORREO_ELECTRONICO 2421 2439\tnnavcu@hotmail.com\n",
      "T3\tPAIS 2406 2412\tEspaña\n",
      "T4\tTERRITORIO 2398 2404\tMadrid\n",
      "T5\tTERRITORIO 2392 2397\t28036\n",
      "T6\tCALLE 2365 2391\tc/ del Abedul 5-7, 2º dcha\n",
      "T7\tNOMBRE_PERSONAL_SANITARIO 303 326\tIgnacio Navarro Cuéllar\n",
      "T8\tNOMBRE_PERSONAL_SANITARIO 2341 2364\tIgnacio Navarro Cuéllar\n",
      "T9\tEDAD_SUJETO_ASISTENCIA 389 396\t70 años\n",
      "T10\tID_TITULACION_PERSONAL_SANITARIO 334 345\t28 28 70973\n",
      "T11\tFECHAS 282 292\t12/12/2016\n",
      "T12\tSEXO_SUJETO_ASISTENCIA 261 262\tH\n",
      "T13\tEDAD_SUJETO_ASISTENCIA 247 254\t70 años\n",
      "T14\tPAIS 233 239\tEspaña\n",
      "T15\tTERRITORIO 166 171\t28016\n",
      "T16\tTERRITORIO 154 160\tMadrid\n",
      "T17\tCALLE 107 130\tCalle Miguel Benitez 90\n",
      "T18\tID_ASEGURAMIENTO 82 93\t26 63514095\n",
      "T19\tID_SUJETO_ASISTENCIA 68 74\t368503\n",
      "T20\tNOMBRE_SUJETO_ASISTENCIA 49 61\tRivera Bueno\n",
      "T21\tNOMBRE_SUJETO_ASISTENCIA 29 36\tErnesto\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    brat_files_pair\n",
    "    .ann\n",
    "    .root\n",
    "    .open(brat_files_pair.ann.at)\n",
    "    .read()\n",
    "    .decode(\"utf-8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3e561-f7fd-437d-8a56-d13f68d06595",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "- Las anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "695f66fb-b945-4512-ad8c-694ee083d64a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BratSpan(id='T1', entity_type='FECHAS', start=215, end=225, text='03/03/1946'),\n",
       " BratSpan(id='T2', entity_type='CORREO_ELECTRONICO', start=2421, end=2439, text='nnavcu@hotmail.com'),\n",
       " BratSpan(id='T3', entity_type='PAIS', start=2406, end=2412, text='España'),\n",
       " BratSpan(id='T4', entity_type='TERRITORIO', start=2398, end=2404, text='Madrid'),\n",
       " BratSpan(id='T5', entity_type='TERRITORIO', start=2392, end=2397, text='28036'),\n",
       " BratSpan(id='T6', entity_type='CALLE', start=2365, end=2391, text='c/ del Abedul 5-7, 2º dcha'),\n",
       " BratSpan(id='T7', entity_type='NOMBRE_PERSONAL_SANITARIO', start=303, end=326, text='Ignacio Navarro Cuéllar'),\n",
       " BratSpan(id='T8', entity_type='NOMBRE_PERSONAL_SANITARIO', start=2341, end=2364, text='Ignacio Navarro Cuéllar'),\n",
       " BratSpan(id='T9', entity_type='EDAD_SUJETO_ASISTENCIA', start=389, end=396, text='70 años'),\n",
       " BratSpan(id='T10', entity_type='ID_TITULACION_PERSONAL_SANITARIO', start=334, end=345, text='28 28 70973'),\n",
       " BratSpan(id='T11', entity_type='FECHAS', start=282, end=292, text='12/12/2016'),\n",
       " BratSpan(id='T12', entity_type='SEXO_SUJETO_ASISTENCIA', start=261, end=262, text='H'),\n",
       " BratSpan(id='T13', entity_type='EDAD_SUJETO_ASISTENCIA', start=247, end=254, text='70 años'),\n",
       " BratSpan(id='T14', entity_type='PAIS', start=233, end=239, text='España'),\n",
       " BratSpan(id='T15', entity_type='TERRITORIO', start=166, end=171, text='28016'),\n",
       " BratSpan(id='T16', entity_type='TERRITORIO', start=154, end=160, text='Madrid'),\n",
       " BratSpan(id='T17', entity_type='CALLE', start=107, end=130, text='Calle Miguel Benitez 90'),\n",
       " BratSpan(id='T18', entity_type='ID_ASEGURAMIENTO', start=82, end=93, text='26 63514095'),\n",
       " BratSpan(id='T19', entity_type='ID_SUJETO_ASISTENCIA', start=68, end=74, text='368503'),\n",
       " BratSpan(id='T20', entity_type='NOMBRE_SUJETO_ASISTENCIA', start=49, end=61, text='Rivera Bueno'),\n",
       " BratSpan(id='T21', entity_type='NOMBRE_SUJETO_ASISTENCIA', start=29, end=36, text='Ernesto')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brat_spans = brat_annotations.brat_spans; brat_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57417ec4-f458-44bb-8240-d1253278cc92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Preprocessamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93c9da-1a78-4d0f-8ba8-1c9136b31d66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Para empezar llamamos nuestro pipeline ``meddocan.language.pipeline.meddocan_pipeline`` hecho con la libreria [spaCy](https://spacy.io/) y miramos sus componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ad9f5d2-94c3-4386-b1f8-8e9259d65550",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>componentes</th>\n",
       "      <td>missaligned_splitter</td>\n",
       "      <td>line_sentencizer</td>\n",
       "      <td>predictor</td>\n",
       "      <td>write_methods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0                 1          2              3\n",
       "componentes  missaligned_splitter  line_sentencizer  predictor  write_methods"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = meddocan_pipeline()\n",
    "pd.DataFrame(nlp.pipe_names, columns=[\"componentes\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34727ff-9166-4e8b-b39c-0146de536c9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Vamos a hacer pasar nuestro texto de ejemplo por el ``meddocan_pipeline`` y ver el efecto de cada componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31a5e2c0-8042-4f95-a5a7-2ceea314a17c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6beeb0d-d8c1-4021-8c6b-44c73611612b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### 1. Tokenización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "103c47af",
   "metadata": {},
   "source": [
    "> :pencil: Un tokenizador se encarga de preparar las entradas para un modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5b0845d-2713-47ca-a767-f08a8f2f7fe4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datos', 'del', 'paciente', '.', '\\n', 'Nombre', ':', ' ', 'Ernesto', '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d4179-6207-4608-927f-7693cf8f5741",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "#### 2. Casos especiales ➟ missaligned_splitter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7434576c",
   "metadata": {},
   "source": [
    "> :warning: El principio de cada entidad debe coincidir con el principio de un token y su fin con el fin de un token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0391aab3-d35e-465f-9d3d-3bb4cc47bd04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DR, Enric, Lopez]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in nlp(\"DREnric Lopez\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edb79f-6091-4032-aa49-a2bc86ffa821",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### 3. Partición del documento en párrafos ➟ line_sentencizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ded7032",
   "metadata": {},
   "source": [
    "> :pencil: Los modelos de NER aceptan frases compuestas de token como entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f37f67c-668b-4771-acd5-5bea5303ebbb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e09d2_row0_col0, #T_e09d2_row1_col0, #T_e09d2_row2_col0, #T_e09d2_row3_col0, #T_e09d2_row4_col0, #T_e09d2_row5_col0, #T_e09d2_row6_col0, #T_e09d2_row7_col0, #T_e09d2_row8_col0, #T_e09d2_row9_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e09d2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e09d2_level0_col0\" class=\"col_heading level0 col0\" >párafo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e09d2_row0_col0\" class=\"data row0 col0\" >Datos del paciente.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e09d2_row1_col0\" class=\"data row1 col0\" >Nombre:  Ernesto.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e09d2_row2_col0\" class=\"data row2 col0\" >Apellidos: Rivera Bueno.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e09d2_row3_col0\" class=\"data row3 col0\" >NHC: 368503.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e09d2_row4_col0\" class=\"data row4 col0\" >NASS: 26 63514095.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e09d2_row5_col0\" class=\"data row5 col0\" >Domicilio:  Calle Miguel Benitez 90.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e09d2_row6_col0\" class=\"data row6 col0\" >Localidad/ Provincia: Madrid.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e09d2_row7_col0\" class=\"data row7 col0\" >CP: 28016.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e09d2_row8_col0\" class=\"data row8 col0\" >Datos asistenciales.\n",
       "</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e09d2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e09d2_row9_col0\" class=\"data row9 col0\" >Fecha de nacimiento: 03/03/1946.\n",
       "</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3f3a5f0730>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "df = pd.DataFrame([sent.text for sent in doc.sents][:10], columns=[\"párrafo\"]);\n",
    "df.style.set_properties(**{'text-align': 'left'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a95774-b262-43e0-bff5-45b672e98e1d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### 4. Asociar entidades al Doc ➟ predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb57a6e-b07f-49a1-8913-ab4decfb02ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "En una primera fase no tenemos modelos con el cual hacer predicciones.\n",
    "Entonces añadimos la entidades a nuestro objeto ``doc`` usando la function ``meddocan.data.utils.set_ents_from_brat_spans``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e277873-1b3f-43cc-a63a-4c8a259cf5c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Datos del paciente.</br>Nombre:  \n",
       "<mark class=\"entity\" style=\"background: #FF6600; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ernesto\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>Apellidos: \n",
       "<mark class=\"entity\" style=\"background: #FF6600; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rivera Bueno\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>NHC: \n",
       "<mark class=\"entity\" style=\"background: #FF9900; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    368503\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>NASS: \n",
       "<mark class=\"entity\" style=\"background: #00FF7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    26 63514095\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_ASEGURAMIENTO</span>\n",
       "</mark>\n",
       ".</br>Domicilio:  \n",
       "<mark class=\"entity\" style=\"background: #ADFF2F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Calle Miguel Benitez 90\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CALLE</span>\n",
       "</mark>\n",
       ".</br>Localidad/ Provincia: \n",
       "<mark class=\"entity\" style=\"background: #CCFFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TERRITORIO</span>\n",
       "</mark>\n",
       ".</br>CP: \n",
       "<mark class=\"entity\" style=\"background: #CCFFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    28016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TERRITORIO</span>\n",
       "</mark>\n",
       ".</br>Datos asistenciales.</br>Fecha de nacimiento: \n",
       "<mark class=\"entity\" style=\"background: #FFCCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    03/03/1946\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FECHAS</span>\n",
       "</mark>\n",
       ".</br>País: \n",
       "<mark class=\"entity\" style=\"background: #FFA07A; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PAIS</span>\n",
       "</mark>\n",
       ".</br>Edad: \n",
       "<mark class=\"entity\" style=\"background: #7FFF00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 años\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EDAD_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       " Sexo: \n",
       "<mark class=\"entity\" style=\"background: #99CCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    H\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SEXO_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>Fecha de Ingreso: \n",
       "<mark class=\"entity\" style=\"background: #FFCCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    12/12/2016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FECHAS</span>\n",
       "</mark>\n",
       ".</br>Médico:  \n",
       "<mark class=\"entity\" style=\"background: #FFD700; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ignacio Navarro Cuéllar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_PERSONAL_SANITARIO</span>\n",
       "</mark>\n",
       " NºCol: \n",
       "<mark class=\"entity\" style=\"background: #FF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    28 28 70973\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_TITULACION_PERSONAL_SANITARIO</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = set_ents_from_brat_spans(doc, brat_spans=brat_spans)\n",
    "displacy.render(doc[:100], style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788fb091-6fd3-43ff-b7e1-240d31ca8169",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "#### Serializar las anotaciones ➟ write_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce2b04-1ca7-47c8-b1cc-451ca56f49bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Para la evaluación, se puede escribir los datos al formato **Brat** gracias al método ``_.to_ann``.\n",
    "\n",
    "> :bulb: Una vez un modelo entrenado, cada documento se puede serializar a formato **formato standoff**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7167c70c-c0de-4327-a5a0-dfbe8dd85b9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_0\tNOMBRE_SUJETO_ASISTENCIA 29 36\tErnesto\n",
      "T_1\tNOMBRE_SUJETO_ASISTENCIA 49 61\tRivera Bueno\n",
      "T_2\tID_SUJETO_ASISTENCIA 68 74\t368503\n",
      "T_3\tID_ASEGURAMIENTO 82 93\t26 63514095\n",
      "T_4\tCALLE 107 130\tCalle Miguel Benitez 90\n",
      "T_5\tTERRITORIO 154 160\tMadrid\n",
      "T_6\tTERRITORIO 166 171\t28016\n",
      "T_7\tFECHAS 215 225\t03/03/1946\n",
      "T_8\tPAIS 233 239\tEspaña\n",
      "T_9\tEDAD_SUJETO_ASISTENCIA 247 254\t70 años\n",
      "T_10\tSEXO_SUJETO_ASISTENCIA 261 262\tH\n",
      "T_11\tFECHAS 282 292\t12/12/2016\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as td:\n",
    "    pth = Path(td, \"file.txt\")\n",
    "    doc._.to_ann(pth)\n",
    "    for i, line in enumerate(pth.read_text().split(\"\\n\")):\n",
    "        print(line)\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd524dba-1ffb-485b-b419-00ca61976b2c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Para el entrenamiento, los datos se escriben al formato **conll03** gracias al método ``_.to_connl03``.\n",
    "\n",
    "> :bulb: Cada documento se puede serializar a formato **IOB**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce03045-baf2-4118-bfdc-91e4f4fc299e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos O\n",
      "del O\n",
      "paciente O\n",
      ". O\n",
      "\n",
      "Nombre O\n",
      ": O\n",
      "Ernesto B-NOMBRE_SUJETO_ASISTENCIA\n",
      ". O\n",
      "\n",
      "Apellidos O\n",
      ": O\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as td:\n",
    "    pth = Path(td, \"file.txt\")\n",
    "    doc._.to_connl03(pth)\n",
    "    for i, line in enumerate(pth.read_text().split(\"\\n\")):\n",
    "        print(line)\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a0769-e827-4664-89ec-7089de86a52a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Entrenamiento con la librería [Flair](https://github.com/flairNLP/flair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd6edb-d67a-4e61-b850-c60d259e1ba4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Creación del dataset ``MEDDOCAN``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b320722-086e-4c1b-94c0-02992521ac29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Los distinctos conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50fcb2aa-91cb-49be-ac5a-d39c1d3a9927",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sets</th>\n",
       "      <td>train</td>\n",
       "      <td>dev</td>\n",
       "      <td>test</td>\n",
       "      <td>sample</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1     2       3           4\n",
       "sets  train  dev  test  sample  background"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[folder.value for folder in ArchiveFolder]], index=[\"sets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79870bdf-53d3-4911-8261-1c62dd05c52a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Solo se usan los sets de *train*, *dev* y *test*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e44644-7048-41c5-a390-641bd1eab8e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Utilizamos el objecto ``meddocan.data.docs_iterators.GsDocs`` que nos permitte obtener objectos ``Doc`` usando el ``meddocan_pipeline`` para cada uno de los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a802dff0-d778-4e2b-b52b-e30dc8f9551a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_docs = GsDocs(ArchiveFolder.train)\n",
    "docs_with_brat_pair = iter(gs_docs)\n",
    "doc_with_brat_pair = next(docs_with_brat_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce915591-bc2a-4c78-9b3d-e29652938e0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "``doc_with_brat_pair`` es una ``NameTuple`` que associa cada ``BratFilesPair`` con el objeto ``Doc`` corespondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35a56667-7f24-4fa3-a49f-20cf0bfbf455",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BratFilesPair(ann=Path('/home/wave/.meddocan/datasets/meddocan/train-set.zip', 'train/brat/S0004-06142005000500011-1.ann'), txt=Path('/home/wave/.meddocan/datasets/meddocan/train-set.zip', 'train/brat/S0004-06142005000500011-1.txt'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_with_brat_pair.brat_files_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ae15ba9-f9eb-4982-93db-d49e3c961ba9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datos del paciente.\n",
       "Nombre:  Ernesto."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_with_brat_pair.doc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6accf0e9-e0b2-4181-ad8d-4052bce13981",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos O\n",
      "del O\n",
      "paciente O\n",
      ". O\n",
      "\n",
      "Nombre O\n",
      ": O\n",
      "Ernesto B-NOMBRE_SUJETO_ASISTENCIA\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "visualize_conll03(doc_with_brat_pair.doc, nb_lines=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d256247-e4b9-47fb-91d4-034079966c94",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "``doc_with_brat_pair`` ayuda a crear el ``MEDDOCAN`` corpus que hereda de ``flair.datasets.ColumnCorpus``."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a1a5be-3163-4727-b13e-fd789086a3c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "El ``MEDDOCAN`` corpus esta creado a partir de ficheros temporales que contienen el texto asi como los offsets al formato **connl03**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71152ae9-5278-41af-9d17-b6629d96f1d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 15:17:00,999 Reading data from /tmp/tmpnweuzjg4\n",
      "2023-03-09 15:17:01,000 Train: /tmp/tmpnweuzjg4/train\n",
      "2023-03-09 15:17:01,001 Dev: /tmp/tmpnweuzjg4/dev\n",
      "2023-03-09 15:17:01,001 Test: /tmp/tmpnweuzjg4/test\n"
     ]
    }
   ],
   "source": [
    "corpus = MEDDOCAN(sentences=True, in_memory=True, document_separator_token=\"-DOCSTART-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4073d072-6d85-4f80-bfb6-7610e43536d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 10811 train + 5518 dev + 5405 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd97fe-4924-4662-8495-fafe0687d0f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Ahora podemos pasar al entrenamiento con **Flair**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4d530-f870-45cd-a827-2262ae84e503",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d46b9b7-9a00-4ffb-a6d9-edb4493d6237",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from meddocan.data.corpus import MEDDOCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782a8b3-598e-4057-8dde-63ece1676fec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "1. Obtener el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad1ea1-aa74-4530-b281-3ca22ab35df3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus: Corpus = MEDDOCAN(sentences=True, document_separator_token=\"-DOCSTART-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2cdc949-cfd5-45b4-9e90-30ddb8d7c14b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus: 10811 train + 5518 dev + 5405 test sentences\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a38517-4bf8-454a-975e-0fc13622c332",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "2. ¿Que label queremos predecir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f232cd3e-7f31-480d-913e-118f2f1215d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_type = 'ner'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c63a4-7a52-420f-8457-bf01e0a4fc2f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "3. Crear el diccionario de labels a partir del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5edee902-7c92-4123-b98c-27abe47decd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 15:19:03,526 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10811it [00:00, 36940.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 15:19:03,825 Dictionary created for label 'ner' with 22 values: TERRITORIO (seen 1875 times), FECHAS (seen 1231 times), EDAD_SUJETO_ASISTENCIA (seen 1035 times), NOMBRE_SUJETO_ASISTENCIA (seen 1009 times), NOMBRE_PERSONAL_SANITARIO (seen 1000 times), SEXO_SUJETO_ASISTENCIA (seen 925 times), CALLE (seen 862 times), PAIS (seen 713 times), ID_SUJETO_ASISTENCIA (seen 567 times), ID_TITULACION_PERSONAL_SANITARIO (seen 471 times), CORREO_ELECTRONICO (seen 469 times), ID_ASEGURAMIENTO (seen 391 times), HOSPITAL (seen 255 times), FAMILIARES_SUJETO_ASISTENCIA (seen 243 times), INSTITUCION (seen 98 times), ID_CONTACTO_ASISTENCIAL (seen 77 times), NUMERO_TELEFONO (seen 58 times), PROFESION (seen 24 times), NUMERO_FAX (seen 15 times), OTROS_SUJETO_ASISTENCIA (seen 9 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7e26021-4b91-484a-830b-90a7a2508e39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 22 tags: <unk>, TERRITORIO, FECHAS, EDAD_SUJETO_ASISTENCIA, NOMBRE_SUJETO_ASISTENCIA, NOMBRE_PERSONAL_SANITARIO, SEXO_SUJETO_ASISTENCIA, CALLE, PAIS, ID_SUJETO_ASISTENCIA, ID_TITULACION_PERSONAL_SANITARIO, CORREO_ELECTRONICO, ID_ASEGURAMIENTO, HOSPITAL, FAMILIARES_SUJETO_ASISTENCIA, INSTITUCION, ID_CONTACTO_ASISTENCIAL, NUMERO_TELEFONO, PROFESION, NUMERO_FAX, OTROS_SUJETO_ASISTENCIA, CENTRO_SALUD\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceda663-38ae-4232-9ba3-99b739e25be6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "4. Inicializar los embeddings generados por el transformador utilizando el contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d834adb-5d63-44ff-ba59-72f29c66c738",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = TransformerWordEmbeddings(\n",
    "    model='dccuchile/bert-base-spanish-wwm-cased',\n",
    "    layers=\"-1\",\n",
    "    subtoken_pooling=\"first\",\n",
    "    fine_tune=True,\n",
    "    use_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4afdb2b-1d93-4ae1-8a6c-85a02992a1d2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerWordEmbeddings(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ca491-0eca-46bc-ae68-cd10ad97da7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "5. Inicializar etiquedator simple (no CRF, no RNN, no reprojección)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa095b60-83fa-4747-bf78-27ea20541e58",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 15:22:00,610 SequenceTagger predicts: Dictionary with 85 tags: O, S-TERRITORIO, B-TERRITORIO, E-TERRITORIO, I-TERRITORIO, S-FECHAS, B-FECHAS, E-FECHAS, I-FECHAS, S-EDAD_SUJETO_ASISTENCIA, B-EDAD_SUJETO_ASISTENCIA, E-EDAD_SUJETO_ASISTENCIA, I-EDAD_SUJETO_ASISTENCIA, S-NOMBRE_SUJETO_ASISTENCIA, B-NOMBRE_SUJETO_ASISTENCIA, E-NOMBRE_SUJETO_ASISTENCIA, I-NOMBRE_SUJETO_ASISTENCIA, S-NOMBRE_PERSONAL_SANITARIO, B-NOMBRE_PERSONAL_SANITARIO, E-NOMBRE_PERSONAL_SANITARIO, I-NOMBRE_PERSONAL_SANITARIO, S-SEXO_SUJETO_ASISTENCIA, B-SEXO_SUJETO_ASISTENCIA, E-SEXO_SUJETO_ASISTENCIA, I-SEXO_SUJETO_ASISTENCIA, S-CALLE, B-CALLE, E-CALLE, I-CALLE, S-PAIS, B-PAIS, E-PAIS, I-PAIS, S-ID_SUJETO_ASISTENCIA, B-ID_SUJETO_ASISTENCIA, E-ID_SUJETO_ASISTENCIA, I-ID_SUJETO_ASISTENCIA, S-ID_TITULACION_PERSONAL_SANITARIO, B-ID_TITULACION_PERSONAL_SANITARIO, E-ID_TITULACION_PERSONAL_SANITARIO, I-ID_TITULACION_PERSONAL_SANITARIO, S-CORREO_ELECTRONICO, B-CORREO_ELECTRONICO, E-CORREO_ELECTRONICO, I-CORREO_ELECTRONICO, S-ID_ASEGURAMIENTO, B-ID_ASEGURAMIENTO, E-ID_ASEGURAMIENTO, I-ID_ASEGURAMIENTO, S-HOSPITAL\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger(\n",
    "    hidden_size=256,\n",
    "    embeddings=embeddings,\n",
    "    tag_dictionary=label_dict,\n",
    "    tag_type='ner',\n",
    "    use_crf=False,\n",
    "    use_rnn=False,\n",
    "    reproject_embeddings=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cd5ffae",
   "metadata": {},
   "source": [
    "> :bulb: Internamente, el ``SequenceTagger`` esta entrenado para atribuir a cada token un tag al formato **IOBES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a71c18-9729-4f4f-a177-11df344f60d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "6. Initializar el trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "13d0a576-c7f5-4089-81b4-8025920a7768",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bf075-3078-44f1-933f-06ae0151cc86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "7. Ejecutar el fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55371d7c-e740-4cb3-b16b-b50b1745b551",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "trainer.fine_tune(\n",
    "    'experiments/meddocan',\n",
    "    learning_rate=5.0e-6,\n",
    "    mini_batch_size=4,\n",
    "    epoch=0\n",
    "  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad8a7b-d918-4cdd-b753-ef0878bf4703",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Gracias al ``meddocan_pipeline`` podemos:\n",
    "\n",
    "* Evaluar el modelo\n",
    "* Hacer la inferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f333e41-a894-4867-ac97-7b1abe488d6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Inferencia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d3e76cd-8a61-421f-9eb9-44448ae24d19",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Se utiliza el ``meddocan_pipeline`` con un modelo entrenado con **Flair**.\n",
    "\n",
    "> :bulb: El modelo añade ``spacy.tokens.Spans`` al objecto ``Doc`` producido por el pipeline. Por ello usamos el componente ``meddocan.language.predictor.PredictorComponent``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccd9bf39-d501-4a42-8276-1de4162c32e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-09 15:43:49,955 loading file /home/wave/.meddocan/models/meddocan-flair-lstm-crf/7a9ec5ed1acfc4a745f9ac72d8ffb8fcd2f463fb817a7ec931ad915b9d55eb2a.ca6fb9679dcac2a696f417c3b42d053c32588efb81398e5ab04cb3c1d867ba68\n",
      "2023-03-09 15:43:50,597 SequenceTagger predicts: Dictionary with 91 tags: O, S-TERRITORIO, B-TERRITORIO, E-TERRITORIO, I-TERRITORIO, S-FECHAS, B-FECHAS, E-FECHAS, I-FECHAS, S-EDAD_SUJETO_ASISTENCIA, B-EDAD_SUJETO_ASISTENCIA, E-EDAD_SUJETO_ASISTENCIA, I-EDAD_SUJETO_ASISTENCIA, S-NOMBRE_SUJETO_ASISTENCIA, B-NOMBRE_SUJETO_ASISTENCIA, E-NOMBRE_SUJETO_ASISTENCIA, I-NOMBRE_SUJETO_ASISTENCIA, S-NOMBRE_PERSONAL_SANITARIO, B-NOMBRE_PERSONAL_SANITARIO, E-NOMBRE_PERSONAL_SANITARIO, I-NOMBRE_PERSONAL_SANITARIO, S-SEXO_SUJETO_ASISTENCIA, B-SEXO_SUJETO_ASISTENCIA, E-SEXO_SUJETO_ASISTENCIA, I-SEXO_SUJETO_ASISTENCIA, S-CALLE, B-CALLE, E-CALLE, I-CALLE, S-PAIS, B-PAIS, E-PAIS, I-PAIS, S-ID_SUJETO_ASISTENCIA, B-ID_SUJETO_ASISTENCIA, E-ID_SUJETO_ASISTENCIA, I-ID_SUJETO_ASISTENCIA, S-ID_TITULACION_PERSONAL_SANITARIO, B-ID_TITULACION_PERSONAL_SANITARIO, E-ID_TITULACION_PERSONAL_SANITARIO, I-ID_TITULACION_PERSONAL_SANITARIO, S-CORREO_ELECTRONICO, B-CORREO_ELECTRONICO, E-CORREO_ELECTRONICO, I-CORREO_ELECTRONICO, S-ID_ASEGURAMIENTO, B-ID_ASEGURAMIENTO, E-ID_ASEGURAMIENTO, I-ID_ASEGURAMIENTO, S-HOSPITAL\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"GuiGel/meddocan-flair-lstm-crf\"\n",
    "FAST = \"flair/ner-english-fast\"\n",
    "\n",
    "nlp = meddocan_pipeline(MODEL)\n",
    "sys = nlp(doc.text);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4ed696e-f83f-4fa4-8a00-d5bd84d35ea8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Datos del paciente.</br>Nombre:  \n",
       "<mark class=\"entity\" style=\"background: #FF6600; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ernesto\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>Apellidos: \n",
       "<mark class=\"entity\" style=\"background: #FF6600; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rivera Bueno\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>NHC: \n",
       "<mark class=\"entity\" style=\"background: #FF9900; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    368503\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>NASS: \n",
       "<mark class=\"entity\" style=\"background: #00FF7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    26 63514095\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_ASEGURAMIENTO</span>\n",
       "</mark>\n",
       ".</br>Domicilio:  \n",
       "<mark class=\"entity\" style=\"background: #ADFF2F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Calle Miguel Benitez 90\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CALLE</span>\n",
       "</mark>\n",
       ".</br>Localidad/ Provincia: \n",
       "<mark class=\"entity\" style=\"background: #CCFFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TERRITORIO</span>\n",
       "</mark>\n",
       ".</br>CP: \n",
       "<mark class=\"entity\" style=\"background: #CCFFFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    28016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TERRITORIO</span>\n",
       "</mark>\n",
       ".</br>Datos asistenciales.</br>Fecha de nacimiento: \n",
       "<mark class=\"entity\" style=\"background: #FFCCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    03/03/1946\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FECHAS</span>\n",
       "</mark>\n",
       ".</br>País: \n",
       "<mark class=\"entity\" style=\"background: #FFA07A; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PAIS</span>\n",
       "</mark>\n",
       ".</br>Edad: \n",
       "<mark class=\"entity\" style=\"background: #7FFF00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    70 años\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EDAD_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       " Sexo: \n",
       "<mark class=\"entity\" style=\"background: #99CCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    H\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SEXO_SUJETO_ASISTENCIA</span>\n",
       "</mark>\n",
       ".</br>Fecha de Ingreso: \n",
       "<mark class=\"entity\" style=\"background: #FFCCFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    12/12/2016\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FECHAS</span>\n",
       "</mark>\n",
       ".</br>Médico:  \n",
       "<mark class=\"entity\" style=\"background: #FFD700; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ignacio Navarro Cuéllar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOMBRE_PERSONAL_SANITARIO</span>\n",
       "</mark>\n",
       " NºCol: \n",
       "<mark class=\"entity\" style=\"background: #FF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    28 28 70973\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ID_TITULACION_PERSONAL_SANITARIO</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(sys[:100], style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c672156-5c8f-4ff3-b133-b72bfd94c47f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9cec4a-df15-413a-b1df-f06bddf4081e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "La **precision** y el **recall** son métricas de rendimiento que se aplican a los datos recuperados de una colección, corpus o espacio muestral.\n",
    "\n",
    "La precision (también llamada valor predictivo positivo) es la fracción de instancias relevantes entre las instancias recuperadas, mientras que el **recall** (también conocida como sensibilidad) es la fracción de instancias relevantes que se recuperaron. Por tanto, tanto la precisión como la recuperación se basan en la relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90aa7f-233f-4663-a736-ad6a9c268135",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Las metricas son el escore F1, el Recall y la Precision\n",
    "\n",
    "![metrics](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619f41a-1eb3-4899-be83-3fdf6c230c0e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Hay distinctas fase a considerar\n",
    "\n",
    "1. Durante el entrenamiento via el caclulo de metricas al nivel de token o subtoken con las predicciones del modelo sobre el set de validation.\n",
    "2. Durante la fase de test donde se evalua el modelo tanto al nivel de token como de span."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c759f9d8-0817-46b9-9c33-cc95e3bdc897",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Evaluación con los tokens**\n",
    "\n",
    "Toma las entidades detectadas por el modelo en ``sys`` y las verdaderas en ``doc``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf40ad-a256-4620-a4eb-f829aa593a7c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents = [\n",
    "    (\n",
    "        token_doc.text,\n",
    "        glue_iob_label(token_doc.ent_iob_, token_doc.ent_type_),\n",
    "        glue_iob_label(token_sys.ent_iob_, token_sys.ent_type_)\n",
    "    ) \n",
    "    for (token_doc, token_sys)\n",
    "    in zip(doc, sys)\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(ents[:20], columns=[\"text\", \"gold\", \"sys\"])\n",
    "df.style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca02d060-0933-4c7f-98e3-0792549d9635",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Lo unico que nos interesa son las columnas **gold** y **sys**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "366055b9-a292-4683-ad2b-9f636e7ea192",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Para tener un calculo de las métricas que no sean nulas construimos un ejemplo de datos ficticios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5adf5-72b0-411f-bbf0-37ecc5cbe312",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"I-PER\"]]\n",
    "y_pred = [[\"O\", \"B-MISC\", \"B-MISC\", \"I-MISC\", \"B-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"O\"]]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[*y_true[0], *y_true[1]], [*y_pred[0], *y_pred[1]]],\n",
    "    index=[\"y_true\", \"y_pred\"]\n",
    ").T\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce18e98-2c3a-4aef-a0ce-182d1e83fd6d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, mode=\"strict\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e3aa8ce-569f-4716-a25b-2679abc533c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Para las personas**\n",
    "\n",
    "* **Precision**: Todas las personas detectas son realmente personas -> precision de 1  \n",
    "* **Recall**: Solo 2 personas de 3 son detectadas -> recall de 2/3 = 0.67  \n",
    "* **micro avg precision**: Se detectan 5 entidades (3 MISC y 2 PER) de las cuales 2 son TP -> 2/5 = 0.4\n",
    "* **macro avg precision**: Hay que detectar 4 entidades (2 MISC y 2 PER) de las cuales se detectan 2 -> 2/4 = 0.5\n",
    "* **micro avg precision**: Hay 2 tipo de entidades -> 1 / 2 = 0.5\n",
    "* **micro avg recall**: Hay 2 tipo de entidades -> 0.67 / 2 = 0.33\n",
    "* **weighted avg precision**: Hay 3 PERS y 1 MISC a detectar -> (3 * 1.0 + 1 * 0.0) / 4 = 0.75\n",
    "* **weighted avg recall**: Hay 3 PERS y 1 MISC a detectar -> (3 * 0.67 + 1 * 0.0) / 4 = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb0096-b5ca-4784-98e0-47c118924352",
   "metadata": {},
   "source": [
    "Es esta mañera de calcular las metricas que se usa internamente en **Flair** para evaluar un modelo durante el entrenamiento sobre el set de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0cbec-9934-43ea-a8ee-6963ddb80819",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Meddocan evaluación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a45c4-4c36-4097-b5e5-a3e61f270e07",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE = \"https://api.github.com/repos/PlanTL-GOB-ES/MEDDOCAN-Evaluation-Script/contents\"\n",
    "# The api where the text can be reach.\n",
    "\n",
    "gold_annotation = get_brat_annotation_from_github(\"gold/brat/sample/S0004-06142005000700014-1.ann\", base=BASE)\n",
    "sys_annotation = get_brat_annotation_from_github(\"system/brat/subtrack2/sample/baseline/S0004-06142005000700014-1.ann\", base=BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74e18e-fe84-4959-a1c4-35261129b879",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* **Subtrack 1**\n",
    "  \n",
    "> La primera tarea se centró en la identificación y clasificación de información sensible (por ejemplo, nombres de pacientes, teléfonos, direcciones, etc.). Se trata de la misma tarea que realizamos al anonimizar documentos legales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bce21a-8c05-4184-8ccb-f4768c5658da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [phi.tag, phi.start, phi.end]\n",
    "         for phi in gold_annotation.phi\n",
    "    ],\n",
    "    columns=[\"TAG\", \"START CHAR\", \"END CHAR\"],\n",
    ")\n",
    "(df\n",
    " .sort_values(by=[\"START CHAR\"])\n",
    " .reset_index()\n",
    " .drop(\"index\", axis=1)\n",
    " .loc[17:20,:]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59f57a6",
   "metadata": {},
   "source": [
    "Calculamos las métricas correspondientes paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0460bbf-721e-4fb4-bf73-d6772e3bcb81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gold_ner = set(sys_annotation.phi)\n",
    "sys_ner = set(gold_annotation.phi)\n",
    "\n",
    "fp = sys_ner - gold_ner\n",
    "tp = gold_ner.intersection(sys_ner)\n",
    "fn = gold_ner - sys_ner\n",
    "\n",
    "precision = len(tp) / (len(tp) + len(fn))\n",
    "recall = len(tp) / (len(tp) + len(fp))\n",
    "f1 =  precision * recall / (precision + recall) * 2\n",
    "\n",
    "df_SubTk1 = pd.DataFrame([precision, recall, f1], index=[\"precision\", \"recall\", \"f1\"], columns=[\"Subtrack1\"]); df_SubTk1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7524b4ee",
   "metadata": {},
   "source": [
    "Evaluación de la Subtrack1 con la funcionalidad de meddocan integrada a nuestra librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dcf7cb-3416-4d60-9768-91e743499790",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = EvaluateSubtrack1({sys_annotation.id: sys_annotation}, {gold_annotation.id: gold_annotation})\n",
    "e.print_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa940e96-a819-49ee-8c5a-7e9b52fa0ce6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* **Subtrack2 [Strict]**\n",
    "> La segunda tarea se centró en la detección de texto sensible más específico para el escenario práctico necesario para la publicación de documentos clínicos desidentificados, donde el objetivo es identificar y enmascarar los datos confidenciales, independientemente del tipo real de entidad o de la identificación correcta del tipo de PHI. En este caso solo nos interesa conocer la ubicación del texto a enmascarar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d779ea9b",
   "metadata": {},
   "source": [
    "Miramos los datos usados para calcular las métricas.\n",
    "\n",
    "> :bulb: La columna text solo es indicativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63685c0b-b0e6-4ef5-ab77-80037f42e483",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [phi.start, phi.end, gold_annotation.text[phi.start: phi.end]]\n",
    "         for phi in gold_annotation.sensitive_spans\n",
    "    ],\n",
    "    columns=[\"START CHAR\", \"END CHAR\", \"TEXT\"],\n",
    ")\n",
    "(df\n",
    " .sort_values(by=[\"START CHAR\"])\n",
    " .reset_index()\n",
    " .drop(\"index\", axis=1)\n",
    " .loc[17:20,:]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "540aa4d7",
   "metadata": {},
   "source": [
    "Calculamos las métricas correspondientes paso a paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ner = set(sys_annotation.sensitive_spans)\n",
    "sys_ner = set(gold_annotation.sensitive_spans)\n",
    "\n",
    "fp = sys_ner - gold_ner\n",
    "tp = gold_ner.intersection(sys_ner)\n",
    "fn = gold_ner - sys_ner\n",
    "\n",
    "precision = len(tp) / (len(tp) + len(fn))\n",
    "recall = len(tp) / (len(tp) + len(fp))\n",
    "f1 =  precision * recall / (precision + recall) * 2\n",
    "\n",
    "df_SubTk2_S = pd.DataFrame([precision, recall, f1], index=[\"precision\", \"recall\", \"f1\"], columns=[\"Subtrack2 [Strict]\"]); df_SubTk2_S"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9806857a",
   "metadata": {},
   "source": [
    "Evaluación de la Subtrack2 [Strict] con la funcionalidad de meddocan integrada a nuestra librería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc350ce0-4b05-4867-a0d3-27e1dc135906",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = EvaluateSubtrack2({sys_annotation.id: sys_annotation}, {gold_annotation.id: gold_annotation})\n",
    "e.print_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a91ce-5751-41d4-95a0-c65245586aa3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* **Subtrack2 [Merged]**\n",
    "> También calculamos adicionalmente otra evaluación en la que fusionamos los tramos de PHI conectados por caracteres no alfanuméricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefb7cb-bb56-4f87-94bb-ee89c102dbdd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [phi.start, phi.end, gold_annotation.text[phi.start: phi.end]]\n",
    "         for phi in gold_annotation.sensitive_spans_merged\n",
    "    ],\n",
    "    columns=[\"START CHAR\", \"END CHAR\", \"TEXT\"],\n",
    ")\n",
    "(df\n",
    " .sort_values(by=[\"START CHAR\"])\n",
    " .reset_index()\n",
    " .drop(\"index\", axis=1)\n",
    " .loc[17:20,:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccc621",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ner = set(sys_annotation.sensitive_spans_merged)\n",
    "sys_ner = set(gold_annotation.sensitive_spans_merged)\n",
    "\n",
    "fp = sys_ner - gold_ner\n",
    "tp = gold_ner.intersection(sys_ner)\n",
    "fn = gold_ner - sys_ner\n",
    "\n",
    "precision = len(tp) / (len(tp) + len(fn))\n",
    "recall = len(tp) / (len(tp) + len(fp))\n",
    "f1 =  precision * recall / (precision + recall) * 2\n",
    "\n",
    "df_SubTk2_M = pd.DataFrame([precision, recall, f1], index=[\"precision\", \"recall\", \"f1\"], columns=[\"Subtrack2 [Merged]\"]); df_SubTk2_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32861a27-7aca-4b73-87de-6adaf0a57e6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = EvaluateSubtrack2merged({sys_annotation.id: sys_annotation}, {gold_annotation.id: gold_annotation})\n",
    "e.print_docs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8882b6bf",
   "metadata": {},
   "source": [
    "Para resumir, vemos que las métricas mejoran según lo que se quiere detectar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_SubTk1, df_SubTk2_S, df_SubTk2_M], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54c3f5-6ed4-4930-a5b8-a5a00c20a3c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Para evaluar fácilmente nuestros modelos hemos creado la linea de comando ``meddocan eval``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d06c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meddocan.cli import eval\n",
    "\n",
    "print(eval.__doc__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5b555f4",
   "metadata": {},
   "source": [
    "Se puede acceder a la cli directamente desde el terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966bac8-b26a-4607-8c5b-5feb3c681974",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! meddocan eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bd3c09-1f44-4e9a-9eeb-aca7b86dc8b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Esta linea de comando crea los ficheros necessario para la evaluación original a partir del ``meddocan_pipeline`` y del modelo a evaluar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaadeed2-86a4-4ced-b38b-166590e924ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Experimentos\n",
    "\n",
    "Vamos a ver mas en detalle como hemos hecho los experimentos usando el ejemplo del experimento llamado *corpus_sentence_bert_context_finetune*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1643fbb6-4f64-42dc-84e3-8d352a3b193b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tree -L 1 ../experiments/corpus_sentence_bert_context_finetune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88272e00",
   "metadata": {},
   "source": [
    "Para visualizar nuestros scripts, utilizamos la función ``display_script``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_script(\"../experiments/corpus_sentence_bert_context_finetune/training.sh\", \"bash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22930377-73ac-4aec-a4a3-c987cdeb1c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_script(\"../experiments/corpus_sentence_bert_context_finetune/get_metrics.py\", \"python\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a4c01fa",
   "metadata": {},
   "source": [
    "Gracias a esos scripts, sacamos por cada experimentos los resultados dentro de la carpeta *evals*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabea195",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree ../experiments/corpus_sentence_bert_context_finetune/an_wh_rs_False_dpt_0_emb_beto-cased-context_FT_True_Ly_-1_seed_1_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cac5f30a",
   "metadata": {},
   "source": [
    "Por ejemplo miramos la evaluation de un modelo sobre el set de validation con la Subtrack1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ae9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    Path(\n",
    "        f\"../experiments/corpus_sentence_bert_context_finetune/\"\n",
    "        f\"an_wh_rs_False_dpt_0_emb_beto-cased-context_FT_True_Ly_-1_seed_1_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/\"\n",
    "        f\"evals/test/ner\"\n",
    "    )\n",
    "    .read_text()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "596d563d-2016-44a2-a894-f49dcf2d82b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Para obtener un resumen de nuestros experimentos creamos una serie de funciones que nos permiten recopilar los resultados de mañera a producir los resultados que se han usado en la documentación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c59b85e2",
   "metadata": {},
   "source": [
    "Creamos funciones para leer las métricas desde los ficheros contenidos en una carpeta *eval*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21869eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable, DefaultDict, List, NamedTuple\n",
    "\n",
    "class SubtrackScores(NamedTuple):\n",
    "    precision: float\n",
    "    recall: float\n",
    "\n",
    "def _get_scores(folder_path: Path, filename: str, precision_line: int, recall_line: int) -> SubtrackScores:\n",
    "    fpth = Path(folder_path / filename)\n",
    "    if not fpth.exists():\n",
    "        raise FileNotFoundError(f\"{fpth} not found!\")\n",
    "\n",
    "    lines = fpth.read_text().split(\"\\n\")\n",
    "\n",
    "    precision = float(lines[precision_line].split(\"=\")[-1])\n",
    "    recall = float(lines[recall_line].split(\"=\")[-1])\n",
    "\n",
    "    return SubtrackScores(precision, recall)\n",
    "\n",
    "def get_subtrack1_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"ner\", -3, -2)\n",
    "\n",
    "def get_subtrack2_strict_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -6, -5)\n",
    "\n",
    "def get_subtrack2_merged_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -3, -2)\n",
    "\n",
    "def get_scores_as_df(seeds: List[int], get_folder: Callable[[int], Path]) -> pd.DataFrame:\n",
    "    subtracks_scores: DefaultDict[List, float] = defaultdict(list)\n",
    "\n",
    "    for seed in seeds:\n",
    "        fpth = get_folder(seed)\n",
    "\n",
    "        p, r = get_subtrack1_scores(fpth)\n",
    "        subtracks_scores[\"1_p\"].append(p)\n",
    "        subtracks_scores[\"1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_strict_scores(fpth)\n",
    "        subtracks_scores[\"2_1_p\"].append(p)\n",
    "        subtracks_scores[\"2_1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_merged_scores(fpth)\n",
    "        subtracks_scores[\"2_2_p\"].append(p)\n",
    "        subtracks_scores[\"2_2_r\"].append(r)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(subtracks_scores)\n",
    "    for col in [\"1\", \"2_1\", \"2_2\"]:\n",
    "        df[f\"{col}_f1\"] = 2*df[f\"{col}_p\"]*df[f\"{col}_r\"] / (df[f\"{col}_p\"] + df[f\"{col}_r\"])\n",
    "\n",
    "    # Reorder columns\n",
    "    new_columns = [\"1_p\", \"1_r\", \"1_f1\", \"2_1_p\", \"2_1_r\", \"2_1_f1\", \"2_2_p\", \"2_2_r\", \"2_2_f1\"]\n",
    "    df = df[new_columns]\n",
    "\n",
    "    # Prepare multi index names\n",
    "    multi_index = pd.MultiIndex.from_product(\n",
    "        [\n",
    "            [\"Subtrack 1\", \"Subtrack 2 [Strict]\", \"Subtrack 2 [Merged]\"],\n",
    "            [\"precision\", \"recall\", \"f1\"]\n",
    "        ],\n",
    "        names=[\"Track\", \"Scores\"]\n",
    "    )\n",
    "    # Give multi index to df\n",
    "    return pd.DataFrame(df.to_numpy().T, index=multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7850f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "seeds = [1, 12, 33]\n",
    "dataset = \"test\"\n",
    "base_folder = Path.cwd().parent\n",
    "get_folder = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_finetune_it_150/an_wh_rs_False_dpt_0_emb_beto-cased_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\"\n",
    "get_scores_as_df_with_seed = partial(get_scores_as_df,  seeds)\n",
    "df_all_scores = get_scores_as_df(seeds, get_folder); df_all_scores.rename(columns=dict(zip(range(3), seeds)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08c2d673",
   "metadata": {},
   "source": [
    "Ahora solo nos interesa conocer el escore medio asi como su desviación estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3be854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_scores.T.describe().T[[\"mean\", \"std\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d607d22",
   "metadata": {},
   "source": [
    "Hacemos lo mismo por cada experimento por una métrica dada $F_{1}$, $precision$ or $recall$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_results(metric: str = \"f1\", dataset: str = \"dev\") -> Dict[Tuple[str, ...], pd.DataFrame]:\n",
    "    get_scores_as_df_with_seed = partial(get_scores_as_df,  [1, 12, 33])\n",
    "    get_folders_all = {\n",
    "        (\"FINETUNE\", \"BETO\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_finetune_it_150/an_wh_rs_False_dpt_0_emb_beto-cased_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"BETO + CONTEXT\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_finetune/an_wh_rs_False_dpt_0_emb_beto-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"BETO + WE\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_we_finetune_it_150/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_{seed})_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"BETO + WE + CONTEXT\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_we_finetune_it_150/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_{seed})_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"XLMRL\"): lambda seed: base_folder / f\"experiments/corpus_sentence_xlmrl_finetune/an_wh_rs_False_dpt_0_emb_xlm-roberta-large-cased_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"XLMRL + WE\"): lambda seed: base_folder / f\"experiments/corpus_sentence_xlmrl_we_finetune/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-xlm-roberta-large-cased_FT_True_Ly_-1_seed_{seed})_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/evals/{dataset}\",\n",
    "        (\"FINETUNE\", \"XLMRL + CONTEXT\"): lambda seed: base_folder / f\"experiments/corpus_sentence_xlmrl_context_finetune/an_wh_rs_False_dpt_0_emb_xlm-roberta-large-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/{dataset}\",\n",
    "        (\"LSTM CRF\", \"BETO\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_lstm_crf/an_wh_rs_False_dpt_0_emb_beto_Ly_all_mean_seed_{seed}_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/{dataset}\",\n",
    "        (\"LSTM CRF\", \"BETO + CONTEXT\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_lstm_crf/an_wh_rs_False_dpt_0_emb_beto_Ly_all_mean_context_seed_{seed}_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/{dataset}\",        \n",
    "        (\"LSTM CRF\", \"BETO + WE\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_we_lstm_crf/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto_Ly_all_mean_seed_{seed})_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/{dataset}\",\n",
    "        (\"LSTM CRF\", \"BETO + WE + CONTEXT\"): lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_we_lstm_crf/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto_Ly_all_mean_context_seed_{seed})_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/{dataset}\",\n",
    "        (\"LSTM CRF\", \"FLAIR\"): lambda seed: base_folder / f\"experiments/corpus_sentence_flair_lstm_crf/an_wh_rs_True_dpt_0.08716810045694838_emb_seed_{seed}_Stack(0_lm-es-forward.pt, 1_lm-es-backward.pt)_hdn_sz_256_lr_0.1_it_150_bs_4_opti_SGD_pjct_emb_True_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/{dataset}\",\n",
    "    }\n",
    "    dfs_all = {k: get_scores_as_df_with_seed(v).T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, [f\"{metric}\"]], :] for k,v in get_folders_all.items()}\n",
    "\n",
    "\n",
    "    get_scores_as_df_with_seed = partial(get_scores_as_df,  [1, 10, 25, 33, 42])\n",
    "    get_folders_flair = {\n",
    "        (\"LSTM CRF\", \"FLAIR + WE\"): lambda seed: base_folder / f\"experiments/corpus_sentence_flair_we_lstm_crf/results_seed_{seed}/evals/{dataset}\",\n",
    "    }\n",
    "    dfs_flair = {k: get_scores_as_df_with_seed(v).T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, [f\"{metric}\"]], :] for k,v in get_folders_flair.items()}\n",
    "\n",
    "    dfs = {**dfs_all, **dfs_flair}\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = get_results(); dfs[(\"FINETUNE\", \"BETO\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "762ba670",
   "metadata": {},
   "source": [
    "Definimos la función ``visualize_df`` para visualizar los resultados con un mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab55858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib import colors\n",
    "\n",
    "def make_pretty(styler):\n",
    "    styler.set_table_styles([\n",
    "        {'selector': '.index_name', 'props': 'font-style: italic; color: darkgrey; font-weight:normal;'},\n",
    "        {'selector': 'th.level1', 'props': 'text-align: left;'},\n",
    "        {'selector': 'th.level0', 'props': 'text-align: center;'},\n",
    "        {'selector': 'th.col_heading', 'props': 'text-align: center;'},\n",
    "        {'selector': 'th.col_heading.level0', 'props': 'font-size: 1.5em;'},\n",
    "        {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "    ], overwrite=False)\n",
    "    # .set_caption(\"Ajuste fino evaluado con distintas métricas\")\n",
    "    styler.hide(axis=\"index\", level=2)\n",
    "    styler.hide(axis=\"columns\", level=1)\n",
    "    styler.format(precision=2)\n",
    "    return styler\n",
    "\n",
    "def visualize_df(df: pd.DataFrame):\n",
    "    # Get the text that will be display in the form mean plus minus std\n",
    "    std = (df*100).iloc[1::2, ::].round(2).astype(str).droplevel(2)\n",
    "    mean = (df*100).iloc[::2, ::].round(2).astype(str).droplevel(2)\n",
    "    df_txt = (mean + \" \\u00b1 \" + std)\n",
    "\n",
    "    # Extract the mean value that will serve to create the gradient map\n",
    "    background_df = df.iloc[::2, ::]\n",
    "\n",
    "    def b_g(s, cmap='PuBu', low=0, high=0):\n",
    "        # Taken from https://stackoverflow.com/questions/47391948/pandas-style-background-gradient-using-other-dataframe\n",
    "        nonlocal background_df\n",
    "        # Pass the columns from Dataframe background_df\n",
    "        a = background_df.loc[:,s.name].copy()\n",
    "        rng = a.max() - a.min()\n",
    "        norm = colors.Normalize(a.min() - (rng * low), a.max() + (rng * high))\n",
    "        normed = norm(a.values)\n",
    "        c = [colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed*0.9)]\n",
    "        return ['background-color: %s' % color for color in c]\n",
    "\n",
    "    return df_txt.style.apply(b_g, cmap='plasma').pipe(make_pretty)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "babe6684",
   "metadata": {},
   "source": [
    "Ahora podemos visualizar una tabla donde nuestros experimentos se pueden comparar fácilmente por una métrica dada, aquí el escore $F_{1 micro}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c85b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = pd.concat(dfs.values(), axis=1, keys=dfs.keys(), names=[\"Embedding\", \"Estrategia\"]).T\n",
    "df_results_test = visualize_df(result_metrics); df_results_test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2822cd66",
   "metadata": {},
   "source": [
    "Ahora volvemos a un poco de teoría rápida"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8060399d",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4775b-60ee-4826-a104-bef8e328c0c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "### Transfert learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38ec0f-ce39-4a05-bb43-700a3cf05bbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Comparación entre el aprendizaje supervisado tradicional (izquierda) y el transfer learning (derecha)\n",
    "\n",
    "![transfer-learning](../cdti/figures/transformers-1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94d46c6c",
   "metadata": {},
   "source": [
    "### Arquitecturas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e208e-9350-4ede-b5f5-3034ad78d4b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* **baseline**\n",
    "\n",
    "    * Flair + LSTM +CRF (+ we)\n",
    "\n",
    "* **2 enfoques para el NER basados en Transformers con la arquitectura Flert**\n",
    "\n",
    "    > :pencil: Usamos 2 modelos, **Beto** y **XLM-Roberta**\n",
    "\n",
    "    * Finetuning + linear transformation (+ we)\n",
    "    * Caractéristica + LSTM + CRF (+ we)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099383c-7a74-43e5-a496-5fa4359952ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Entrenamiento: **Flair + LSTM-CRF**\n",
    "\n",
    "![training flair](../cdti/figures/flair-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a834072-2a10-46ad-9727-cc503f35173e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* procedimiento de entrenamiento\n",
    "\n",
    "\n",
    "|     Parameter      |       Value       |\n",
    "| :----------------: | :---------------: |\n",
    "|   Learning rate    |        0.1        |\n",
    "|  Mini Batch size   |         4         |\n",
    "|     Max epochs     |        150        |\n",
    "|     Optimizer      |        SGD        |\n",
    "|     Scheduler      | Anneal On Plateau |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87615515",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        (\"LSTM CRF\", \"FLAIR\"): dfs[(\"LSTM CRF\", \"FLAIR\")],\n",
    "        (\"LSTM CRF\", \"+ WE\"): dfs[(\"LSTM CRF\", \"FLAIR + WE\")],\n",
    "    }\n",
    "df = pd.concat(data.values(), axis=1, keys=data.keys(), names=[\"Estrategia\", \"Embeddings\"]).T\n",
    "visualize_df(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e449cc1a",
   "metadata": {},
   "source": [
    "* **Flert**\n",
    "\n",
    "![Flert architecture](../cdti/figures/flert-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad456aaf-7cd0-4a49-9226-454a5e886ba2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Entrenamiento: **Método de ajuste fino**\n",
    "\n",
    " Agrupación de subpalabras para crear representaciones a nivel de tokens que luego se pasan a la capa lineal final\n",
    "![training finetuning](../cdti/figures/flert-2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88342b34-1da3-4271-9b70-faf1567d9eb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* BETO\n",
    "\n",
    "|     Parameter      |              Value              |\n",
    "| :----------------: | :-----------------------------: |\n",
    "| Transformer layers |              last               |\n",
    "|   Learning rate    |              5e-6               |\n",
    "|  Mini Batch size   |                4                |\n",
    "|     Max epochs     |               150               |\n",
    "|     Optimizer      |              AdamW              |\n",
    "|     Scheduler      | Linear Warmup With Linear Decay |\n",
    "|       Warmup       |               0.1               |\n",
    "|  Subword pooling   |              first              |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3bc8b23-bcf2-48ff-9856-155402cbba93",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* XLM RoBERTa Large\n",
    "\n",
    "|     Parameter      |              Value              |\n",
    "| :----------------: | :-----------------------------: |\n",
    "| Transformer layers |              last               |\n",
    "|   Learning rate    |              5e-6               |\n",
    "|  Mini Batch size   |                4                |\n",
    "|     Max epochs     |               40                |\n",
    "|     Optimizer      |              AdamW              |\n",
    "|     Scheduler      | Linear Warmup With Linear Decay |\n",
    "|       Warmup       |               0.1               |\n",
    "|  Subword pooling   |              first              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        (\"XLMR LARGE\", \"Transformador lineal\"): dfs[(\"FINETUNE\", \"XLMRL\")],\n",
    "        (\"XLMR LARGE\", \"+ Context\"): dfs[(\"FINETUNE\", \"XLMRL + CONTEXT\")],\n",
    "        (\"XLMR LARGE\", \"+ WE\"): dfs[(\"FINETUNE\", \"XLMRL + WE\")],\n",
    "        (\"BETO\", \"Transformador lineal\"): dfs[(\"FINETUNE\", \"BETO\")],\n",
    "        (\"BETO\", \"+ Context\"): dfs[(\"FINETUNE\", \"BETO + CONTEXT\")],\n",
    "        (\"BETO\", \"+ WE\"): dfs[(\"FINETUNE\", \"BETO + WE\")],\n",
    "        (\"BETO\", \"+ WE + Context\"): dfs[(\"FINETUNE\", \"BETO + WE + CONTEXT\")],\n",
    "    }\n",
    "df = pd.concat(data.values(), axis=1, keys=data.keys(), names=[\"Transformador\", \"Estrategia\"]).T\n",
    "visualize_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde6be7-4a38-444d-9599-c28771c22398",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Entrenamiento: **Método basado en características**\n",
    "\n",
    "Hacemos una media de las 4 ultimas capas\n",
    "\n",
    "![training feature based](../cdti/figures/flert-3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4db9885-8b1e-4cd2-9e90-d3a07514cdf1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Procedimiento de entrenamiento\n",
    "\n",
    "|     Parameter      |       Value       |\n",
    "| :----------------: | :---------------: |\n",
    "|   Learning rate    |        0.1        |\n",
    "|  Mini Batch size   |         4         |\n",
    "|     Max epochs     |        150        |\n",
    "|     Optimizer      |        SGD        |\n",
    "|     Scheduler      | Anneal On Plateau |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        (\"LSTM CRF\", \"BETO (Ultimas 4 capas)\"): dfs[(\"LSTM CRF\", \"BETO\")],\n",
    "        (\"LSTM CRF\", \"+ Context\"): dfs[(\"LSTM CRF\", \"BETO + CONTEXT\")],\n",
    "        (\"LSTM CRF\", \"+ WE\"): dfs[(\"LSTM CRF\", \"BETO + WE\")],\n",
    "        (\"LSTM CRF\", \"+ WE + Context\"): dfs[(\"LSTM CRF\", \"BETO + WE + CONTEXT\")],\n",
    "    }\n",
    "df = pd.concat(data.values(), axis=1, keys=data.keys(), names=[\"Estrategia\", \"computation\"]).T\n",
    "visualize_df(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5ca80a5",
   "metadata": {},
   "source": [
    "> :pencil: No hemos probado con XLM-Roberta por falta de recursos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a7753c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097418b-93f1-4515-bb78-a1f45876bc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kill -9 $(ps aux | grep 'tensorboard' | awk {'print$2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0cb87-d85d-441e-9839-ba3c68bf5ff8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Entrenamiento: Método basado en características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f814a8-1d36-418e-af57-1b28144ce767",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db66d5c-7130-4ed8-9003-f3587583d3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd .. && bash scripts/test-cov.sh"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "0f89559bc32b8577479c9159291558d358fde821c77c8596ffd3d3e81e733cec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
