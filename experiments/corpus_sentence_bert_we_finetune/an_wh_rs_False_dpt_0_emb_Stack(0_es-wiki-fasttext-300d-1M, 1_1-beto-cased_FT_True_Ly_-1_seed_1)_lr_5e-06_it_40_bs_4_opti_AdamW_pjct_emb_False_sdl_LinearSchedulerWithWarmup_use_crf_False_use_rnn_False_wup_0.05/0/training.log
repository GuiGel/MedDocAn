2022-09-13 09:27:51,355 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,357 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'es'
      (embedding): Embedding(985667, 300)
      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=False)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1068, out_features=89, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2022-09-13 09:27:51,357 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,357 Corpus: "Corpus: 10311 train + 5268 dev + 5155 test sentences"
2022-09-13 09:27:51,357 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,357 Parameters:
2022-09-13 09:27:51,358  - learning_rate: "0.000005"
2022-09-13 09:27:51,358  - mini_batch_size: "4"
2022-09-13 09:27:51,358  - patience: "3"
2022-09-13 09:27:51,358  - anneal_factor: "0.5"
2022-09-13 09:27:51,358  - max_epochs: "40"
2022-09-13 09:27:51,358  - shuffle: "True"
2022-09-13 09:27:51,358  - train_with_dev: "False"
2022-09-13 09:27:51,358  - batch_growth_annealing: "False"
2022-09-13 09:27:51,358 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,358 Model training base path: "experiments/corpus_sentence_bert_we_finetune/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_1)_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0"
2022-09-13 09:27:51,358 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,358 Device: cuda:1
2022-09-13 09:27:51,358 ----------------------------------------------------------------------------------------------------
2022-09-13 09:27:51,358 Embeddings storage mode: gpu
2022-09-13 09:27:51,358 ----------------------------------------------------------------------------------------------------
2022-09-13 09:29:12,135 epoch 1 - iter 257/2578 - loss 4.86705695 - samples/sec: 12.73 - lr: 0.000000
2022-09-13 09:30:34,221 epoch 1 - iter 514/2578 - loss 4.64415643 - samples/sec: 12.53 - lr: 0.000000
2022-09-13 09:32:05,484 epoch 1 - iter 771/2578 - loss 4.12723234 - samples/sec: 11.27 - lr: 0.000001
2022-09-13 09:33:37,552 epoch 1 - iter 1028/2578 - loss 3.38239818 - samples/sec: 11.17 - lr: 0.000001
2022-09-13 09:34:59,992 epoch 1 - iter 1285/2578 - loss 2.92479834 - samples/sec: 12.47 - lr: 0.000001
2022-09-13 09:36:30,019 epoch 1 - iter 1542/2578 - loss 2.53120529 - samples/sec: 11.42 - lr: 0.000001
2022-09-13 09:37:49,269 epoch 1 - iter 1799/2578 - loss 2.27200647 - samples/sec: 12.97 - lr: 0.000002
2022-09-13 09:39:17,739 epoch 1 - iter 2056/2578 - loss 2.03930157 - samples/sec: 11.62 - lr: 0.000002
2022-09-13 09:40:48,133 epoch 1 - iter 2313/2578 - loss 1.85374969 - samples/sec: 11.37 - lr: 0.000002
2022-09-13 09:42:11,188 epoch 1 - iter 2570/2578 - loss 1.72870050 - samples/sec: 12.38 - lr: 0.000002
2022-09-13 09:42:14,231 ----------------------------------------------------------------------------------------------------
2022-09-13 09:42:14,231 EPOCH 1 done: loss 1.7229 - lr 0.000002
2022-09-13 09:43:58,499 Evaluating as a multi-label problem: False
2022-09-13 09:43:58,556 DEV : loss 0.15601447224617004 - f1-score (micro avg)  0.7686
2022-09-13 09:43:58,915 BAD EPOCHS (no improvement): 4
2022-09-13 09:43:58,920 saving best model
2022-09-13 09:44:02,247 ----------------------------------------------------------------------------------------------------
2022-09-13 09:45:40,042 epoch 2 - iter 257/2578 - loss 0.39828203 - samples/sec: 10.51 - lr: 0.000003
2022-09-13 09:47:09,920 epoch 2 - iter 514/2578 - loss 0.39099111 - samples/sec: 11.44 - lr: 0.000003
2022-09-13 09:48:42,532 epoch 2 - iter 771/2578 - loss 0.37796329 - samples/sec: 11.10 - lr: 0.000003
2022-09-13 09:49:23,327 epoch 2 - iter 1028/2578 - loss 0.35995961 - samples/sec: 25.21 - lr: 0.000003
2022-09-13 09:49:59,996 epoch 2 - iter 1285/2578 - loss 0.35204076 - samples/sec: 28.05 - lr: 0.000004
2022-09-13 09:50:35,643 epoch 2 - iter 1542/2578 - loss 0.34543990 - samples/sec: 28.85 - lr: 0.000004
2022-09-13 09:51:12,618 epoch 2 - iter 1799/2578 - loss 0.34192467 - samples/sec: 27.81 - lr: 0.000004
2022-09-13 09:51:51,092 epoch 2 - iter 2056/2578 - loss 0.33516648 - samples/sec: 26.73 - lr: 0.000004
2022-09-13 09:52:28,432 epoch 2 - iter 2313/2578 - loss 0.32902468 - samples/sec: 27.54 - lr: 0.000005
2022-09-13 09:53:05,883 epoch 2 - iter 2570/2578 - loss 0.32506434 - samples/sec: 27.46 - lr: 0.000005
2022-09-13 09:53:06,963 ----------------------------------------------------------------------------------------------------
2022-09-13 09:53:06,964 EPOCH 2 done: loss 0.3255 - lr 0.000005
2022-09-13 09:53:57,587 Evaluating as a multi-label problem: False
2022-09-13 09:53:57,641 DEV : loss 0.054901327937841415 - f1-score (micro avg)  0.9021
2022-09-13 09:53:58,016 BAD EPOCHS (no improvement): 4
2022-09-13 09:53:58,019 saving best model
2022-09-13 09:54:09,443 ----------------------------------------------------------------------------------------------------
2022-09-13 09:54:47,283 epoch 3 - iter 257/2578 - loss 0.25758971 - samples/sec: 27.18 - lr: 0.000005
2022-09-13 09:55:25,583 epoch 3 - iter 514/2578 - loss 0.26586619 - samples/sec: 26.85 - lr: 0.000005
2022-09-13 09:56:04,467 epoch 3 - iter 771/2578 - loss 0.26761479 - samples/sec: 26.45 - lr: 0.000005
2022-09-13 09:56:43,016 epoch 3 - iter 1028/2578 - loss 0.27162537 - samples/sec: 26.68 - lr: 0.000005
2022-09-13 09:57:19,334 epoch 3 - iter 1285/2578 - loss 0.27296191 - samples/sec: 28.32 - lr: 0.000005
2022-09-13 09:57:56,269 epoch 3 - iter 1542/2578 - loss 0.27219432 - samples/sec: 27.84 - lr: 0.000005
2022-09-13 09:58:33,890 epoch 3 - iter 1799/2578 - loss 0.27090375 - samples/sec: 27.33 - lr: 0.000005
2022-09-13 09:59:10,987 epoch 3 - iter 2056/2578 - loss 0.27149698 - samples/sec: 27.72 - lr: 0.000005
2022-09-13 09:59:49,339 epoch 3 - iter 2313/2578 - loss 0.27034523 - samples/sec: 26.81 - lr: 0.000005
2022-09-13 10:00:28,512 epoch 3 - iter 2570/2578 - loss 0.26984434 - samples/sec: 26.25 - lr: 0.000005
2022-09-13 10:00:29,803 ----------------------------------------------------------------------------------------------------
2022-09-13 10:00:29,804 EPOCH 3 done: loss 0.2698 - lr 0.000005
2022-09-13 10:01:20,681 Evaluating as a multi-label problem: False
2022-09-13 10:01:20,733 DEV : loss 0.038663093000650406 - f1-score (micro avg)  0.9347
2022-09-13 10:01:21,104 BAD EPOCHS (no improvement): 4
2022-09-13 10:01:21,108 saving best model
2022-09-13 10:01:32,570 ----------------------------------------------------------------------------------------------------
2022-09-13 10:02:10,582 epoch 4 - iter 257/2578 - loss 0.24357612 - samples/sec: 27.06 - lr: 0.000005
2022-09-13 10:02:48,131 epoch 4 - iter 514/2578 - loss 0.24540567 - samples/sec: 27.39 - lr: 0.000005
2022-09-13 10:03:28,523 epoch 4 - iter 771/2578 - loss 0.24532586 - samples/sec: 25.46 - lr: 0.000005
2022-09-13 10:04:08,482 epoch 4 - iter 1028/2578 - loss 0.24578240 - samples/sec: 25.74 - lr: 0.000005
2022-09-13 10:04:46,107 epoch 4 - iter 1285/2578 - loss 0.24764053 - samples/sec: 27.33 - lr: 0.000005
2022-09-13 10:05:23,768 epoch 4 - iter 1542/2578 - loss 0.24826260 - samples/sec: 27.31 - lr: 0.000005
2022-09-13 10:05:59,681 epoch 4 - iter 1799/2578 - loss 0.24886113 - samples/sec: 28.64 - lr: 0.000005
2022-09-13 10:06:37,646 epoch 4 - iter 2056/2578 - loss 0.24802150 - samples/sec: 27.09 - lr: 0.000005
2022-09-13 10:07:14,387 epoch 4 - iter 2313/2578 - loss 0.24717788 - samples/sec: 27.99 - lr: 0.000005
2022-09-13 10:07:51,257 epoch 4 - iter 2570/2578 - loss 0.24845638 - samples/sec: 27.89 - lr: 0.000005
2022-09-13 10:07:52,393 ----------------------------------------------------------------------------------------------------
2022-09-13 10:07:52,394 EPOCH 4 done: loss 0.2485 - lr 0.000005
2022-09-13 10:08:43,224 Evaluating as a multi-label problem: False
2022-09-13 10:08:43,277 DEV : loss 0.032431986182928085 - f1-score (micro avg)  0.9514
2022-09-13 10:08:43,666 BAD EPOCHS (no improvement): 4
2022-09-13 10:08:43,671 saving best model
2022-09-13 10:08:55,541 ----------------------------------------------------------------------------------------------------
2022-09-13 10:09:32,361 epoch 5 - iter 257/2578 - loss 0.24171837 - samples/sec: 27.93 - lr: 0.000005
2022-09-13 10:10:11,038 epoch 5 - iter 514/2578 - loss 0.23975205 - samples/sec: 26.59 - lr: 0.000005
2022-09-13 10:10:48,847 epoch 5 - iter 771/2578 - loss 0.23968688 - samples/sec: 27.20 - lr: 0.000005
2022-09-13 10:11:26,873 epoch 5 - iter 1028/2578 - loss 0.24085148 - samples/sec: 27.04 - lr: 0.000005
2022-09-13 10:12:03,093 epoch 5 - iter 1285/2578 - loss 0.24233609 - samples/sec: 28.39 - lr: 0.000005
2022-09-13 10:12:41,843 epoch 5 - iter 1542/2578 - loss 0.24057435 - samples/sec: 26.54 - lr: 0.000005
2022-09-13 10:13:19,237 epoch 5 - iter 1799/2578 - loss 0.24205593 - samples/sec: 27.50 - lr: 0.000005
2022-09-13 10:13:58,933 epoch 5 - iter 2056/2578 - loss 0.24235743 - samples/sec: 25.91 - lr: 0.000005
2022-09-13 10:14:35,047 epoch 5 - iter 2313/2578 - loss 0.24256100 - samples/sec: 28.48 - lr: 0.000005
2022-09-13 10:15:12,875 epoch 5 - iter 2570/2578 - loss 0.24203070 - samples/sec: 27.19 - lr: 0.000005
2022-09-13 10:15:13,808 ----------------------------------------------------------------------------------------------------
2022-09-13 10:15:13,808 EPOCH 5 done: loss 0.2419 - lr 0.000005
2022-09-13 10:16:05,869 Evaluating as a multi-label problem: False
2022-09-13 10:16:05,927 DEV : loss 0.031122632324695587 - f1-score (micro avg)  0.9586
2022-09-13 10:16:06,330 BAD EPOCHS (no improvement): 4
2022-09-13 10:16:06,335 saving best model
2022-09-13 10:16:18,030 ----------------------------------------------------------------------------------------------------
2022-09-13 10:16:55,928 epoch 6 - iter 257/2578 - loss 0.24441938 - samples/sec: 27.14 - lr: 0.000005
2022-09-13 10:17:32,801 epoch 6 - iter 514/2578 - loss 0.24135531 - samples/sec: 27.89 - lr: 0.000005
2022-09-13 10:18:13,466 epoch 6 - iter 771/2578 - loss 0.23984223 - samples/sec: 25.29 - lr: 0.000005
2022-09-13 10:18:54,009 epoch 6 - iter 1028/2578 - loss 0.23545927 - samples/sec: 25.36 - lr: 0.000005
2022-09-13 10:19:31,451 epoch 6 - iter 1285/2578 - loss 0.23579719 - samples/sec: 27.47 - lr: 0.000005
2022-09-13 10:20:09,808 epoch 6 - iter 1542/2578 - loss 0.23752643 - samples/sec: 26.81 - lr: 0.000005
2022-09-13 10:20:47,535 epoch 6 - iter 1799/2578 - loss 0.23935300 - samples/sec: 27.26 - lr: 0.000005
2022-09-13 10:21:24,002 epoch 6 - iter 2056/2578 - loss 0.23897554 - samples/sec: 28.20 - lr: 0.000005
2022-09-13 10:21:58,809 epoch 6 - iter 2313/2578 - loss 0.23773464 - samples/sec: 29.55 - lr: 0.000004
2022-09-13 10:22:36,121 epoch 6 - iter 2570/2578 - loss 0.23752901 - samples/sec: 27.56 - lr: 0.000004
2022-09-13 10:22:37,399 ----------------------------------------------------------------------------------------------------
2022-09-13 10:22:37,399 EPOCH 6 done: loss 0.2375 - lr 0.000004
2022-09-13 10:23:27,763 Evaluating as a multi-label problem: False
2022-09-13 10:23:27,815 DEV : loss 0.02824694849550724 - f1-score (micro avg)  0.9649
2022-09-13 10:23:28,189 BAD EPOCHS (no improvement): 4
2022-09-13 10:23:28,193 saving best model
2022-09-13 10:23:39,625 ----------------------------------------------------------------------------------------------------
2022-09-13 10:24:16,183 epoch 7 - iter 257/2578 - loss 0.22153408 - samples/sec: 28.13 - lr: 0.000004
2022-09-13 10:24:53,012 epoch 7 - iter 514/2578 - loss 0.23017225 - samples/sec: 27.92 - lr: 0.000004
2022-09-13 10:25:31,241 epoch 7 - iter 771/2578 - loss 0.23433325 - samples/sec: 26.90 - lr: 0.000004
2022-09-13 10:26:09,977 epoch 7 - iter 1028/2578 - loss 0.23317473 - samples/sec: 26.55 - lr: 0.000004
2022-09-13 10:26:48,555 epoch 7 - iter 1285/2578 - loss 0.23345590 - samples/sec: 26.66 - lr: 0.000004
2022-09-13 10:27:25,643 epoch 7 - iter 1542/2578 - loss 0.23517115 - samples/sec: 27.73 - lr: 0.000004
2022-09-13 10:28:04,649 epoch 7 - iter 1799/2578 - loss 0.23484920 - samples/sec: 26.36 - lr: 0.000004
2022-09-13 10:28:41,412 epoch 7 - iter 2056/2578 - loss 0.23674752 - samples/sec: 27.97 - lr: 0.000004
2022-09-13 10:29:19,855 epoch 7 - iter 2313/2578 - loss 0.23556446 - samples/sec: 26.75 - lr: 0.000004
2022-09-13 10:29:58,925 epoch 7 - iter 2570/2578 - loss 0.23425090 - samples/sec: 26.32 - lr: 0.000004
2022-09-13 10:30:00,128 ----------------------------------------------------------------------------------------------------
2022-09-13 10:30:00,128 EPOCH 7 done: loss 0.2343 - lr 0.000004
2022-09-13 10:30:50,909 Evaluating as a multi-label problem: False
2022-09-13 10:30:50,962 DEV : loss 0.02842571586370468 - f1-score (micro avg)  0.9664
2022-09-13 10:30:51,338 BAD EPOCHS (no improvement): 4
2022-09-13 10:30:51,342 saving best model
2022-09-13 10:31:02,903 ----------------------------------------------------------------------------------------------------
2022-09-13 10:31:40,682 epoch 8 - iter 257/2578 - loss 0.22227099 - samples/sec: 27.22 - lr: 0.000004
2022-09-13 10:32:19,598 epoch 8 - iter 514/2578 - loss 0.22919397 - samples/sec: 26.43 - lr: 0.000004
2022-09-13 10:32:58,868 epoch 8 - iter 771/2578 - loss 0.23070685 - samples/sec: 26.19 - lr: 0.000004
2022-09-13 10:33:35,035 epoch 8 - iter 1028/2578 - loss 0.23212893 - samples/sec: 28.43 - lr: 0.000004
2022-09-13 10:34:12,893 epoch 8 - iter 1285/2578 - loss 0.23001616 - samples/sec: 27.16 - lr: 0.000004
2022-09-13 10:34:47,638 epoch 8 - iter 1542/2578 - loss 0.23076665 - samples/sec: 29.60 - lr: 0.000004
2022-09-13 10:35:25,896 epoch 8 - iter 1799/2578 - loss 0.22973855 - samples/sec: 26.88 - lr: 0.000004
2022-09-13 10:36:04,310 epoch 8 - iter 2056/2578 - loss 0.23062697 - samples/sec: 26.77 - lr: 0.000004
2022-09-13 10:36:42,094 epoch 8 - iter 2313/2578 - loss 0.23079231 - samples/sec: 27.22 - lr: 0.000004
2022-09-13 10:37:19,645 epoch 8 - iter 2570/2578 - loss 0.23046077 - samples/sec: 27.39 - lr: 0.000004
2022-09-13 10:37:20,701 ----------------------------------------------------------------------------------------------------
2022-09-13 10:37:20,702 EPOCH 8 done: loss 0.2305 - lr 0.000004
2022-09-13 10:38:11,060 Evaluating as a multi-label problem: False
2022-09-13 10:38:11,112 DEV : loss 0.029025550931692123 - f1-score (micro avg)  0.9682
2022-09-13 10:38:11,480 BAD EPOCHS (no improvement): 4
2022-09-13 10:38:11,484 saving best model
2022-09-13 10:38:23,079 ----------------------------------------------------------------------------------------------------
2022-09-13 10:38:59,496 epoch 9 - iter 257/2578 - loss 0.23731868 - samples/sec: 28.24 - lr: 0.000004
2022-09-13 10:39:36,721 epoch 9 - iter 514/2578 - loss 0.23514032 - samples/sec: 27.63 - lr: 0.000004
2022-09-13 10:40:16,195 epoch 9 - iter 771/2578 - loss 0.23236924 - samples/sec: 26.05 - lr: 0.000004
2022-09-13 10:40:53,275 epoch 9 - iter 1028/2578 - loss 0.23333346 - samples/sec: 27.73 - lr: 0.000004
2022-09-13 10:41:33,947 epoch 9 - iter 1285/2578 - loss 0.23428438 - samples/sec: 25.28 - lr: 0.000004
2022-09-13 10:42:11,123 epoch 9 - iter 1542/2578 - loss 0.23238317 - samples/sec: 27.66 - lr: 0.000004
2022-09-13 10:42:49,802 epoch 9 - iter 1799/2578 - loss 0.23343459 - samples/sec: 26.59 - lr: 0.000004
2022-09-13 10:43:28,275 epoch 9 - iter 2056/2578 - loss 0.23242581 - samples/sec: 26.73 - lr: 0.000004
2022-09-13 10:44:05,546 epoch 9 - iter 2313/2578 - loss 0.23228888 - samples/sec: 27.59 - lr: 0.000004
2022-09-13 10:44:42,360 epoch 9 - iter 2570/2578 - loss 0.23253726 - samples/sec: 27.93 - lr: 0.000004
2022-09-13 10:44:43,199 ----------------------------------------------------------------------------------------------------
2022-09-13 10:44:43,200 EPOCH 9 done: loss 0.2325 - lr 0.000004
2022-09-13 10:45:33,641 Evaluating as a multi-label problem: False
2022-09-13 10:45:33,696 DEV : loss 0.029135489836335182 - f1-score (micro avg)  0.9683
2022-09-13 10:45:34,104 BAD EPOCHS (no improvement): 4
2022-09-13 10:45:34,109 saving best model
2022-09-13 10:45:45,615 ----------------------------------------------------------------------------------------------------
2022-09-13 10:46:21,768 epoch 10 - iter 257/2578 - loss 0.22531719 - samples/sec: 28.45 - lr: 0.000004
2022-09-13 10:46:59,190 epoch 10 - iter 514/2578 - loss 0.22080566 - samples/sec: 27.48 - lr: 0.000004
2022-09-13 10:47:35,873 epoch 10 - iter 771/2578 - loss 0.22257733 - samples/sec: 28.03 - lr: 0.000004
2022-09-13 10:48:15,012 epoch 10 - iter 1028/2578 - loss 0.22314922 - samples/sec: 26.27 - lr: 0.000004
2022-09-13 10:48:55,025 epoch 10 - iter 1285/2578 - loss 0.22272577 - samples/sec: 25.70 - lr: 0.000004
2022-09-13 10:49:33,020 epoch 10 - iter 1542/2578 - loss 0.22339685 - samples/sec: 27.07 - lr: 0.000004
2022-09-13 10:50:10,573 epoch 10 - iter 1799/2578 - loss 0.22412557 - samples/sec: 27.39 - lr: 0.000004
2022-09-13 10:50:48,840 epoch 10 - iter 2056/2578 - loss 0.22370452 - samples/sec: 26.87 - lr: 0.000004
2022-09-13 10:51:26,104 epoch 10 - iter 2313/2578 - loss 0.22412734 - samples/sec: 27.60 - lr: 0.000004
2022-09-13 10:52:04,879 epoch 10 - iter 2570/2578 - loss 0.22476163 - samples/sec: 26.52 - lr: 0.000004
2022-09-13 10:52:06,118 ----------------------------------------------------------------------------------------------------
2022-09-13 10:52:06,119 EPOCH 10 done: loss 0.2247 - lr 0.000004
2022-09-13 10:52:58,218 Evaluating as a multi-label problem: False
2022-09-13 10:52:58,269 DEV : loss 0.029278233647346497 - f1-score (micro avg)  0.971
2022-09-13 10:52:58,645 BAD EPOCHS (no improvement): 4
2022-09-13 10:52:58,649 saving best model
2022-09-13 10:53:10,119 ----------------------------------------------------------------------------------------------------
2022-09-13 10:53:46,478 epoch 11 - iter 257/2578 - loss 0.22759416 - samples/sec: 28.28 - lr: 0.000004
2022-09-13 10:54:24,091 epoch 11 - iter 514/2578 - loss 0.21938852 - samples/sec: 27.34 - lr: 0.000004
2022-09-13 10:55:00,805 epoch 11 - iter 771/2578 - loss 0.22425515 - samples/sec: 28.01 - lr: 0.000004
2022-09-13 10:55:38,962 epoch 11 - iter 1028/2578 - loss 0.22193513 - samples/sec: 26.95 - lr: 0.000004
2022-09-13 10:56:18,006 epoch 11 - iter 1285/2578 - loss 0.22395748 - samples/sec: 26.34 - lr: 0.000004
2022-09-13 10:56:56,963 epoch 11 - iter 1542/2578 - loss 0.22436828 - samples/sec: 26.40 - lr: 0.000004
2022-09-13 10:57:37,500 epoch 11 - iter 1799/2578 - loss 0.22555013 - samples/sec: 25.37 - lr: 0.000004
2022-09-13 10:58:14,104 epoch 11 - iter 2056/2578 - loss 0.22530075 - samples/sec: 28.09 - lr: 0.000004
2022-09-13 10:58:52,408 epoch 11 - iter 2313/2578 - loss 0.22424969 - samples/sec: 26.85 - lr: 0.000004
2022-09-13 10:59:28,738 epoch 11 - iter 2570/2578 - loss 0.22492245 - samples/sec: 28.31 - lr: 0.000004
2022-09-13 10:59:29,988 ----------------------------------------------------------------------------------------------------
2022-09-13 10:59:29,988 EPOCH 11 done: loss 0.2248 - lr 0.000004
2022-09-13 11:00:20,856 Evaluating as a multi-label problem: False
2022-09-13 11:00:20,908 DEV : loss 0.03011683188378811 - f1-score (micro avg)  0.9675
2022-09-13 11:00:21,284 BAD EPOCHS (no improvement): 4
2022-09-13 11:00:21,288 ----------------------------------------------------------------------------------------------------
2022-09-13 11:01:00,433 epoch 12 - iter 257/2578 - loss 0.22142587 - samples/sec: 26.28 - lr: 0.000004
2022-09-13 11:01:37,711 epoch 12 - iter 514/2578 - loss 0.22188778 - samples/sec: 27.59 - lr: 0.000004
2022-09-13 11:02:17,187 epoch 12 - iter 771/2578 - loss 0.22100701 - samples/sec: 26.05 - lr: 0.000004
2022-09-13 11:02:54,461 epoch 12 - iter 1028/2578 - loss 0.22235791 - samples/sec: 27.59 - lr: 0.000004
2022-09-13 11:03:30,195 epoch 12 - iter 1285/2578 - loss 0.22454966 - samples/sec: 28.78 - lr: 0.000004
2022-09-13 11:04:08,050 epoch 12 - iter 1542/2578 - loss 0.22621410 - samples/sec: 27.17 - lr: 0.000004
2022-09-13 11:04:44,921 epoch 12 - iter 1799/2578 - loss 0.22566852 - samples/sec: 27.89 - lr: 0.000004
2022-09-13 11:05:23,719 epoch 12 - iter 2056/2578 - loss 0.22428814 - samples/sec: 26.51 - lr: 0.000004
2022-09-13 11:06:02,806 epoch 12 - iter 2313/2578 - loss 0.22532868 - samples/sec: 26.31 - lr: 0.000004
2022-09-13 11:06:41,702 epoch 12 - iter 2570/2578 - loss 0.22488601 - samples/sec: 26.44 - lr: 0.000004
2022-09-13 11:06:43,024 ----------------------------------------------------------------------------------------------------
2022-09-13 11:06:43,024 EPOCH 12 done: loss 0.2249 - lr 0.000004
2022-09-13 11:07:33,778 Evaluating as a multi-label problem: False
2022-09-13 11:07:33,829 DEV : loss 0.030672712251544 - f1-score (micro avg)  0.9693
2022-09-13 11:07:34,201 BAD EPOCHS (no improvement): 4
2022-09-13 11:07:34,206 ----------------------------------------------------------------------------------------------------
2022-09-13 11:08:14,098 epoch 13 - iter 257/2578 - loss 0.21674759 - samples/sec: 25.78 - lr: 0.000004
2022-09-13 11:08:54,125 epoch 13 - iter 514/2578 - loss 0.21909350 - samples/sec: 25.69 - lr: 0.000004
2022-09-13 11:09:31,170 epoch 13 - iter 771/2578 - loss 0.21894405 - samples/sec: 27.76 - lr: 0.000004
2022-09-13 11:10:06,882 epoch 13 - iter 1028/2578 - loss 0.22034130 - samples/sec: 28.80 - lr: 0.000004
2022-09-13 11:10:45,603 epoch 13 - iter 1285/2578 - loss 0.22077024 - samples/sec: 26.56 - lr: 0.000004
2022-09-13 11:11:22,014 epoch 13 - iter 1542/2578 - loss 0.22161272 - samples/sec: 28.24 - lr: 0.000004
2022-09-13 11:12:00,119 epoch 13 - iter 1799/2578 - loss 0.22141980 - samples/sec: 26.99 - lr: 0.000004
2022-09-13 11:12:40,019 epoch 13 - iter 2056/2578 - loss 0.22255094 - samples/sec: 25.77 - lr: 0.000004
2022-09-13 11:13:16,502 epoch 13 - iter 2313/2578 - loss 0.22238301 - samples/sec: 28.19 - lr: 0.000004
2022-09-13 11:13:54,365 epoch 13 - iter 2570/2578 - loss 0.22166666 - samples/sec: 27.16 - lr: 0.000004
2022-09-13 11:13:55,443 ----------------------------------------------------------------------------------------------------
2022-09-13 11:13:55,444 EPOCH 13 done: loss 0.2218 - lr 0.000004
2022-09-13 11:14:46,624 Evaluating as a multi-label problem: False
2022-09-13 11:14:46,676 DEV : loss 0.03179657459259033 - f1-score (micro avg)  0.9703
2022-09-13 11:14:47,047 BAD EPOCHS (no improvement): 4
2022-09-13 11:14:47,051 ----------------------------------------------------------------------------------------------------
2022-09-13 11:15:23,551 epoch 14 - iter 257/2578 - loss 0.22571911 - samples/sec: 28.18 - lr: 0.000004
2022-09-13 11:16:01,249 epoch 14 - iter 514/2578 - loss 0.22278196 - samples/sec: 27.28 - lr: 0.000004
2022-09-13 11:16:37,144 epoch 14 - iter 771/2578 - loss 0.22124334 - samples/sec: 28.65 - lr: 0.000004
2022-09-13 11:17:14,291 epoch 14 - iter 1028/2578 - loss 0.22110895 - samples/sec: 27.68 - lr: 0.000004
2022-09-13 11:17:52,904 epoch 14 - iter 1285/2578 - loss 0.22081822 - samples/sec: 26.63 - lr: 0.000003
2022-09-13 11:18:28,771 epoch 14 - iter 1542/2578 - loss 0.21985778 - samples/sec: 28.67 - lr: 0.000003
2022-09-13 11:19:08,145 epoch 14 - iter 1799/2578 - loss 0.22011074 - samples/sec: 26.12 - lr: 0.000003
2022-09-13 11:19:47,370 epoch 14 - iter 2056/2578 - loss 0.21979723 - samples/sec: 26.22 - lr: 0.000003
2022-09-13 11:20:26,986 epoch 14 - iter 2313/2578 - loss 0.21903441 - samples/sec: 25.96 - lr: 0.000003
2022-09-13 11:21:07,466 epoch 14 - iter 2570/2578 - loss 0.21772412 - samples/sec: 25.40 - lr: 0.000003
2022-09-13 11:21:08,696 ----------------------------------------------------------------------------------------------------
2022-09-13 11:21:08,696 EPOCH 14 done: loss 0.2178 - lr 0.000003
2022-09-13 11:21:59,621 Evaluating as a multi-label problem: False
2022-09-13 11:21:59,672 DEV : loss 0.0315636470913887 - f1-score (micro avg)  0.9702
2022-09-13 11:22:00,048 BAD EPOCHS (no improvement): 4
2022-09-13 11:22:00,052 ----------------------------------------------------------------------------------------------------
2022-09-13 11:22:38,828 epoch 15 - iter 257/2578 - loss 0.21328579 - samples/sec: 26.53 - lr: 0.000003
2022-09-13 11:23:16,326 epoch 15 - iter 514/2578 - loss 0.21790679 - samples/sec: 27.42 - lr: 0.000003
2022-09-13 11:23:51,163 epoch 15 - iter 771/2578 - loss 0.21845318 - samples/sec: 29.52 - lr: 0.000003
2022-09-13 11:24:31,837 epoch 15 - iter 1028/2578 - loss 0.21718482 - samples/sec: 25.28 - lr: 0.000003
2022-09-13 11:25:12,628 epoch 15 - iter 1285/2578 - loss 0.21598988 - samples/sec: 25.21 - lr: 0.000003
2022-09-13 11:25:49,137 epoch 15 - iter 1542/2578 - loss 0.21627336 - samples/sec: 28.17 - lr: 0.000003
2022-09-13 11:26:23,884 epoch 15 - iter 1799/2578 - loss 0.21671187 - samples/sec: 29.60 - lr: 0.000003
2022-09-13 11:26:59,556 epoch 15 - iter 2056/2578 - loss 0.21705425 - samples/sec: 28.83 - lr: 0.000003
2022-09-13 11:27:38,445 epoch 15 - iter 2313/2578 - loss 0.21788611 - samples/sec: 26.44 - lr: 0.000003
2022-09-13 11:28:18,260 epoch 15 - iter 2570/2578 - loss 0.21805346 - samples/sec: 25.83 - lr: 0.000003
2022-09-13 11:28:19,288 ----------------------------------------------------------------------------------------------------
2022-09-13 11:28:19,288 EPOCH 15 done: loss 0.2180 - lr 0.000003
2022-09-13 11:29:09,949 Evaluating as a multi-label problem: False
2022-09-13 11:29:10,002 DEV : loss 0.03365728259086609 - f1-score (micro avg)  0.9688
2022-09-13 11:29:10,337 BAD EPOCHS (no improvement): 4
2022-09-13 11:29:10,385 ----------------------------------------------------------------------------------------------------
2022-09-13 11:29:47,986 epoch 16 - iter 257/2578 - loss 0.21677764 - samples/sec: 27.35 - lr: 0.000003
2022-09-13 11:30:26,267 epoch 16 - iter 514/2578 - loss 0.21816829 - samples/sec: 26.86 - lr: 0.000003
2022-09-13 11:31:03,260 epoch 16 - iter 771/2578 - loss 0.22080775 - samples/sec: 27.80 - lr: 0.000003
2022-09-13 11:31:41,390 epoch 16 - iter 1028/2578 - loss 0.21769546 - samples/sec: 26.97 - lr: 0.000003
2022-09-13 11:32:17,786 epoch 16 - iter 1285/2578 - loss 0.21900315 - samples/sec: 28.25 - lr: 0.000003
2022-09-13 11:32:56,388 epoch 16 - iter 1542/2578 - loss 0.21903442 - samples/sec: 26.64 - lr: 0.000003
2022-09-13 11:33:32,350 epoch 16 - iter 1799/2578 - loss 0.21861038 - samples/sec: 28.60 - lr: 0.000003
2022-09-13 11:34:10,099 epoch 16 - iter 2056/2578 - loss 0.21891897 - samples/sec: 27.24 - lr: 0.000003
2022-09-13 11:34:49,375 epoch 16 - iter 2313/2578 - loss 0.21764550 - samples/sec: 26.18 - lr: 0.000003
2022-09-13 11:35:27,833 epoch 16 - iter 2570/2578 - loss 0.21875760 - samples/sec: 26.74 - lr: 0.000003
2022-09-13 11:35:28,856 ----------------------------------------------------------------------------------------------------
2022-09-13 11:35:28,857 EPOCH 16 done: loss 0.2187 - lr 0.000003
2022-09-13 11:36:20,292 Evaluating as a multi-label problem: False
2022-09-13 11:36:20,344 DEV : loss 0.03316093608736992 - f1-score (micro avg)  0.9695
2022-09-13 11:36:20,713 BAD EPOCHS (no improvement): 4
2022-09-13 11:36:20,717 ----------------------------------------------------------------------------------------------------
2022-09-13 11:36:58,710 epoch 17 - iter 257/2578 - loss 0.22273968 - samples/sec: 27.07 - lr: 0.000003
2022-09-13 11:37:33,766 epoch 17 - iter 514/2578 - loss 0.22203360 - samples/sec: 29.33 - lr: 0.000003
2022-09-13 11:38:12,667 epoch 17 - iter 771/2578 - loss 0.21906652 - samples/sec: 26.44 - lr: 0.000003
2022-09-13 11:38:50,220 epoch 17 - iter 1028/2578 - loss 0.21840960 - samples/sec: 27.38 - lr: 0.000003
2022-09-13 11:39:26,858 epoch 17 - iter 1285/2578 - loss 0.21751755 - samples/sec: 28.07 - lr: 0.000003
2022-09-13 11:40:05,346 epoch 17 - iter 1542/2578 - loss 0.21948794 - samples/sec: 26.72 - lr: 0.000003
2022-09-13 11:40:45,316 epoch 17 - iter 1799/2578 - loss 0.21965142 - samples/sec: 25.73 - lr: 0.000003
2022-09-13 11:41:23,229 epoch 17 - iter 2056/2578 - loss 0.21919531 - samples/sec: 27.12 - lr: 0.000003
2022-09-13 11:42:01,257 epoch 17 - iter 2313/2578 - loss 0.21855916 - samples/sec: 27.04 - lr: 0.000003
2022-09-13 11:42:39,088 epoch 17 - iter 2570/2578 - loss 0.21923201 - samples/sec: 27.18 - lr: 0.000003
2022-09-13 11:42:40,263 ----------------------------------------------------------------------------------------------------
2022-09-13 11:42:40,264 EPOCH 17 done: loss 0.2191 - lr 0.000003
2022-09-13 11:43:30,849 Evaluating as a multi-label problem: False
2022-09-13 11:43:30,901 DEV : loss 0.03296395763754845 - f1-score (micro avg)  0.9693
2022-09-13 11:43:31,278 BAD EPOCHS (no improvement): 4
2022-09-13 11:43:31,283 ----------------------------------------------------------------------------------------------------
2022-09-13 11:44:08,229 epoch 18 - iter 257/2578 - loss 0.22787217 - samples/sec: 27.84 - lr: 0.000003
2022-09-13 11:44:43,921 epoch 18 - iter 514/2578 - loss 0.22426038 - samples/sec: 28.81 - lr: 0.000003
2022-09-13 11:45:23,916 epoch 18 - iter 771/2578 - loss 0.22036889 - samples/sec: 25.71 - lr: 0.000003
2022-09-13 11:46:03,364 epoch 18 - iter 1028/2578 - loss 0.22032981 - samples/sec: 26.07 - lr: 0.000003
2022-09-13 11:46:41,980 epoch 18 - iter 1285/2578 - loss 0.22060776 - samples/sec: 26.63 - lr: 0.000003
2022-09-13 11:47:19,986 epoch 18 - iter 1542/2578 - loss 0.22117021 - samples/sec: 27.06 - lr: 0.000003
2022-09-13 11:47:56,042 epoch 18 - iter 1799/2578 - loss 0.22082440 - samples/sec: 28.52 - lr: 0.000003
2022-09-13 11:48:31,628 epoch 18 - iter 2056/2578 - loss 0.22067147 - samples/sec: 28.90 - lr: 0.000003
2022-09-13 11:49:10,315 epoch 18 - iter 2313/2578 - loss 0.21967244 - samples/sec: 26.58 - lr: 0.000003
2022-09-13 11:49:49,224 epoch 18 - iter 2570/2578 - loss 0.22066672 - samples/sec: 26.43 - lr: 0.000003
2022-09-13 11:49:50,562 ----------------------------------------------------------------------------------------------------
2022-09-13 11:49:50,562 EPOCH 18 done: loss 0.2207 - lr 0.000003
2022-09-13 11:50:41,200 Evaluating as a multi-label problem: False
2022-09-13 11:50:41,253 DEV : loss 0.033959969878196716 - f1-score (micro avg)  0.9683
2022-09-13 11:50:41,625 BAD EPOCHS (no improvement): 4
2022-09-13 11:50:41,630 ----------------------------------------------------------------------------------------------------
2022-09-13 11:51:17,727 epoch 19 - iter 257/2578 - loss 0.21142215 - samples/sec: 28.50 - lr: 0.000003
2022-09-13 11:51:54,766 epoch 19 - iter 514/2578 - loss 0.20785311 - samples/sec: 27.76 - lr: 0.000003
2022-09-13 11:52:31,683 epoch 19 - iter 771/2578 - loss 0.21238629 - samples/sec: 27.86 - lr: 0.000003
2022-09-13 11:53:07,264 epoch 19 - iter 1028/2578 - loss 0.21301877 - samples/sec: 28.90 - lr: 0.000003
2022-09-13 11:53:44,724 epoch 19 - iter 1285/2578 - loss 0.21085000 - samples/sec: 27.45 - lr: 0.000003
2022-09-13 11:54:21,416 epoch 19 - iter 1542/2578 - loss 0.21185880 - samples/sec: 28.03 - lr: 0.000003
2022-09-13 11:55:03,301 epoch 19 - iter 1799/2578 - loss 0.21216416 - samples/sec: 24.55 - lr: 0.000003
2022-09-13 11:55:41,736 epoch 19 - iter 2056/2578 - loss 0.21044904 - samples/sec: 26.76 - lr: 0.000003
2022-09-13 11:56:21,644 epoch 19 - iter 2313/2578 - loss 0.21000624 - samples/sec: 25.77 - lr: 0.000003
2022-09-13 11:56:59,364 epoch 19 - iter 2570/2578 - loss 0.21040036 - samples/sec: 27.26 - lr: 0.000003
2022-09-13 11:57:00,410 ----------------------------------------------------------------------------------------------------
2022-09-13 11:57:00,411 EPOCH 19 done: loss 0.2104 - lr 0.000003
2022-09-13 11:57:50,794 Evaluating as a multi-label problem: False
2022-09-13 11:57:50,845 DEV : loss 0.034170277416706085 - f1-score (micro avg)  0.9682
2022-09-13 11:57:51,216 BAD EPOCHS (no improvement): 4
2022-09-13 11:57:51,220 ----------------------------------------------------------------------------------------------------
2022-09-13 11:58:28,141 epoch 20 - iter 257/2578 - loss 0.22785486 - samples/sec: 27.86 - lr: 0.000003
2022-09-13 11:59:06,666 epoch 20 - iter 514/2578 - loss 0.21729715 - samples/sec: 26.69 - lr: 0.000003
2022-09-13 11:59:46,249 epoch 20 - iter 771/2578 - loss 0.21838024 - samples/sec: 25.98 - lr: 0.000003
2022-09-13 12:00:25,017 epoch 20 - iter 1028/2578 - loss 0.21520745 - samples/sec: 26.53 - lr: 0.000003
2022-09-13 12:01:01,639 epoch 20 - iter 1285/2578 - loss 0.21479485 - samples/sec: 28.08 - lr: 0.000003
2022-09-13 12:01:36,833 epoch 20 - iter 1542/2578 - loss 0.21407126 - samples/sec: 29.22 - lr: 0.000003
2022-09-13 12:02:16,324 epoch 20 - iter 1799/2578 - loss 0.21510431 - samples/sec: 26.04 - lr: 0.000003
2022-09-13 12:02:54,483 epoch 20 - iter 2056/2578 - loss 0.21545992 - samples/sec: 26.95 - lr: 0.000003
2022-09-13 12:03:32,642 epoch 20 - iter 2313/2578 - loss 0.21462946 - samples/sec: 26.95 - lr: 0.000003
2022-09-13 12:04:09,292 epoch 20 - iter 2570/2578 - loss 0.21452327 - samples/sec: 28.06 - lr: 0.000003
2022-09-13 12:04:10,485 ----------------------------------------------------------------------------------------------------
2022-09-13 12:04:10,485 EPOCH 20 done: loss 0.2146 - lr 0.000003
2022-09-13 12:05:01,296 Evaluating as a multi-label problem: False
2022-09-13 12:05:01,350 DEV : loss 0.03488673269748688 - f1-score (micro avg)  0.97
2022-09-13 12:05:01,678 BAD EPOCHS (no improvement): 4
2022-09-13 12:05:01,725 ----------------------------------------------------------------------------------------------------
2022-09-13 12:05:39,257 epoch 21 - iter 257/2578 - loss 0.21722882 - samples/sec: 27.41 - lr: 0.000003
2022-09-13 12:06:17,050 epoch 21 - iter 514/2578 - loss 0.21263956 - samples/sec: 27.21 - lr: 0.000003
2022-09-13 12:06:53,090 epoch 21 - iter 771/2578 - loss 0.21155700 - samples/sec: 28.53 - lr: 0.000003
2022-09-13 12:07:32,973 epoch 21 - iter 1028/2578 - loss 0.21179961 - samples/sec: 25.78 - lr: 0.000003
2022-09-13 12:08:10,315 epoch 21 - iter 1285/2578 - loss 0.21316786 - samples/sec: 27.54 - lr: 0.000003
2022-09-13 12:08:48,141 epoch 21 - iter 1542/2578 - loss 0.21479943 - samples/sec: 27.19 - lr: 0.000003
2022-09-13 12:09:25,826 epoch 21 - iter 1799/2578 - loss 0.21449699 - samples/sec: 27.29 - lr: 0.000003
2022-09-13 12:10:03,598 epoch 21 - iter 2056/2578 - loss 0.21396532 - samples/sec: 27.23 - lr: 0.000003
2022-09-13 12:10:41,607 epoch 21 - iter 2313/2578 - loss 0.21378346 - samples/sec: 27.06 - lr: 0.000003
2022-09-13 12:11:20,637 epoch 21 - iter 2570/2578 - loss 0.21345946 - samples/sec: 26.35 - lr: 0.000003
2022-09-13 12:11:21,652 ----------------------------------------------------------------------------------------------------
2022-09-13 12:11:21,653 EPOCH 21 done: loss 0.2134 - lr 0.000003
2022-09-13 12:12:13,020 Evaluating as a multi-label problem: False
2022-09-13 12:12:13,072 DEV : loss 0.0360444039106369 - f1-score (micro avg)  0.9679
2022-09-13 12:12:13,448 BAD EPOCHS (no improvement): 4
2022-09-13 12:12:13,452 ----------------------------------------------------------------------------------------------------
2022-09-13 12:12:51,861 epoch 22 - iter 257/2578 - loss 0.21147238 - samples/sec: 26.78 - lr: 0.000002
2022-09-13 12:13:29,605 epoch 22 - iter 514/2578 - loss 0.21721792 - samples/sec: 27.25 - lr: 0.000002
2022-09-13 12:14:06,848 epoch 22 - iter 771/2578 - loss 0.21519649 - samples/sec: 27.61 - lr: 0.000002
2022-09-13 12:14:44,138 epoch 22 - iter 1028/2578 - loss 0.21049624 - samples/sec: 27.58 - lr: 0.000002
2022-09-13 12:15:23,898 epoch 22 - iter 1285/2578 - loss 0.21057683 - samples/sec: 25.86 - lr: 0.000002
2022-09-13 12:16:01,673 epoch 22 - iter 1542/2578 - loss 0.21205511 - samples/sec: 27.22 - lr: 0.000002
2022-09-13 12:16:40,150 epoch 22 - iter 1799/2578 - loss 0.21150978 - samples/sec: 26.73 - lr: 0.000002
2022-09-13 12:17:16,700 epoch 22 - iter 2056/2578 - loss 0.21142549 - samples/sec: 28.14 - lr: 0.000002
2022-09-13 12:17:55,862 epoch 22 - iter 2313/2578 - loss 0.21233310 - samples/sec: 26.26 - lr: 0.000002
2022-09-13 12:18:33,785 epoch 22 - iter 2570/2578 - loss 0.21214936 - samples/sec: 27.12 - lr: 0.000002
2022-09-13 12:18:34,778 ----------------------------------------------------------------------------------------------------
2022-09-13 12:18:34,778 EPOCH 22 done: loss 0.2121 - lr 0.000002
2022-09-13 12:19:25,654 Evaluating as a multi-label problem: False
2022-09-13 12:19:25,706 DEV : loss 0.03558309003710747 - f1-score (micro avg)  0.9716
2022-09-13 12:19:26,082 BAD EPOCHS (no improvement): 4
2022-09-13 12:19:26,086 saving best model
2022-09-13 12:19:39,257 ----------------------------------------------------------------------------------------------------
2022-09-13 12:20:15,790 epoch 23 - iter 257/2578 - loss 0.21196923 - samples/sec: 28.15 - lr: 0.000002
2022-09-13 12:20:51,931 epoch 23 - iter 514/2578 - loss 0.20479328 - samples/sec: 28.45 - lr: 0.000002
2022-09-13 12:21:29,119 epoch 23 - iter 771/2578 - loss 0.20765154 - samples/sec: 27.65 - lr: 0.000002
2022-09-13 12:22:09,254 epoch 23 - iter 1028/2578 - loss 0.20706886 - samples/sec: 25.62 - lr: 0.000002
2022-09-13 12:22:45,633 epoch 23 - iter 1285/2578 - loss 0.20626016 - samples/sec: 28.27 - lr: 0.000002
2022-09-13 12:23:21,238 epoch 23 - iter 1542/2578 - loss 0.20922382 - samples/sec: 28.88 - lr: 0.000002
2022-09-13 12:24:00,015 epoch 23 - iter 1799/2578 - loss 0.21042390 - samples/sec: 26.52 - lr: 0.000002
2022-09-13 12:24:39,469 epoch 23 - iter 2056/2578 - loss 0.21143889 - samples/sec: 26.06 - lr: 0.000002
2022-09-13 12:25:18,816 epoch 23 - iter 2313/2578 - loss 0.21174374 - samples/sec: 26.13 - lr: 0.000002
2022-09-13 12:25:56,485 epoch 23 - iter 2570/2578 - loss 0.21101795 - samples/sec: 27.30 - lr: 0.000002
2022-09-13 12:25:57,505 ----------------------------------------------------------------------------------------------------
2022-09-13 12:25:57,505 EPOCH 23 done: loss 0.2109 - lr 0.000002
2022-09-13 12:26:48,123 Evaluating as a multi-label problem: False
2022-09-13 12:26:48,175 DEV : loss 0.03660694509744644 - f1-score (micro avg)  0.971
2022-09-13 12:26:48,548 BAD EPOCHS (no improvement): 4
2022-09-13 12:26:48,552 ----------------------------------------------------------------------------------------------------
2022-09-13 12:27:27,189 epoch 24 - iter 257/2578 - loss 0.21287423 - samples/sec: 26.62 - lr: 0.000002
2022-09-13 12:28:04,288 epoch 24 - iter 514/2578 - loss 0.21170892 - samples/sec: 27.72 - lr: 0.000002
2022-09-13 12:28:41,677 epoch 24 - iter 771/2578 - loss 0.21157186 - samples/sec: 27.50 - lr: 0.000002
2022-09-13 12:29:17,500 epoch 24 - iter 1028/2578 - loss 0.20979879 - samples/sec: 28.71 - lr: 0.000002
2022-09-13 12:29:54,930 epoch 24 - iter 1285/2578 - loss 0.20807547 - samples/sec: 27.47 - lr: 0.000002
2022-09-13 12:30:32,456 epoch 24 - iter 1542/2578 - loss 0.20879147 - samples/sec: 27.40 - lr: 0.000002
2022-09-13 12:31:10,123 epoch 24 - iter 1799/2578 - loss 0.20768435 - samples/sec: 27.30 - lr: 0.000002
2022-09-13 12:31:49,042 epoch 24 - iter 2056/2578 - loss 0.20921286 - samples/sec: 26.42 - lr: 0.000002
2022-09-13 12:32:27,331 epoch 24 - iter 2313/2578 - loss 0.20981884 - samples/sec: 26.86 - lr: 0.000002
2022-09-13 12:33:06,904 epoch 24 - iter 2570/2578 - loss 0.20973675 - samples/sec: 25.99 - lr: 0.000002
2022-09-13 12:33:08,203 ----------------------------------------------------------------------------------------------------
2022-09-13 12:33:08,204 EPOCH 24 done: loss 0.2097 - lr 0.000002
2022-09-13 12:33:59,043 Evaluating as a multi-label problem: False
2022-09-13 12:33:59,094 DEV : loss 0.03603705018758774 - f1-score (micro avg)  0.9718
2022-09-13 12:33:59,473 BAD EPOCHS (no improvement): 4
2022-09-13 12:33:59,476 saving best model
2022-09-13 12:34:10,940 ----------------------------------------------------------------------------------------------------
2022-09-13 12:34:48,501 epoch 25 - iter 257/2578 - loss 0.21062992 - samples/sec: 27.38 - lr: 0.000002
2022-09-13 12:35:25,079 epoch 25 - iter 514/2578 - loss 0.21014003 - samples/sec: 28.11 - lr: 0.000002
2022-09-13 12:36:03,875 epoch 25 - iter 771/2578 - loss 0.20922757 - samples/sec: 26.51 - lr: 0.000002
2022-09-13 12:36:40,144 epoch 25 - iter 1028/2578 - loss 0.20726393 - samples/sec: 28.35 - lr: 0.000002
2022-09-13 12:37:20,688 epoch 25 - iter 1285/2578 - loss 0.20873685 - samples/sec: 25.36 - lr: 0.000002
2022-09-13 12:37:58,686 epoch 25 - iter 1542/2578 - loss 0.21030775 - samples/sec: 27.06 - lr: 0.000002
2022-09-13 12:38:34,889 epoch 25 - iter 1799/2578 - loss 0.21124292 - samples/sec: 28.41 - lr: 0.000002
2022-09-13 12:39:11,344 epoch 25 - iter 2056/2578 - loss 0.21201254 - samples/sec: 28.21 - lr: 0.000002
2022-09-13 12:39:49,074 epoch 25 - iter 2313/2578 - loss 0.21180793 - samples/sec: 27.26 - lr: 0.000002
2022-09-13 12:40:27,795 epoch 25 - iter 2570/2578 - loss 0.21220164 - samples/sec: 26.56 - lr: 0.000002
2022-09-13 12:40:28,855 ----------------------------------------------------------------------------------------------------
2022-09-13 12:40:28,856 EPOCH 25 done: loss 0.2122 - lr 0.000002
2022-09-13 12:41:19,590 Evaluating as a multi-label problem: False
2022-09-13 12:41:19,642 DEV : loss 0.0371515229344368 - f1-score (micro avg)  0.9706
2022-09-13 12:41:20,016 BAD EPOCHS (no improvement): 4
2022-09-13 12:41:20,021 ----------------------------------------------------------------------------------------------------
2022-09-13 12:41:58,179 epoch 26 - iter 257/2578 - loss 0.21601044 - samples/sec: 26.95 - lr: 0.000002
2022-09-13 12:42:34,381 epoch 26 - iter 514/2578 - loss 0.21252715 - samples/sec: 28.41 - lr: 0.000002
2022-09-13 12:43:13,014 epoch 26 - iter 771/2578 - loss 0.21144637 - samples/sec: 26.62 - lr: 0.000002
2022-09-13 12:43:50,190 epoch 26 - iter 1028/2578 - loss 0.21310922 - samples/sec: 27.66 - lr: 0.000002
2022-09-13 12:44:27,729 epoch 26 - iter 1285/2578 - loss 0.21403470 - samples/sec: 27.40 - lr: 0.000002
2022-09-13 12:45:05,944 epoch 26 - iter 1542/2578 - loss 0.21405945 - samples/sec: 26.91 - lr: 0.000002
2022-09-13 12:45:44,615 epoch 26 - iter 1799/2578 - loss 0.21304001 - samples/sec: 26.59 - lr: 0.000002
2022-09-13 12:46:22,631 epoch 26 - iter 2056/2578 - loss 0.21204899 - samples/sec: 27.05 - lr: 0.000002
2022-09-13 12:47:00,093 epoch 26 - iter 2313/2578 - loss 0.21270453 - samples/sec: 27.45 - lr: 0.000002
2022-09-13 12:47:37,162 epoch 26 - iter 2570/2578 - loss 0.21247991 - samples/sec: 27.74 - lr: 0.000002
2022-09-13 12:47:38,439 ----------------------------------------------------------------------------------------------------
2022-09-13 12:47:38,439 EPOCH 26 done: loss 0.2124 - lr 0.000002
2022-09-13 12:48:30,035 Evaluating as a multi-label problem: False
2022-09-13 12:48:30,086 DEV : loss 0.03786192834377289 - f1-score (micro avg)  0.9694
2022-09-13 12:48:30,461 BAD EPOCHS (no improvement): 4
2022-09-13 12:48:30,465 ----------------------------------------------------------------------------------------------------
2022-09-13 12:49:09,229 epoch 27 - iter 257/2578 - loss 0.21087265 - samples/sec: 26.53 - lr: 0.000002
2022-09-13 12:49:46,708 epoch 27 - iter 514/2578 - loss 0.21438098 - samples/sec: 27.44 - lr: 0.000002
2022-09-13 12:50:25,518 epoch 27 - iter 771/2578 - loss 0.21415656 - samples/sec: 26.50 - lr: 0.000002
2022-09-13 12:51:03,948 epoch 27 - iter 1028/2578 - loss 0.21257024 - samples/sec: 26.76 - lr: 0.000002
2022-09-13 12:51:38,880 epoch 27 - iter 1285/2578 - loss 0.21344406 - samples/sec: 29.44 - lr: 0.000002
2022-09-13 12:52:18,810 epoch 27 - iter 1542/2578 - loss 0.21139217 - samples/sec: 25.75 - lr: 0.000002
2022-09-13 12:52:56,830 epoch 27 - iter 1799/2578 - loss 0.21109125 - samples/sec: 27.05 - lr: 0.000002
2022-09-13 12:53:34,393 epoch 27 - iter 2056/2578 - loss 0.21142118 - samples/sec: 27.38 - lr: 0.000002
2022-09-13 12:54:11,664 epoch 27 - iter 2313/2578 - loss 0.21113565 - samples/sec: 27.59 - lr: 0.000002
2022-09-13 12:54:49,909 epoch 27 - iter 2570/2578 - loss 0.21097992 - samples/sec: 26.89 - lr: 0.000002
2022-09-13 12:54:50,988 ----------------------------------------------------------------------------------------------------
2022-09-13 12:54:50,988 EPOCH 27 done: loss 0.2110 - lr 0.000002
2022-09-13 12:55:41,813 Evaluating as a multi-label problem: False
2022-09-13 12:55:41,865 DEV : loss 0.03835530951619148 - f1-score (micro avg)  0.9699
2022-09-13 12:55:42,243 BAD EPOCHS (no improvement): 4
2022-09-13 12:55:42,247 ----------------------------------------------------------------------------------------------------
2022-09-13 12:56:22,147 epoch 28 - iter 257/2578 - loss 0.20567494 - samples/sec: 25.78 - lr: 0.000002
2022-09-13 12:56:58,989 epoch 28 - iter 514/2578 - loss 0.21052489 - samples/sec: 27.91 - lr: 0.000002
2022-09-13 12:57:36,382 epoch 28 - iter 771/2578 - loss 0.20927027 - samples/sec: 27.50 - lr: 0.000002
2022-09-13 12:58:15,291 epoch 28 - iter 1028/2578 - loss 0.20946108 - samples/sec: 26.43 - lr: 0.000002
2022-09-13 12:58:51,144 epoch 28 - iter 1285/2578 - loss 0.20979574 - samples/sec: 28.68 - lr: 0.000002
2022-09-13 12:59:29,095 epoch 28 - iter 1542/2578 - loss 0.20992488 - samples/sec: 27.10 - lr: 0.000002
2022-09-13 13:00:05,516 epoch 28 - iter 1799/2578 - loss 0.20915724 - samples/sec: 28.24 - lr: 0.000002
2022-09-13 13:00:41,819 epoch 28 - iter 2056/2578 - loss 0.20974500 - samples/sec: 28.33 - lr: 0.000002
2022-09-13 13:01:19,038 epoch 28 - iter 2313/2578 - loss 0.21059499 - samples/sec: 27.63 - lr: 0.000002
2022-09-13 13:01:58,484 epoch 28 - iter 2570/2578 - loss 0.20955027 - samples/sec: 26.07 - lr: 0.000002
2022-09-13 13:02:00,290 ----------------------------------------------------------------------------------------------------
2022-09-13 13:02:00,290 EPOCH 28 done: loss 0.2094 - lr 0.000002
2022-09-13 13:02:51,053 Evaluating as a multi-label problem: False
2022-09-13 13:02:51,103 DEV : loss 0.03861440345644951 - f1-score (micro avg)  0.9707
2022-09-13 13:02:51,479 BAD EPOCHS (no improvement): 4
2022-09-13 13:02:51,483 ----------------------------------------------------------------------------------------------------
2022-09-13 13:03:31,341 epoch 29 - iter 257/2578 - loss 0.20319163 - samples/sec: 25.81 - lr: 0.000002
2022-09-13 13:04:09,545 epoch 29 - iter 514/2578 - loss 0.20223624 - samples/sec: 26.92 - lr: 0.000002
2022-09-13 13:04:45,414 epoch 29 - iter 771/2578 - loss 0.20080929 - samples/sec: 28.67 - lr: 0.000002
2022-09-13 13:05:21,336 epoch 29 - iter 1028/2578 - loss 0.20365794 - samples/sec: 28.63 - lr: 0.000002
2022-09-13 13:05:58,087 epoch 29 - iter 1285/2578 - loss 0.20452689 - samples/sec: 27.98 - lr: 0.000002
2022-09-13 13:06:36,133 epoch 29 - iter 1542/2578 - loss 0.20734270 - samples/sec: 27.03 - lr: 0.000002
2022-09-13 13:07:14,860 epoch 29 - iter 1799/2578 - loss 0.20665513 - samples/sec: 26.55 - lr: 0.000001
2022-09-13 13:07:52,059 epoch 29 - iter 2056/2578 - loss 0.20590518 - samples/sec: 27.64 - lr: 0.000001
2022-09-13 13:08:31,280 epoch 29 - iter 2313/2578 - loss 0.20651087 - samples/sec: 26.22 - lr: 0.000001
2022-09-13 13:09:09,471 epoch 29 - iter 2570/2578 - loss 0.20723458 - samples/sec: 26.93 - lr: 0.000001
2022-09-13 13:09:10,615 ----------------------------------------------------------------------------------------------------
2022-09-13 13:09:10,615 EPOCH 29 done: loss 0.2073 - lr 0.000001
2022-09-13 13:10:01,463 Evaluating as a multi-label problem: False
2022-09-13 13:10:01,516 DEV : loss 0.03832782059907913 - f1-score (micro avg)  0.9714
2022-09-13 13:10:01,892 BAD EPOCHS (no improvement): 4
2022-09-13 13:10:01,896 ----------------------------------------------------------------------------------------------------
2022-09-13 13:10:41,084 epoch 30 - iter 257/2578 - loss 0.20689305 - samples/sec: 26.25 - lr: 0.000001
2022-09-13 13:11:18,281 epoch 30 - iter 514/2578 - loss 0.21057828 - samples/sec: 27.65 - lr: 0.000001
2022-09-13 13:11:56,249 epoch 30 - iter 771/2578 - loss 0.20776040 - samples/sec: 27.08 - lr: 0.000001
2022-09-13 13:12:32,818 epoch 30 - iter 1028/2578 - loss 0.20843817 - samples/sec: 28.12 - lr: 0.000001
2022-09-13 13:13:11,956 epoch 30 - iter 1285/2578 - loss 0.20892090 - samples/sec: 26.27 - lr: 0.000001
2022-09-13 13:13:50,028 epoch 30 - iter 1542/2578 - loss 0.20909099 - samples/sec: 27.01 - lr: 0.000001
2022-09-13 13:14:27,241 epoch 30 - iter 1799/2578 - loss 0.20870028 - samples/sec: 27.63 - lr: 0.000001
2022-09-13 13:15:05,246 epoch 30 - iter 2056/2578 - loss 0.20866758 - samples/sec: 27.06 - lr: 0.000001
2022-09-13 13:15:42,659 epoch 30 - iter 2313/2578 - loss 0.20907862 - samples/sec: 27.49 - lr: 0.000001
2022-09-13 13:16:18,695 epoch 30 - iter 2570/2578 - loss 0.20922386 - samples/sec: 28.54 - lr: 0.000001
2022-09-13 13:16:20,008 ----------------------------------------------------------------------------------------------------
2022-09-13 13:16:20,009 EPOCH 30 done: loss 0.2091 - lr 0.000001
2022-09-13 13:17:10,812 Evaluating as a multi-label problem: False
2022-09-13 13:17:10,864 DEV : loss 0.03773649409413338 - f1-score (micro avg)  0.9714
2022-09-13 13:17:11,241 BAD EPOCHS (no improvement): 4
2022-09-13 13:17:11,245 ----------------------------------------------------------------------------------------------------
2022-09-13 13:17:49,351 epoch 31 - iter 257/2578 - loss 0.21172684 - samples/sec: 26.99 - lr: 0.000001
2022-09-13 13:18:27,186 epoch 31 - iter 514/2578 - loss 0.20751055 - samples/sec: 27.18 - lr: 0.000001
2022-09-13 13:19:04,805 epoch 31 - iter 771/2578 - loss 0.20582961 - samples/sec: 27.34 - lr: 0.000001
2022-09-13 13:19:43,379 epoch 31 - iter 1028/2578 - loss 0.20706275 - samples/sec: 26.66 - lr: 0.000001
2022-09-13 13:20:20,017 epoch 31 - iter 1285/2578 - loss 0.20753729 - samples/sec: 28.07 - lr: 0.000001
2022-09-13 13:20:55,274 epoch 31 - iter 1542/2578 - loss 0.20636936 - samples/sec: 29.17 - lr: 0.000001
2022-09-13 13:21:33,511 epoch 31 - iter 1799/2578 - loss 0.20682487 - samples/sec: 26.89 - lr: 0.000001
2022-09-13 13:22:11,565 epoch 31 - iter 2056/2578 - loss 0.20660928 - samples/sec: 27.02 - lr: 0.000001
2022-09-13 13:22:50,495 epoch 31 - iter 2313/2578 - loss 0.20677944 - samples/sec: 26.42 - lr: 0.000001
2022-09-13 13:23:29,866 epoch 31 - iter 2570/2578 - loss 0.20748891 - samples/sec: 26.12 - lr: 0.000001
2022-09-13 13:23:30,851 ----------------------------------------------------------------------------------------------------
2022-09-13 13:23:30,851 EPOCH 31 done: loss 0.2074 - lr 0.000001
2022-09-13 13:24:22,941 Evaluating as a multi-label problem: False
2022-09-13 13:24:22,993 DEV : loss 0.0379493273794651 - f1-score (micro avg)  0.9707
2022-09-13 13:24:23,368 BAD EPOCHS (no improvement): 4
2022-09-13 13:24:23,372 ----------------------------------------------------------------------------------------------------
2022-09-13 13:24:59,353 epoch 32 - iter 257/2578 - loss 0.20754618 - samples/sec: 28.59 - lr: 0.000001
2022-09-13 13:25:37,535 epoch 32 - iter 514/2578 - loss 0.20974095 - samples/sec: 26.93 - lr: 0.000001
2022-09-13 13:26:15,730 epoch 32 - iter 771/2578 - loss 0.20928125 - samples/sec: 26.92 - lr: 0.000001
2022-09-13 13:26:55,355 epoch 32 - iter 1028/2578 - loss 0.20902727 - samples/sec: 25.95 - lr: 0.000001
2022-09-13 13:27:32,942 epoch 32 - iter 1285/2578 - loss 0.20982726 - samples/sec: 27.36 - lr: 0.000001
2022-09-13 13:28:11,275 epoch 32 - iter 1542/2578 - loss 0.20915657 - samples/sec: 26.83 - lr: 0.000001
2022-09-13 13:28:50,277 epoch 32 - iter 1799/2578 - loss 0.20938814 - samples/sec: 26.37 - lr: 0.000001
2022-09-13 13:29:27,373 epoch 32 - iter 2056/2578 - loss 0.21081879 - samples/sec: 27.72 - lr: 0.000001
2022-09-13 13:30:04,318 epoch 32 - iter 2313/2578 - loss 0.21170354 - samples/sec: 27.84 - lr: 0.000001
2022-09-13 13:30:41,061 epoch 32 - iter 2570/2578 - loss 0.21158348 - samples/sec: 27.99 - lr: 0.000001
2022-09-13 13:30:42,566 ----------------------------------------------------------------------------------------------------
2022-09-13 13:30:42,566 EPOCH 32 done: loss 0.2113 - lr 0.000001
2022-09-13 13:31:33,489 Evaluating as a multi-label problem: False
2022-09-13 13:31:33,540 DEV : loss 0.037701986730098724 - f1-score (micro avg)  0.9709
2022-09-13 13:31:33,910 BAD EPOCHS (no improvement): 4
2022-09-13 13:31:33,914 ----------------------------------------------------------------------------------------------------
2022-09-13 13:32:12,748 epoch 33 - iter 257/2578 - loss 0.21036137 - samples/sec: 26.49 - lr: 0.000001
2022-09-13 13:32:50,644 epoch 33 - iter 514/2578 - loss 0.21132407 - samples/sec: 27.14 - lr: 0.000001
2022-09-13 13:33:27,884 epoch 33 - iter 771/2578 - loss 0.21261586 - samples/sec: 27.61 - lr: 0.000001
2022-09-13 13:34:04,948 epoch 33 - iter 1028/2578 - loss 0.21159695 - samples/sec: 27.75 - lr: 0.000001
2022-09-13 13:34:42,293 epoch 33 - iter 1285/2578 - loss 0.21123589 - samples/sec: 27.54 - lr: 0.000001
2022-09-13 13:35:20,553 epoch 33 - iter 1542/2578 - loss 0.21156891 - samples/sec: 26.88 - lr: 0.000001
2022-09-13 13:35:55,916 epoch 33 - iter 1799/2578 - loss 0.21076147 - samples/sec: 29.08 - lr: 0.000001
2022-09-13 13:36:37,545 epoch 33 - iter 2056/2578 - loss 0.20983396 - samples/sec: 24.70 - lr: 0.000001
2022-09-13 13:37:13,658 epoch 33 - iter 2313/2578 - loss 0.21066584 - samples/sec: 28.48 - lr: 0.000001
2022-09-13 13:37:51,518 epoch 33 - iter 2570/2578 - loss 0.21050744 - samples/sec: 27.16 - lr: 0.000001
2022-09-13 13:37:52,455 ----------------------------------------------------------------------------------------------------
2022-09-13 13:37:52,456 EPOCH 33 done: loss 0.2104 - lr 0.000001
2022-09-13 13:38:43,328 Evaluating as a multi-label problem: False
2022-09-13 13:38:43,380 DEV : loss 0.03799707442522049 - f1-score (micro avg)  0.9713
2022-09-13 13:38:43,755 BAD EPOCHS (no improvement): 4
2022-09-13 13:38:43,759 ----------------------------------------------------------------------------------------------------
2022-09-13 13:39:19,521 epoch 34 - iter 257/2578 - loss 0.20830378 - samples/sec: 28.76 - lr: 0.000001
2022-09-13 13:39:59,049 epoch 34 - iter 514/2578 - loss 0.21062987 - samples/sec: 26.02 - lr: 0.000001
2022-09-13 13:40:36,619 epoch 34 - iter 771/2578 - loss 0.21086978 - samples/sec: 27.37 - lr: 0.000001
2022-09-13 13:41:14,044 epoch 34 - iter 1028/2578 - loss 0.20924268 - samples/sec: 27.48 - lr: 0.000001
2022-09-13 13:41:53,357 epoch 34 - iter 1285/2578 - loss 0.20823953 - samples/sec: 26.16 - lr: 0.000001
2022-09-13 13:42:30,564 epoch 34 - iter 1542/2578 - loss 0.21072951 - samples/sec: 27.64 - lr: 0.000001
2022-09-13 13:43:08,446 epoch 34 - iter 1799/2578 - loss 0.20943323 - samples/sec: 27.15 - lr: 0.000001
2022-09-13 13:43:45,310 epoch 34 - iter 2056/2578 - loss 0.21008392 - samples/sec: 27.90 - lr: 0.000001
2022-09-13 13:44:23,566 epoch 34 - iter 2313/2578 - loss 0.21118233 - samples/sec: 26.88 - lr: 0.000001
2022-09-13 13:45:02,292 epoch 34 - iter 2570/2578 - loss 0.21222518 - samples/sec: 26.55 - lr: 0.000001
2022-09-13 13:45:03,349 ----------------------------------------------------------------------------------------------------
2022-09-13 13:45:03,350 EPOCH 34 done: loss 0.2122 - lr 0.000001
2022-09-13 13:45:54,090 Evaluating as a multi-label problem: False
2022-09-13 13:45:54,142 DEV : loss 0.03900553286075592 - f1-score (micro avg)  0.9712
2022-09-13 13:45:54,518 BAD EPOCHS (no improvement): 4
2022-09-13 13:45:54,522 ----------------------------------------------------------------------------------------------------
2022-09-13 13:46:28,887 epoch 35 - iter 257/2578 - loss 0.20376910 - samples/sec: 29.93 - lr: 0.000001
2022-09-13 13:47:06,767 epoch 35 - iter 514/2578 - loss 0.20374409 - samples/sec: 27.15 - lr: 0.000001
2022-09-13 13:47:44,016 epoch 35 - iter 771/2578 - loss 0.20339444 - samples/sec: 27.61 - lr: 0.000001
2022-09-13 13:48:20,286 epoch 35 - iter 1028/2578 - loss 0.20217221 - samples/sec: 28.35 - lr: 0.000001
2022-09-13 13:48:58,810 epoch 35 - iter 1285/2578 - loss 0.20227999 - samples/sec: 26.69 - lr: 0.000001
2022-09-13 13:49:38,458 epoch 35 - iter 1542/2578 - loss 0.20364262 - samples/sec: 25.94 - lr: 0.000001
2022-09-13 13:50:16,752 epoch 35 - iter 1799/2578 - loss 0.20387800 - samples/sec: 26.85 - lr: 0.000001
2022-09-13 13:50:57,648 epoch 35 - iter 2056/2578 - loss 0.20424351 - samples/sec: 25.14 - lr: 0.000001
2022-09-13 13:51:34,572 epoch 35 - iter 2313/2578 - loss 0.20533197 - samples/sec: 27.85 - lr: 0.000001
2022-09-13 13:52:12,871 epoch 35 - iter 2570/2578 - loss 0.20522522 - samples/sec: 26.85 - lr: 0.000001
2022-09-13 13:52:13,851 ----------------------------------------------------------------------------------------------------
2022-09-13 13:52:13,851 EPOCH 35 done: loss 0.2052 - lr 0.000001
2022-09-13 13:53:04,666 Evaluating as a multi-label problem: False
2022-09-13 13:53:04,714 DEV : loss 0.038471490144729614 - f1-score (micro avg)  0.9699
2022-09-13 13:53:05,088 BAD EPOCHS (no improvement): 4
2022-09-13 13:53:05,092 ----------------------------------------------------------------------------------------------------
2022-09-13 13:53:40,206 epoch 36 - iter 257/2578 - loss 0.19807484 - samples/sec: 29.29 - lr: 0.000001
2022-09-13 13:54:17,839 epoch 36 - iter 514/2578 - loss 0.20249458 - samples/sec: 27.33 - lr: 0.000001
2022-09-13 13:54:55,438 epoch 36 - iter 771/2578 - loss 0.20531598 - samples/sec: 27.35 - lr: 0.000001
2022-09-13 13:55:34,360 epoch 36 - iter 1028/2578 - loss 0.20464069 - samples/sec: 26.42 - lr: 0.000001
2022-09-13 13:56:12,734 epoch 36 - iter 1285/2578 - loss 0.20439681 - samples/sec: 26.80 - lr: 0.000001
2022-09-13 13:56:50,700 epoch 36 - iter 1542/2578 - loss 0.20533526 - samples/sec: 27.09 - lr: 0.000001
2022-09-13 13:57:27,120 epoch 36 - iter 1799/2578 - loss 0.20686622 - samples/sec: 28.24 - lr: 0.000001
2022-09-13 13:58:06,993 epoch 36 - iter 2056/2578 - loss 0.20800222 - samples/sec: 25.79 - lr: 0.000001
2022-09-13 13:58:46,695 epoch 36 - iter 2313/2578 - loss 0.20698992 - samples/sec: 25.90 - lr: 0.000001
2022-09-13 13:59:24,294 epoch 36 - iter 2570/2578 - loss 0.20711572 - samples/sec: 27.35 - lr: 0.000001
2022-09-13 13:59:25,332 ----------------------------------------------------------------------------------------------------
2022-09-13 13:59:25,332 EPOCH 36 done: loss 0.2072 - lr 0.000001
2022-09-13 14:00:16,023 Evaluating as a multi-label problem: False
2022-09-13 14:00:16,073 DEV : loss 0.039186496287584305 - f1-score (micro avg)  0.9702
2022-09-13 14:00:16,444 BAD EPOCHS (no improvement): 4
2022-09-13 14:00:16,448 ----------------------------------------------------------------------------------------------------
2022-09-13 14:00:56,368 epoch 37 - iter 257/2578 - loss 0.20446249 - samples/sec: 25.77 - lr: 0.000001
2022-09-13 14:01:31,212 epoch 37 - iter 514/2578 - loss 0.20462612 - samples/sec: 29.51 - lr: 0.000001
2022-09-13 14:02:07,603 epoch 37 - iter 771/2578 - loss 0.20867908 - samples/sec: 28.26 - lr: 0.000000
2022-09-13 14:02:45,778 epoch 37 - iter 1028/2578 - loss 0.20661397 - samples/sec: 26.94 - lr: 0.000000
2022-09-13 14:03:27,164 epoch 37 - iter 1285/2578 - loss 0.20780119 - samples/sec: 24.85 - lr: 0.000000
2022-09-13 14:04:06,047 epoch 37 - iter 1542/2578 - loss 0.20809957 - samples/sec: 26.45 - lr: 0.000000
2022-09-13 14:04:44,279 epoch 37 - iter 1799/2578 - loss 0.20930900 - samples/sec: 26.90 - lr: 0.000000
2022-09-13 14:05:20,360 epoch 37 - iter 2056/2578 - loss 0.20987349 - samples/sec: 28.50 - lr: 0.000000
2022-09-13 14:05:59,729 epoch 37 - iter 2313/2578 - loss 0.21022051 - samples/sec: 26.12 - lr: 0.000000
2022-09-13 14:06:37,130 epoch 37 - iter 2570/2578 - loss 0.21016037 - samples/sec: 27.50 - lr: 0.000000
2022-09-13 14:06:38,146 ----------------------------------------------------------------------------------------------------
2022-09-13 14:06:38,146 EPOCH 37 done: loss 0.2101 - lr 0.000000
2022-09-13 14:07:29,532 Evaluating as a multi-label problem: False
2022-09-13 14:07:29,580 DEV : loss 0.038938019424676895 - f1-score (micro avg)  0.9694
2022-09-13 14:07:29,955 BAD EPOCHS (no improvement): 4
2022-09-13 14:07:29,958 ----------------------------------------------------------------------------------------------------
2022-09-13 14:08:07,824 epoch 38 - iter 257/2578 - loss 0.19718014 - samples/sec: 27.16 - lr: 0.000000
2022-09-13 14:08:44,602 epoch 38 - iter 514/2578 - loss 0.20057575 - samples/sec: 27.96 - lr: 0.000000
2022-09-13 14:09:20,322 epoch 38 - iter 771/2578 - loss 0.20380043 - samples/sec: 28.79 - lr: 0.000000
2022-09-13 14:10:01,290 epoch 38 - iter 1028/2578 - loss 0.20627424 - samples/sec: 25.10 - lr: 0.000000
2022-09-13 14:10:37,397 epoch 38 - iter 1285/2578 - loss 0.20825140 - samples/sec: 28.48 - lr: 0.000000
2022-09-13 14:11:15,749 epoch 38 - iter 1542/2578 - loss 0.20794106 - samples/sec: 26.81 - lr: 0.000000
2022-09-13 14:11:55,123 epoch 38 - iter 1799/2578 - loss 0.20827029 - samples/sec: 26.12 - lr: 0.000000
2022-09-13 14:12:34,382 epoch 38 - iter 2056/2578 - loss 0.20765444 - samples/sec: 26.19 - lr: 0.000000
2022-09-13 14:13:12,824 epoch 38 - iter 2313/2578 - loss 0.20826044 - samples/sec: 26.75 - lr: 0.000000
2022-09-13 14:13:51,077 epoch 38 - iter 2570/2578 - loss 0.20816346 - samples/sec: 26.88 - lr: 0.000000
2022-09-13 14:13:52,293 ----------------------------------------------------------------------------------------------------
2022-09-13 14:13:52,293 EPOCH 38 done: loss 0.2082 - lr 0.000000
2022-09-13 14:14:43,012 Evaluating as a multi-label problem: False
2022-09-13 14:14:43,062 DEV : loss 0.038825202733278275 - f1-score (micro avg)  0.969
2022-09-13 14:14:43,438 BAD EPOCHS (no improvement): 4
2022-09-13 14:14:43,442 ----------------------------------------------------------------------------------------------------
2022-09-13 14:15:20,495 epoch 39 - iter 257/2578 - loss 0.20824177 - samples/sec: 27.76 - lr: 0.000000
2022-09-13 14:15:59,578 epoch 39 - iter 514/2578 - loss 0.21333355 - samples/sec: 26.31 - lr: 0.000000
2022-09-13 14:16:36,903 epoch 39 - iter 771/2578 - loss 0.21425892 - samples/sec: 27.55 - lr: 0.000000
2022-09-13 14:17:16,985 epoch 39 - iter 1028/2578 - loss 0.21038445 - samples/sec: 25.66 - lr: 0.000000
2022-09-13 14:17:55,529 epoch 39 - iter 1285/2578 - loss 0.20840690 - samples/sec: 26.68 - lr: 0.000000
2022-09-13 14:18:30,706 epoch 39 - iter 1542/2578 - loss 0.20906283 - samples/sec: 29.23 - lr: 0.000000
2022-09-13 14:19:10,816 epoch 39 - iter 1799/2578 - loss 0.20999545 - samples/sec: 25.64 - lr: 0.000000
2022-09-13 14:19:48,915 epoch 39 - iter 2056/2578 - loss 0.20958752 - samples/sec: 26.99 - lr: 0.000000
2022-09-13 14:20:26,375 epoch 39 - iter 2313/2578 - loss 0.21025963 - samples/sec: 27.45 - lr: 0.000000
2022-09-13 14:21:04,753 epoch 39 - iter 2570/2578 - loss 0.21059180 - samples/sec: 26.80 - lr: 0.000000
2022-09-13 14:21:05,630 ----------------------------------------------------------------------------------------------------
2022-09-13 14:21:05,630 EPOCH 39 done: loss 0.2106 - lr 0.000000
2022-09-13 14:21:56,482 Evaluating as a multi-label problem: False
2022-09-13 14:21:56,532 DEV : loss 0.039033349603414536 - f1-score (micro avg)  0.97
2022-09-13 14:21:56,908 BAD EPOCHS (no improvement): 4
2022-09-13 14:21:56,912 ----------------------------------------------------------------------------------------------------
2022-09-13 14:22:35,657 epoch 40 - iter 257/2578 - loss 0.21120095 - samples/sec: 26.55 - lr: 0.000000
2022-09-13 14:23:14,609 epoch 40 - iter 514/2578 - loss 0.20453367 - samples/sec: 26.40 - lr: 0.000000
2022-09-13 14:23:51,410 epoch 40 - iter 771/2578 - loss 0.20054452 - samples/sec: 27.94 - lr: 0.000000
2022-09-13 14:24:30,118 epoch 40 - iter 1028/2578 - loss 0.20345247 - samples/sec: 26.57 - lr: 0.000000
2022-09-13 14:25:08,011 epoch 40 - iter 1285/2578 - loss 0.20492841 - samples/sec: 27.14 - lr: 0.000000
2022-09-13 14:25:46,006 epoch 40 - iter 1542/2578 - loss 0.20583032 - samples/sec: 27.07 - lr: 0.000000
2022-09-13 14:26:24,643 epoch 40 - iter 1799/2578 - loss 0.20565242 - samples/sec: 26.62 - lr: 0.000000
2022-09-13 14:27:01,882 epoch 40 - iter 2056/2578 - loss 0.20749364 - samples/sec: 27.62 - lr: 0.000000
2022-09-13 14:27:40,662 epoch 40 - iter 2313/2578 - loss 0.20645417 - samples/sec: 26.52 - lr: 0.000000
2022-09-13 14:28:18,068 epoch 40 - iter 2570/2578 - loss 0.20673097 - samples/sec: 27.49 - lr: 0.000000
2022-09-13 14:28:18,953 ----------------------------------------------------------------------------------------------------
2022-09-13 14:28:18,954 EPOCH 40 done: loss 0.2067 - lr 0.000000
2022-09-13 14:29:09,671 Evaluating as a multi-label problem: False
2022-09-13 14:29:09,722 DEV : loss 0.0390104316174984 - f1-score (micro avg)  0.97
2022-09-13 14:29:10,094 BAD EPOCHS (no improvement): 4
2022-09-13 14:29:13,335 ----------------------------------------------------------------------------------------------------
2022-09-13 14:29:13,336 loading file experiments/corpus_sentence_bert_we_finetune/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_1)_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/best-model.pt
2022-09-13 14:29:17,068 SequenceTagger predicts: Dictionary with 89 tags: O, S-TERRITORIO, B-TERRITORIO, E-TERRITORIO, I-TERRITORIO, S-FECHAS, B-FECHAS, E-FECHAS, I-FECHAS, S-EDAD_SUJETO_ASISTENCIA, B-EDAD_SUJETO_ASISTENCIA, E-EDAD_SUJETO_ASISTENCIA, I-EDAD_SUJETO_ASISTENCIA, S-NOMBRE_SUJETO_ASISTENCIA, B-NOMBRE_SUJETO_ASISTENCIA, E-NOMBRE_SUJETO_ASISTENCIA, I-NOMBRE_SUJETO_ASISTENCIA, S-NOMBRE_PERSONAL_SANITARIO, B-NOMBRE_PERSONAL_SANITARIO, E-NOMBRE_PERSONAL_SANITARIO, I-NOMBRE_PERSONAL_SANITARIO, S-SEXO_SUJETO_ASISTENCIA, B-SEXO_SUJETO_ASISTENCIA, E-SEXO_SUJETO_ASISTENCIA, I-SEXO_SUJETO_ASISTENCIA, S-CALLE, B-CALLE, E-CALLE, I-CALLE, S-PAIS, B-PAIS, E-PAIS, I-PAIS, S-ID_SUJETO_ASISTENCIA, B-ID_SUJETO_ASISTENCIA, E-ID_SUJETO_ASISTENCIA, I-ID_SUJETO_ASISTENCIA, S-ID_TITULACION_PERSONAL_SANITARIO, B-ID_TITULACION_PERSONAL_SANITARIO, E-ID_TITULACION_PERSONAL_SANITARIO, I-ID_TITULACION_PERSONAL_SANITARIO, S-CORREO_ELECTRONICO, B-CORREO_ELECTRONICO, E-CORREO_ELECTRONICO, I-CORREO_ELECTRONICO, S-ID_ASEGURAMIENTO, B-ID_ASEGURAMIENTO, E-ID_ASEGURAMIENTO, I-ID_ASEGURAMIENTO, S-HOSPITAL
2022-09-13 14:30:07,058 Evaluating as a multi-label problem: False
2022-09-13 14:30:07,109 0.9651	0.9763	0.9707	0.9479
2022-09-13 14:30:07,110 
Results:
- F-score (micro) 0.9707
- F-score (macro) 0.8607
- Accuracy 0.9479

By class:
                                  precision    recall  f1-score   support

                      TERRITORIO     0.9750    0.9791    0.9770       956
                          FECHAS     0.9902    0.9951    0.9927       611
          EDAD_SUJETO_ASISTENCIA     0.9697    0.9884    0.9790       518
        NOMBRE_SUJETO_ASISTENCIA     0.9940    0.9980    0.9960       502
       NOMBRE_PERSONAL_SANITARIO     0.9901    0.9960    0.9930       501
          SEXO_SUJETO_ASISTENCIA     0.9704    0.9957    0.9829       461
                           CALLE     0.9522    0.9637    0.9579       413
                            PAIS     0.9836    0.9917    0.9877       363
            ID_SUJETO_ASISTENCIA     0.9757    0.9929    0.9842       283
              CORREO_ELECTRONICO     0.9800    0.9839    0.9820       249
ID_TITULACION_PERSONAL_SANITARIO     0.9915    1.0000    0.9957       234
                ID_ASEGURAMIENTO     1.0000    0.9949    0.9975       198
                        HOSPITAL     0.9120    0.8769    0.8941       130
    FAMILIARES_SUJETO_ASISTENCIA     0.7558    0.8025    0.7784        81
                     INSTITUCION     0.4568    0.5522    0.5000        67
         ID_CONTACTO_ASISTENCIAL     0.9048    0.9744    0.9383        39
                 NUMERO_TELEFONO     0.8966    1.0000    0.9455        26
                       PROFESION     0.5000    0.7778    0.6087         9
                      NUMERO_FAX     0.8571    0.8571    0.8571         7
                    CENTRO_SALUD     0.8000    0.6667    0.7273         6
         OTROS_SUJETO_ASISTENCIA     0.0000    0.0000    0.0000         7

                       micro avg     0.9651    0.9763    0.9707      5661
                       macro avg     0.8503    0.8756    0.8607      5661
                    weighted avg     0.9657    0.9763    0.9708      5661

2022-09-13 14:30:07,110 ----------------------------------------------------------------------------------------------------
