2022-09-13 14:31:01,254 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,256 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'es'
      (embedding): Embedding(985667, 300)
      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=False)
    )
    (list_embedding_1): TransformerWordEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(31002, 768, padding_idx=1)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (linear): Linear(in_features=1068, out_features=89, bias=True)
  (loss_function): CrossEntropyLoss()
)"
2022-09-13 14:31:01,256 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,256 Corpus: "Corpus: 10311 train + 5268 dev + 5155 test sentences"
2022-09-13 14:31:01,256 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,256 Parameters:
2022-09-13 14:31:01,256  - learning_rate: "0.000005"
2022-09-13 14:31:01,256  - mini_batch_size: "4"
2022-09-13 14:31:01,256  - patience: "3"
2022-09-13 14:31:01,256  - anneal_factor: "0.5"
2022-09-13 14:31:01,256  - max_epochs: "40"
2022-09-13 14:31:01,256  - shuffle: "True"
2022-09-13 14:31:01,257  - train_with_dev: "False"
2022-09-13 14:31:01,257  - batch_growth_annealing: "False"
2022-09-13 14:31:01,257 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,257 Model training base path: "experiments/corpus_sentence_bert_we_finetune/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_12)_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0"
2022-09-13 14:31:01,257 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,257 Device: cuda:1
2022-09-13 14:31:01,257 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:01,257 Embeddings storage mode: gpu
2022-09-13 14:31:01,257 ----------------------------------------------------------------------------------------------------
2022-09-13 14:31:32,962 epoch 1 - iter 257/2578 - loss 4.71129434 - samples/sec: 32.44 - lr: 0.000000
2022-09-13 14:32:06,581 epoch 1 - iter 514/2578 - loss 4.50613822 - samples/sec: 30.59 - lr: 0.000000
2022-09-13 14:32:46,853 epoch 1 - iter 771/2578 - loss 3.92415550 - samples/sec: 25.53 - lr: 0.000001
2022-09-13 14:33:26,319 epoch 1 - iter 1028/2578 - loss 3.19275734 - samples/sec: 26.06 - lr: 0.000001
2022-09-13 14:34:01,029 epoch 1 - iter 1285/2578 - loss 2.76112008 - samples/sec: 29.63 - lr: 0.000001
2022-09-13 14:34:39,635 epoch 1 - iter 1542/2578 - loss 2.38967602 - samples/sec: 26.64 - lr: 0.000001
2022-09-13 14:35:16,749 epoch 1 - iter 1799/2578 - loss 2.14604825 - samples/sec: 27.71 - lr: 0.000002
2022-09-13 14:35:55,100 epoch 1 - iter 2056/2578 - loss 1.92460604 - samples/sec: 26.81 - lr: 0.000002
2022-09-13 14:36:33,619 epoch 1 - iter 2313/2578 - loss 1.75177906 - samples/sec: 26.70 - lr: 0.000002
2022-09-13 14:37:08,052 epoch 1 - iter 2570/2578 - loss 1.63638535 - samples/sec: 29.87 - lr: 0.000002
2022-09-13 14:37:09,363 ----------------------------------------------------------------------------------------------------
2022-09-13 14:37:09,364 EPOCH 1 done: loss 1.6312 - lr 0.000002
2022-09-13 14:38:00,833 Evaluating as a multi-label problem: False
2022-09-13 14:38:00,883 DEV : loss 0.1480223685503006 - f1-score (micro avg)  0.8148
2022-09-13 14:38:01,226 BAD EPOCHS (no improvement): 4
2022-09-13 14:38:01,230 saving best model
2022-09-13 14:38:04,439 ----------------------------------------------------------------------------------------------------
2022-09-13 14:38:44,008 epoch 2 - iter 257/2578 - loss 0.39317606 - samples/sec: 25.99 - lr: 0.000003
2022-09-13 14:39:22,233 epoch 2 - iter 514/2578 - loss 0.39125704 - samples/sec: 26.90 - lr: 0.000003
2022-09-13 14:40:00,660 epoch 2 - iter 771/2578 - loss 0.37979046 - samples/sec: 26.76 - lr: 0.000003
2022-09-13 14:40:35,827 epoch 2 - iter 1028/2578 - loss 0.36765012 - samples/sec: 29.24 - lr: 0.000003
2022-09-13 14:41:14,643 epoch 2 - iter 1285/2578 - loss 0.35954490 - samples/sec: 26.49 - lr: 0.000004
2022-09-13 14:41:53,747 epoch 2 - iter 1542/2578 - loss 0.35228941 - samples/sec: 26.30 - lr: 0.000004
2022-09-13 14:42:33,674 epoch 2 - iter 1799/2578 - loss 0.34474419 - samples/sec: 25.76 - lr: 0.000004
2022-09-13 14:43:10,634 epoch 2 - iter 2056/2578 - loss 0.33947732 - samples/sec: 27.82 - lr: 0.000004
2022-09-13 14:43:46,879 epoch 2 - iter 2313/2578 - loss 0.33524717 - samples/sec: 28.37 - lr: 0.000005
2022-09-13 14:44:25,048 epoch 2 - iter 2570/2578 - loss 0.33033255 - samples/sec: 26.94 - lr: 0.000005
2022-09-13 14:44:26,521 ----------------------------------------------------------------------------------------------------
2022-09-13 14:44:26,521 EPOCH 2 done: loss 0.3298 - lr 0.000005
2022-09-13 14:45:17,072 Evaluating as a multi-label problem: False
2022-09-13 14:45:17,123 DEV : loss 0.06031970679759979 - f1-score (micro avg)  0.9019
2022-09-13 14:45:17,506 BAD EPOCHS (no improvement): 4
2022-09-13 14:45:17,510 saving best model
2022-09-13 14:45:31,755 ----------------------------------------------------------------------------------------------------
2022-09-13 14:46:07,410 epoch 3 - iter 257/2578 - loss 0.28792374 - samples/sec: 28.84 - lr: 0.000005
2022-09-13 14:46:43,136 epoch 3 - iter 514/2578 - loss 0.28395108 - samples/sec: 28.78 - lr: 0.000005
2022-09-13 14:47:22,761 epoch 3 - iter 771/2578 - loss 0.27741880 - samples/sec: 25.95 - lr: 0.000005
2022-09-13 14:48:00,591 epoch 3 - iter 1028/2578 - loss 0.27863652 - samples/sec: 27.18 - lr: 0.000005
2022-09-13 14:48:38,124 epoch 3 - iter 1285/2578 - loss 0.27794220 - samples/sec: 27.40 - lr: 0.000005
2022-09-13 14:49:15,483 epoch 3 - iter 1542/2578 - loss 0.27644170 - samples/sec: 27.53 - lr: 0.000005
2022-09-13 14:49:56,310 epoch 3 - iter 1799/2578 - loss 0.27348527 - samples/sec: 25.19 - lr: 0.000005
2022-09-13 14:50:34,669 epoch 3 - iter 2056/2578 - loss 0.27127143 - samples/sec: 26.81 - lr: 0.000005
2022-09-13 14:51:11,695 epoch 3 - iter 2313/2578 - loss 0.27048105 - samples/sec: 27.77 - lr: 0.000005
2022-09-13 14:51:50,363 epoch 3 - iter 2570/2578 - loss 0.26840488 - samples/sec: 26.59 - lr: 0.000005
2022-09-13 14:51:51,628 ----------------------------------------------------------------------------------------------------
2022-09-13 14:51:51,628 EPOCH 3 done: loss 0.2687 - lr 0.000005
2022-09-13 14:52:42,348 Evaluating as a multi-label problem: False
2022-09-13 14:52:42,398 DEV : loss 0.041734784841537476 - f1-score (micro avg)  0.9306
2022-09-13 14:52:42,768 BAD EPOCHS (no improvement): 4
2022-09-13 14:52:42,772 saving best model
2022-09-13 14:52:54,174 ----------------------------------------------------------------------------------------------------
2022-09-13 14:53:31,577 epoch 4 - iter 257/2578 - loss 0.26153500 - samples/sec: 27.50 - lr: 0.000005
2022-09-13 14:54:11,295 epoch 4 - iter 514/2578 - loss 0.25232975 - samples/sec: 25.89 - lr: 0.000005
2022-09-13 14:54:50,667 epoch 4 - iter 771/2578 - loss 0.25266400 - samples/sec: 26.12 - lr: 0.000005
2022-09-13 14:55:28,922 epoch 4 - iter 1028/2578 - loss 0.25683440 - samples/sec: 26.88 - lr: 0.000005
2022-09-13 14:56:05,072 epoch 4 - iter 1285/2578 - loss 0.25551309 - samples/sec: 28.45 - lr: 0.000005
2022-09-13 14:56:41,279 epoch 4 - iter 1542/2578 - loss 0.25443539 - samples/sec: 28.40 - lr: 0.000005
2022-09-13 14:57:17,137 epoch 4 - iter 1799/2578 - loss 0.25541172 - samples/sec: 28.68 - lr: 0.000005
2022-09-13 14:57:55,017 epoch 4 - iter 2056/2578 - loss 0.25398020 - samples/sec: 27.15 - lr: 0.000005
2022-09-13 14:58:34,659 epoch 4 - iter 2313/2578 - loss 0.25305971 - samples/sec: 25.94 - lr: 0.000005
2022-09-13 14:59:12,869 epoch 4 - iter 2570/2578 - loss 0.25388903 - samples/sec: 26.91 - lr: 0.000005
2022-09-13 14:59:14,032 ----------------------------------------------------------------------------------------------------
2022-09-13 14:59:14,032 EPOCH 4 done: loss 0.2537 - lr 0.000005
2022-09-13 15:00:04,820 Evaluating as a multi-label problem: False
2022-09-13 15:00:04,870 DEV : loss 0.032717883586883545 - f1-score (micro avg)  0.9476
2022-09-13 15:00:05,235 BAD EPOCHS (no improvement): 4
2022-09-13 15:00:05,239 saving best model
2022-09-13 15:00:16,478 ----------------------------------------------------------------------------------------------------
2022-09-13 15:00:53,499 epoch 5 - iter 257/2578 - loss 0.23915280 - samples/sec: 27.78 - lr: 0.000005
2022-09-13 15:01:32,510 epoch 5 - iter 514/2578 - loss 0.24476663 - samples/sec: 26.36 - lr: 0.000005
2022-09-13 15:02:08,895 epoch 5 - iter 771/2578 - loss 0.24499268 - samples/sec: 28.26 - lr: 0.000005
2022-09-13 15:02:45,702 epoch 5 - iter 1028/2578 - loss 0.24258065 - samples/sec: 27.94 - lr: 0.000005
2022-09-13 15:03:24,250 epoch 5 - iter 1285/2578 - loss 0.24160758 - samples/sec: 26.68 - lr: 0.000005
2022-09-13 15:04:02,267 epoch 5 - iter 1542/2578 - loss 0.24118795 - samples/sec: 27.05 - lr: 0.000005
2022-09-13 15:04:40,520 epoch 5 - iter 1799/2578 - loss 0.24225058 - samples/sec: 26.88 - lr: 0.000005
2022-09-13 15:05:18,814 epoch 5 - iter 2056/2578 - loss 0.24352299 - samples/sec: 26.85 - lr: 0.000005
2022-09-13 15:05:57,041 epoch 5 - iter 2313/2578 - loss 0.24318253 - samples/sec: 26.90 - lr: 0.000005
2022-09-13 15:06:35,605 epoch 5 - iter 2570/2578 - loss 0.24410544 - samples/sec: 26.67 - lr: 0.000005
2022-09-13 15:06:37,150 ----------------------------------------------------------------------------------------------------
2022-09-13 15:06:37,150 EPOCH 5 done: loss 0.2441 - lr 0.000005
2022-09-13 15:07:27,773 Evaluating as a multi-label problem: False
2022-09-13 15:07:27,822 DEV : loss 0.028417877852916718 - f1-score (micro avg)  0.9579
2022-09-13 15:07:28,190 BAD EPOCHS (no improvement): 4
2022-09-13 15:07:28,194 saving best model
2022-09-13 15:07:39,601 ----------------------------------------------------------------------------------------------------
2022-09-13 15:08:19,239 epoch 6 - iter 257/2578 - loss 0.24167215 - samples/sec: 25.95 - lr: 0.000005
2022-09-13 15:08:54,543 epoch 6 - iter 514/2578 - loss 0.23578971 - samples/sec: 29.13 - lr: 0.000005
2022-09-13 15:09:32,139 epoch 6 - iter 771/2578 - loss 0.23824234 - samples/sec: 27.35 - lr: 0.000005
2022-09-13 15:10:09,770 epoch 6 - iter 1028/2578 - loss 0.23656228 - samples/sec: 27.33 - lr: 0.000005
2022-09-13 15:10:47,086 epoch 6 - iter 1285/2578 - loss 0.23805310 - samples/sec: 27.56 - lr: 0.000005
2022-09-13 15:11:24,612 epoch 6 - iter 1542/2578 - loss 0.23873398 - samples/sec: 27.40 - lr: 0.000005
2022-09-13 15:12:03,544 epoch 6 - iter 1799/2578 - loss 0.23873518 - samples/sec: 26.41 - lr: 0.000005
2022-09-13 15:12:42,545 epoch 6 - iter 2056/2578 - loss 0.23821728 - samples/sec: 26.37 - lr: 0.000005
2022-09-13 15:13:20,054 epoch 6 - iter 2313/2578 - loss 0.24032984 - samples/sec: 27.42 - lr: 0.000004
2022-09-13 15:13:57,748 epoch 6 - iter 2570/2578 - loss 0.24022955 - samples/sec: 27.28 - lr: 0.000004
2022-09-13 15:13:58,865 ----------------------------------------------------------------------------------------------------
2022-09-13 15:13:58,865 EPOCH 6 done: loss 0.2403 - lr 0.000004
2022-09-13 15:14:49,433 Evaluating as a multi-label problem: False
2022-09-13 15:14:49,481 DEV : loss 0.028817860409617424 - f1-score (micro avg)  0.9611
2022-09-13 15:14:49,851 BAD EPOCHS (no improvement): 4
2022-09-13 15:14:49,855 saving best model
2022-09-13 15:15:01,283 ----------------------------------------------------------------------------------------------------
2022-09-13 15:15:39,426 epoch 7 - iter 257/2578 - loss 0.23300245 - samples/sec: 26.96 - lr: 0.000004
2022-09-13 15:16:19,439 epoch 7 - iter 514/2578 - loss 0.24002940 - samples/sec: 25.70 - lr: 0.000004
2022-09-13 15:16:57,283 epoch 7 - iter 771/2578 - loss 0.23831706 - samples/sec: 27.17 - lr: 0.000004
2022-09-13 15:17:36,305 epoch 7 - iter 1028/2578 - loss 0.23513930 - samples/sec: 26.35 - lr: 0.000004
2022-09-13 15:18:13,874 epoch 7 - iter 1285/2578 - loss 0.23708464 - samples/sec: 27.37 - lr: 0.000004
2022-09-13 15:18:49,895 epoch 7 - iter 1542/2578 - loss 0.23758819 - samples/sec: 28.55 - lr: 0.000004
2022-09-13 15:19:27,744 epoch 7 - iter 1799/2578 - loss 0.23689186 - samples/sec: 27.17 - lr: 0.000004
2022-09-13 15:20:07,352 epoch 7 - iter 2056/2578 - loss 0.23750724 - samples/sec: 25.96 - lr: 0.000004
2022-09-13 15:20:45,751 epoch 7 - iter 2313/2578 - loss 0.23644717 - samples/sec: 26.78 - lr: 0.000004
2022-09-13 15:21:19,883 epoch 7 - iter 2570/2578 - loss 0.23611645 - samples/sec: 30.13 - lr: 0.000004
2022-09-13 15:21:21,115 ----------------------------------------------------------------------------------------------------
2022-09-13 15:21:21,115 EPOCH 7 done: loss 0.2361 - lr 0.000004
2022-09-13 15:22:13,014 Evaluating as a multi-label problem: False
2022-09-13 15:22:13,063 DEV : loss 0.02786894515156746 - f1-score (micro avg)  0.9666
2022-09-13 15:22:13,434 BAD EPOCHS (no improvement): 4
2022-09-13 15:22:13,438 saving best model
2022-09-13 15:22:24,767 ----------------------------------------------------------------------------------------------------
2022-09-13 15:23:00,233 epoch 8 - iter 257/2578 - loss 0.22834015 - samples/sec: 29.00 - lr: 0.000004
2022-09-13 15:23:38,435 epoch 8 - iter 514/2578 - loss 0.22913866 - samples/sec: 26.92 - lr: 0.000004
2022-09-13 15:24:15,983 epoch 8 - iter 771/2578 - loss 0.22902730 - samples/sec: 27.39 - lr: 0.000004
2022-09-13 15:24:54,873 epoch 8 - iter 1028/2578 - loss 0.22706765 - samples/sec: 26.44 - lr: 0.000004
2022-09-13 15:25:31,776 epoch 8 - iter 1285/2578 - loss 0.22692066 - samples/sec: 27.87 - lr: 0.000004
2022-09-13 15:26:08,371 epoch 8 - iter 1542/2578 - loss 0.22749123 - samples/sec: 28.10 - lr: 0.000004
2022-09-13 15:26:45,963 epoch 8 - iter 1799/2578 - loss 0.22731803 - samples/sec: 27.36 - lr: 0.000004
2022-09-13 15:27:24,082 epoch 8 - iter 2056/2578 - loss 0.22805633 - samples/sec: 26.98 - lr: 0.000004
2022-09-13 15:28:03,110 epoch 8 - iter 2313/2578 - loss 0.22808379 - samples/sec: 26.35 - lr: 0.000004
2022-09-13 15:28:43,368 epoch 8 - iter 2570/2578 - loss 0.22783677 - samples/sec: 25.54 - lr: 0.000004
2022-09-13 15:28:44,460 ----------------------------------------------------------------------------------------------------
2022-09-13 15:28:44,460 EPOCH 8 done: loss 0.2276 - lr 0.000004
2022-09-13 15:29:35,361 Evaluating as a multi-label problem: False
2022-09-13 15:29:35,410 DEV : loss 0.02690071240067482 - f1-score (micro avg)  0.9675
2022-09-13 15:29:35,777 BAD EPOCHS (no improvement): 4
2022-09-13 15:29:35,781 saving best model
2022-09-13 15:29:47,172 ----------------------------------------------------------------------------------------------------
2022-09-13 15:30:24,689 epoch 9 - iter 257/2578 - loss 0.23820111 - samples/sec: 27.41 - lr: 0.000004
2022-09-13 15:31:04,013 epoch 9 - iter 514/2578 - loss 0.22872990 - samples/sec: 26.15 - lr: 0.000004
2022-09-13 15:31:41,571 epoch 9 - iter 771/2578 - loss 0.23317602 - samples/sec: 27.38 - lr: 0.000004
2022-09-13 15:32:18,375 epoch 9 - iter 1028/2578 - loss 0.23286459 - samples/sec: 27.94 - lr: 0.000004
2022-09-13 15:32:56,807 epoch 9 - iter 1285/2578 - loss 0.23170791 - samples/sec: 26.76 - lr: 0.000004
2022-09-13 15:33:34,777 epoch 9 - iter 1542/2578 - loss 0.23325084 - samples/sec: 27.08 - lr: 0.000004
2022-09-13 15:34:11,717 epoch 9 - iter 1799/2578 - loss 0.23277747 - samples/sec: 27.84 - lr: 0.000004
2022-09-13 15:34:51,160 epoch 9 - iter 2056/2578 - loss 0.23187900 - samples/sec: 26.07 - lr: 0.000004
2022-09-13 15:35:28,838 epoch 9 - iter 2313/2578 - loss 0.23069845 - samples/sec: 27.29 - lr: 0.000004
2022-09-13 15:36:05,961 epoch 9 - iter 2570/2578 - loss 0.23061266 - samples/sec: 27.70 - lr: 0.000004
2022-09-13 15:36:06,850 ----------------------------------------------------------------------------------------------------
2022-09-13 15:36:06,851 EPOCH 9 done: loss 0.2306 - lr 0.000004
2022-09-13 15:36:57,693 Evaluating as a multi-label problem: False
2022-09-13 15:36:57,740 DEV : loss 0.02960006520152092 - f1-score (micro avg)  0.968
2022-09-13 15:36:58,108 BAD EPOCHS (no improvement): 4
2022-09-13 15:36:58,112 saving best model
2022-09-13 15:37:09,580 ----------------------------------------------------------------------------------------------------
2022-09-13 15:37:47,365 epoch 10 - iter 257/2578 - loss 0.23343656 - samples/sec: 27.22 - lr: 0.000004
2022-09-13 15:38:27,007 epoch 10 - iter 514/2578 - loss 0.22952439 - samples/sec: 25.94 - lr: 0.000004
2022-09-13 15:39:07,074 epoch 10 - iter 771/2578 - loss 0.22572973 - samples/sec: 25.67 - lr: 0.000004
2022-09-13 15:39:48,236 epoch 10 - iter 1028/2578 - loss 0.22443777 - samples/sec: 24.98 - lr: 0.000004
2022-09-13 15:40:23,660 epoch 10 - iter 1285/2578 - loss 0.22299158 - samples/sec: 29.03 - lr: 0.000004
2022-09-13 15:41:01,124 epoch 10 - iter 1542/2578 - loss 0.22336101 - samples/sec: 27.45 - lr: 0.000004
2022-09-13 15:41:38,848 epoch 10 - iter 1799/2578 - loss 0.22350047 - samples/sec: 27.26 - lr: 0.000004
2022-09-13 15:42:14,536 epoch 10 - iter 2056/2578 - loss 0.22455787 - samples/sec: 28.82 - lr: 0.000004
2022-09-13 15:42:50,528 epoch 10 - iter 2313/2578 - loss 0.22476691 - samples/sec: 28.57 - lr: 0.000004
2022-09-13 15:43:28,275 epoch 10 - iter 2570/2578 - loss 0.22437056 - samples/sec: 27.24 - lr: 0.000004
2022-09-13 15:43:29,318 ----------------------------------------------------------------------------------------------------
2022-09-13 15:43:29,318 EPOCH 10 done: loss 0.2243 - lr 0.000004
2022-09-13 15:44:20,026 Evaluating as a multi-label problem: False
2022-09-13 15:44:20,074 DEV : loss 0.02880937047302723 - f1-score (micro avg)  0.9686
2022-09-13 15:44:20,445 BAD EPOCHS (no improvement): 4
2022-09-13 15:44:20,449 saving best model
2022-09-13 15:44:31,855 ----------------------------------------------------------------------------------------------------
2022-09-13 15:45:08,863 epoch 11 - iter 257/2578 - loss 0.22489648 - samples/sec: 27.79 - lr: 0.000004
2022-09-13 15:45:47,207 epoch 11 - iter 514/2578 - loss 0.22640149 - samples/sec: 26.82 - lr: 0.000004
2022-09-13 15:46:27,494 epoch 11 - iter 771/2578 - loss 0.22854484 - samples/sec: 25.53 - lr: 0.000004
2022-09-13 15:47:04,198 epoch 11 - iter 1028/2578 - loss 0.22933984 - samples/sec: 28.02 - lr: 0.000004
2022-09-13 15:47:43,167 epoch 11 - iter 1285/2578 - loss 0.22992674 - samples/sec: 26.39 - lr: 0.000004
2022-09-13 15:48:21,687 epoch 11 - iter 1542/2578 - loss 0.22758988 - samples/sec: 26.70 - lr: 0.000004
2022-09-13 15:48:59,912 epoch 11 - iter 1799/2578 - loss 0.22651099 - samples/sec: 26.90 - lr: 0.000004
2022-09-13 15:49:38,969 epoch 11 - iter 2056/2578 - loss 0.22619503 - samples/sec: 26.33 - lr: 0.000004
2022-09-13 15:50:16,724 epoch 11 - iter 2313/2578 - loss 0.22620197 - samples/sec: 27.24 - lr: 0.000004
2022-09-13 15:50:52,126 epoch 11 - iter 2570/2578 - loss 0.22777657 - samples/sec: 29.05 - lr: 0.000004
2022-09-13 15:50:53,403 ----------------------------------------------------------------------------------------------------
2022-09-13 15:50:53,403 EPOCH 11 done: loss 0.2278 - lr 0.000004
2022-09-13 15:51:44,078 Evaluating as a multi-label problem: False
2022-09-13 15:51:44,126 DEV : loss 0.02940770424902439 - f1-score (micro avg)  0.9698
2022-09-13 15:51:44,495 BAD EPOCHS (no improvement): 4
2022-09-13 15:51:44,499 saving best model
2022-09-13 15:51:55,905 ----------------------------------------------------------------------------------------------------
2022-09-13 15:52:30,307 epoch 12 - iter 257/2578 - loss 0.22096597 - samples/sec: 29.89 - lr: 0.000004
2022-09-13 15:53:07,981 epoch 12 - iter 514/2578 - loss 0.22436529 - samples/sec: 27.30 - lr: 0.000004
2022-09-13 15:53:45,923 epoch 12 - iter 771/2578 - loss 0.22304137 - samples/sec: 27.10 - lr: 0.000004
2022-09-13 15:54:24,685 epoch 12 - iter 1028/2578 - loss 0.22605006 - samples/sec: 26.53 - lr: 0.000004
2022-09-13 15:55:01,433 epoch 12 - iter 1285/2578 - loss 0.22462050 - samples/sec: 27.98 - lr: 0.000004
2022-09-13 15:55:42,660 epoch 12 - iter 1542/2578 - loss 0.22311511 - samples/sec: 24.94 - lr: 0.000004
2022-09-13 15:56:20,861 epoch 12 - iter 1799/2578 - loss 0.22357934 - samples/sec: 26.92 - lr: 0.000004
2022-09-13 15:56:57,350 epoch 12 - iter 2056/2578 - loss 0.22308582 - samples/sec: 28.18 - lr: 0.000004
2022-09-13 15:57:35,532 epoch 12 - iter 2313/2578 - loss 0.22325424 - samples/sec: 26.93 - lr: 0.000004
2022-09-13 15:58:15,726 epoch 12 - iter 2570/2578 - loss 0.22330132 - samples/sec: 25.58 - lr: 0.000004
2022-09-13 15:58:16,863 ----------------------------------------------------------------------------------------------------
2022-09-13 15:58:16,863 EPOCH 12 done: loss 0.2235 - lr 0.000004
2022-09-13 15:59:07,800 Evaluating as a multi-label problem: False
2022-09-13 15:59:07,848 DEV : loss 0.03093055449426174 - f1-score (micro avg)  0.9691
2022-09-13 15:59:08,214 BAD EPOCHS (no improvement): 4
2022-09-13 15:59:08,218 ----------------------------------------------------------------------------------------------------
2022-09-13 15:59:46,187 epoch 13 - iter 257/2578 - loss 0.21878394 - samples/sec: 27.09 - lr: 0.000004
2022-09-13 16:00:22,630 epoch 13 - iter 514/2578 - loss 0.22241354 - samples/sec: 28.22 - lr: 0.000004
2022-09-13 16:01:00,336 epoch 13 - iter 771/2578 - loss 0.21976713 - samples/sec: 27.27 - lr: 0.000004
2022-09-13 16:01:42,208 epoch 13 - iter 1028/2578 - loss 0.21969885 - samples/sec: 24.56 - lr: 0.000004
2022-09-13 16:02:21,346 epoch 13 - iter 1285/2578 - loss 0.22124605 - samples/sec: 26.27 - lr: 0.000004
2022-09-13 16:03:00,476 epoch 13 - iter 1542/2578 - loss 0.22025030 - samples/sec: 26.28 - lr: 0.000004
2022-09-13 16:03:37,365 epoch 13 - iter 1799/2578 - loss 0.22309922 - samples/sec: 27.88 - lr: 0.000004
2022-09-13 16:04:14,871 epoch 13 - iter 2056/2578 - loss 0.22178943 - samples/sec: 27.42 - lr: 0.000004
2022-09-13 16:04:53,813 epoch 13 - iter 2313/2578 - loss 0.22090354 - samples/sec: 26.41 - lr: 0.000004
2022-09-13 16:05:31,396 epoch 13 - iter 2570/2578 - loss 0.22121594 - samples/sec: 27.36 - lr: 0.000004
2022-09-13 16:05:32,405 ----------------------------------------------------------------------------------------------------
2022-09-13 16:05:32,406 EPOCH 13 done: loss 0.2213 - lr 0.000004
2022-09-13 16:06:23,937 Evaluating as a multi-label problem: False
2022-09-13 16:06:23,985 DEV : loss 0.03160492330789566 - f1-score (micro avg)  0.968
2022-09-13 16:06:24,351 BAD EPOCHS (no improvement): 4
2022-09-13 16:06:24,356 ----------------------------------------------------------------------------------------------------
2022-09-13 16:07:03,396 epoch 14 - iter 257/2578 - loss 0.22149027 - samples/sec: 26.35 - lr: 0.000004
2022-09-13 16:07:42,017 epoch 14 - iter 514/2578 - loss 0.21810198 - samples/sec: 26.63 - lr: 0.000004
2022-09-13 16:08:22,713 epoch 14 - iter 771/2578 - loss 0.21920114 - samples/sec: 25.27 - lr: 0.000004
2022-09-13 16:09:02,214 epoch 14 - iter 1028/2578 - loss 0.21985755 - samples/sec: 26.03 - lr: 0.000004
2022-09-13 16:09:39,639 epoch 14 - iter 1285/2578 - loss 0.22066294 - samples/sec: 27.48 - lr: 0.000003
2022-09-13 16:10:15,967 epoch 14 - iter 1542/2578 - loss 0.21989428 - samples/sec: 28.31 - lr: 0.000003
2022-09-13 16:10:54,067 epoch 14 - iter 1799/2578 - loss 0.22087306 - samples/sec: 26.99 - lr: 0.000003
2022-09-13 16:11:31,125 epoch 14 - iter 2056/2578 - loss 0.22301058 - samples/sec: 27.75 - lr: 0.000003
2022-09-13 16:12:09,178 epoch 14 - iter 2313/2578 - loss 0.22336537 - samples/sec: 27.02 - lr: 0.000003
2022-09-13 16:12:46,059 epoch 14 - iter 2570/2578 - loss 0.22330833 - samples/sec: 27.88 - lr: 0.000003
2022-09-13 16:12:47,272 ----------------------------------------------------------------------------------------------------
2022-09-13 16:12:47,273 EPOCH 14 done: loss 0.2232 - lr 0.000003
2022-09-13 16:13:38,195 Evaluating as a multi-label problem: False
2022-09-13 16:13:38,243 DEV : loss 0.03242998197674751 - f1-score (micro avg)  0.9702
2022-09-13 16:13:38,615 BAD EPOCHS (no improvement): 4
2022-09-13 16:13:38,620 saving best model
2022-09-13 16:13:49,902 ----------------------------------------------------------------------------------------------------
2022-09-13 16:14:28,823 epoch 15 - iter 257/2578 - loss 0.21589500 - samples/sec: 26.42 - lr: 0.000003
2022-09-13 16:15:06,135 epoch 15 - iter 514/2578 - loss 0.22109107 - samples/sec: 27.56 - lr: 0.000003
2022-09-13 16:15:42,969 epoch 15 - iter 771/2578 - loss 0.22321919 - samples/sec: 27.92 - lr: 0.000003
2022-09-13 16:16:20,998 epoch 15 - iter 1028/2578 - loss 0.22166825 - samples/sec: 27.04 - lr: 0.000003
2022-09-13 16:16:59,111 epoch 15 - iter 1285/2578 - loss 0.22294698 - samples/sec: 26.98 - lr: 0.000003
2022-09-13 16:17:38,381 epoch 15 - iter 1542/2578 - loss 0.22090055 - samples/sec: 26.19 - lr: 0.000003
2022-09-13 16:18:16,039 epoch 15 - iter 1799/2578 - loss 0.22100546 - samples/sec: 27.31 - lr: 0.000003
2022-09-13 16:18:54,452 epoch 15 - iter 2056/2578 - loss 0.22099088 - samples/sec: 26.77 - lr: 0.000003
2022-09-13 16:19:31,231 epoch 15 - iter 2313/2578 - loss 0.22103264 - samples/sec: 27.96 - lr: 0.000003
2022-09-13 16:20:09,281 epoch 15 - iter 2570/2578 - loss 0.22098689 - samples/sec: 27.03 - lr: 0.000003
2022-09-13 16:20:10,088 ----------------------------------------------------------------------------------------------------
2022-09-13 16:20:10,089 EPOCH 15 done: loss 0.2209 - lr 0.000003
2022-09-13 16:21:00,940 Evaluating as a multi-label problem: False
2022-09-13 16:21:00,988 DEV : loss 0.031669847667217255 - f1-score (micro avg)  0.9707
2022-09-13 16:21:01,357 BAD EPOCHS (no improvement): 4
2022-09-13 16:21:01,361 saving best model
2022-09-13 16:21:12,769 ----------------------------------------------------------------------------------------------------
2022-09-13 16:21:51,867 epoch 16 - iter 257/2578 - loss 0.21996785 - samples/sec: 26.30 - lr: 0.000003
2022-09-13 16:22:30,365 epoch 16 - iter 514/2578 - loss 0.22462319 - samples/sec: 26.71 - lr: 0.000003
2022-09-13 16:23:07,023 epoch 16 - iter 771/2578 - loss 0.22528485 - samples/sec: 28.05 - lr: 0.000003
2022-09-13 16:23:43,780 epoch 16 - iter 1028/2578 - loss 0.22138433 - samples/sec: 27.98 - lr: 0.000003
2022-09-13 16:24:21,214 epoch 16 - iter 1285/2578 - loss 0.21946090 - samples/sec: 27.47 - lr: 0.000003
2022-09-13 16:25:00,187 epoch 16 - iter 1542/2578 - loss 0.21894293 - samples/sec: 26.39 - lr: 0.000003
2022-09-13 16:25:37,957 epoch 16 - iter 1799/2578 - loss 0.21825625 - samples/sec: 27.23 - lr: 0.000003
2022-09-13 16:26:14,790 epoch 16 - iter 2056/2578 - loss 0.21779262 - samples/sec: 27.92 - lr: 0.000003
2022-09-13 16:26:54,826 epoch 16 - iter 2313/2578 - loss 0.21779655 - samples/sec: 25.69 - lr: 0.000003
2022-09-13 16:27:33,552 epoch 16 - iter 2570/2578 - loss 0.21873970 - samples/sec: 26.55 - lr: 0.000003
2022-09-13 16:27:34,806 ----------------------------------------------------------------------------------------------------
2022-09-13 16:27:34,806 EPOCH 16 done: loss 0.2187 - lr 0.000003
2022-09-13 16:28:25,570 Evaluating as a multi-label problem: False
2022-09-13 16:28:25,618 DEV : loss 0.033690035343170166 - f1-score (micro avg)  0.9718
2022-09-13 16:28:25,988 BAD EPOCHS (no improvement): 4
2022-09-13 16:28:25,992 saving best model
2022-09-13 16:28:37,416 ----------------------------------------------------------------------------------------------------
2022-09-13 16:29:12,055 epoch 17 - iter 257/2578 - loss 0.21663026 - samples/sec: 29.69 - lr: 0.000003
2022-09-13 16:29:49,010 epoch 17 - iter 514/2578 - loss 0.22286970 - samples/sec: 27.83 - lr: 0.000003
2022-09-13 16:30:26,374 epoch 17 - iter 771/2578 - loss 0.21762328 - samples/sec: 27.52 - lr: 0.000003
2022-09-13 16:31:04,547 epoch 17 - iter 1028/2578 - loss 0.21478332 - samples/sec: 26.94 - lr: 0.000003
2022-09-13 16:31:43,935 epoch 17 - iter 1285/2578 - loss 0.21617137 - samples/sec: 26.11 - lr: 0.000003
2022-09-13 16:32:22,531 epoch 17 - iter 1542/2578 - loss 0.21649780 - samples/sec: 26.64 - lr: 0.000003
2022-09-13 16:33:03,110 epoch 17 - iter 1799/2578 - loss 0.21693158 - samples/sec: 25.34 - lr: 0.000003
2022-09-13 16:33:41,455 epoch 17 - iter 2056/2578 - loss 0.21741666 - samples/sec: 26.82 - lr: 0.000003
2022-09-13 16:34:21,394 epoch 17 - iter 2313/2578 - loss 0.21664406 - samples/sec: 25.75 - lr: 0.000003
2022-09-13 16:34:58,273 epoch 17 - iter 2570/2578 - loss 0.21745800 - samples/sec: 27.89 - lr: 0.000003
2022-09-13 16:34:59,557 ----------------------------------------------------------------------------------------------------
2022-09-13 16:34:59,558 EPOCH 17 done: loss 0.2175 - lr 0.000003
2022-09-13 16:35:50,236 Evaluating as a multi-label problem: False
2022-09-13 16:35:50,284 DEV : loss 0.03338336944580078 - f1-score (micro avg)  0.97
2022-09-13 16:35:50,651 BAD EPOCHS (no improvement): 4
2022-09-13 16:35:50,655 ----------------------------------------------------------------------------------------------------
2022-09-13 16:36:29,310 epoch 18 - iter 257/2578 - loss 0.22418358 - samples/sec: 26.61 - lr: 0.000003
2022-09-13 16:37:06,806 epoch 18 - iter 514/2578 - loss 0.21993031 - samples/sec: 27.43 - lr: 0.000003
2022-09-13 16:37:44,925 epoch 18 - iter 771/2578 - loss 0.21852435 - samples/sec: 26.98 - lr: 0.000003
2022-09-13 16:38:22,327 epoch 18 - iter 1028/2578 - loss 0.21678579 - samples/sec: 27.49 - lr: 0.000003
2022-09-13 16:39:02,396 epoch 18 - iter 1285/2578 - loss 0.21758434 - samples/sec: 25.66 - lr: 0.000003
2022-09-13 16:39:40,392 epoch 18 - iter 1542/2578 - loss 0.21746629 - samples/sec: 27.06 - lr: 0.000003
2022-09-13 16:40:17,420 epoch 18 - iter 1799/2578 - loss 0.21749081 - samples/sec: 27.77 - lr: 0.000003
2022-09-13 16:40:58,811 epoch 18 - iter 2056/2578 - loss 0.21745940 - samples/sec: 24.84 - lr: 0.000003
2022-09-13 16:41:36,296 epoch 18 - iter 2313/2578 - loss 0.21670944 - samples/sec: 27.43 - lr: 0.000003
2022-09-13 16:42:13,202 epoch 18 - iter 2570/2578 - loss 0.21756642 - samples/sec: 27.86 - lr: 0.000003
2022-09-13 16:42:14,262 ----------------------------------------------------------------------------------------------------
2022-09-13 16:42:14,262 EPOCH 18 done: loss 0.2176 - lr 0.000003
2022-09-13 16:43:05,954 Evaluating as a multi-label problem: False
2022-09-13 16:43:06,002 DEV : loss 0.03577391058206558 - f1-score (micro avg)  0.9712
2022-09-13 16:43:06,372 BAD EPOCHS (no improvement): 4
2022-09-13 16:43:06,376 ----------------------------------------------------------------------------------------------------
2022-09-13 16:43:45,065 epoch 19 - iter 257/2578 - loss 0.21768086 - samples/sec: 26.59 - lr: 0.000003
2022-09-13 16:44:23,409 epoch 19 - iter 514/2578 - loss 0.22050777 - samples/sec: 26.82 - lr: 0.000003
2022-09-13 16:45:02,267 epoch 19 - iter 771/2578 - loss 0.21857295 - samples/sec: 26.46 - lr: 0.000003
2022-09-13 16:45:42,327 epoch 19 - iter 1028/2578 - loss 0.21642742 - samples/sec: 25.67 - lr: 0.000003
2022-09-13 16:46:20,565 epoch 19 - iter 1285/2578 - loss 0.21660632 - samples/sec: 26.89 - lr: 0.000003
2022-09-13 16:46:57,245 epoch 19 - iter 1542/2578 - loss 0.21703768 - samples/sec: 28.04 - lr: 0.000003
2022-09-13 16:47:35,141 epoch 19 - iter 1799/2578 - loss 0.21667972 - samples/sec: 27.14 - lr: 0.000003
2022-09-13 16:48:13,197 epoch 19 - iter 2056/2578 - loss 0.21666897 - samples/sec: 27.02 - lr: 0.000003
2022-09-13 16:48:51,581 epoch 19 - iter 2313/2578 - loss 0.21676476 - samples/sec: 26.79 - lr: 0.000003
2022-09-13 16:49:28,713 epoch 19 - iter 2570/2578 - loss 0.21608318 - samples/sec: 27.69 - lr: 0.000003
2022-09-13 16:49:29,574 ----------------------------------------------------------------------------------------------------
2022-09-13 16:49:29,574 EPOCH 19 done: loss 0.2161 - lr 0.000003
2022-09-13 16:50:20,363 Evaluating as a multi-label problem: False
2022-09-13 16:50:20,410 DEV : loss 0.034349143505096436 - f1-score (micro avg)  0.9708
2022-09-13 16:50:20,781 BAD EPOCHS (no improvement): 4
2022-09-13 16:50:20,785 ----------------------------------------------------------------------------------------------------
2022-09-13 16:51:00,614 epoch 20 - iter 257/2578 - loss 0.20929946 - samples/sec: 25.82 - lr: 0.000003
2022-09-13 16:51:39,206 epoch 20 - iter 514/2578 - loss 0.20831192 - samples/sec: 26.65 - lr: 0.000003
2022-09-13 16:52:15,042 epoch 20 - iter 771/2578 - loss 0.21276640 - samples/sec: 28.70 - lr: 0.000003
2022-09-13 16:52:51,613 epoch 20 - iter 1028/2578 - loss 0.21200882 - samples/sec: 28.12 - lr: 0.000003
2022-09-13 16:53:30,468 epoch 20 - iter 1285/2578 - loss 0.21009850 - samples/sec: 26.47 - lr: 0.000003
2022-09-13 16:54:07,036 epoch 20 - iter 1542/2578 - loss 0.20959081 - samples/sec: 28.12 - lr: 0.000003
2022-09-13 16:54:46,913 epoch 20 - iter 1799/2578 - loss 0.21198973 - samples/sec: 25.79 - lr: 0.000003
2022-09-13 16:55:25,480 epoch 20 - iter 2056/2578 - loss 0.21193374 - samples/sec: 26.66 - lr: 0.000003
2022-09-13 16:56:05,087 epoch 20 - iter 2313/2578 - loss 0.21264811 - samples/sec: 25.96 - lr: 0.000003
2022-09-13 16:56:42,642 epoch 20 - iter 2570/2578 - loss 0.21228149 - samples/sec: 27.38 - lr: 0.000003
2022-09-13 16:56:43,860 ----------------------------------------------------------------------------------------------------
2022-09-13 16:56:43,860 EPOCH 20 done: loss 0.2122 - lr 0.000003
2022-09-13 16:57:34,617 Evaluating as a multi-label problem: False
2022-09-13 16:57:34,665 DEV : loss 0.038751740008592606 - f1-score (micro avg)  0.9727
2022-09-13 16:57:35,030 BAD EPOCHS (no improvement): 4
2022-09-13 16:57:35,034 saving best model
2022-09-13 16:57:46,213 ----------------------------------------------------------------------------------------------------
2022-09-13 16:58:23,029 epoch 21 - iter 257/2578 - loss 0.22349439 - samples/sec: 27.93 - lr: 0.000003
2022-09-13 16:58:59,596 epoch 21 - iter 514/2578 - loss 0.21981816 - samples/sec: 28.12 - lr: 0.000003
2022-09-13 16:59:36,728 epoch 21 - iter 771/2578 - loss 0.21785973 - samples/sec: 27.70 - lr: 0.000003
2022-09-13 17:00:14,613 epoch 21 - iter 1028/2578 - loss 0.21825908 - samples/sec: 27.14 - lr: 0.000003
2022-09-13 17:00:54,699 epoch 21 - iter 1285/2578 - loss 0.21673734 - samples/sec: 25.65 - lr: 0.000003
2022-09-13 17:01:31,810 epoch 21 - iter 1542/2578 - loss 0.21656377 - samples/sec: 27.71 - lr: 0.000003
2022-09-13 17:02:09,803 epoch 21 - iter 1799/2578 - loss 0.21603598 - samples/sec: 27.07 - lr: 0.000003
2022-09-13 17:02:49,918 epoch 21 - iter 2056/2578 - loss 0.21621329 - samples/sec: 25.63 - lr: 0.000003
2022-09-13 17:03:29,920 epoch 21 - iter 2313/2578 - loss 0.21623459 - samples/sec: 25.71 - lr: 0.000003
2022-09-13 17:04:07,065 epoch 21 - iter 2570/2578 - loss 0.21579294 - samples/sec: 27.68 - lr: 0.000003
2022-09-13 17:04:08,048 ----------------------------------------------------------------------------------------------------
2022-09-13 17:04:08,048 EPOCH 21 done: loss 0.2157 - lr 0.000003
2022-09-13 17:04:58,769 Evaluating as a multi-label problem: False
2022-09-13 17:04:58,817 DEV : loss 0.035542454570531845 - f1-score (micro avg)  0.9713
2022-09-13 17:04:59,185 BAD EPOCHS (no improvement): 4
2022-09-13 17:04:59,189 ----------------------------------------------------------------------------------------------------
2022-09-13 17:05:37,835 epoch 22 - iter 257/2578 - loss 0.20874979 - samples/sec: 26.62 - lr: 0.000002
2022-09-13 17:06:16,734 epoch 22 - iter 514/2578 - loss 0.21047103 - samples/sec: 26.44 - lr: 0.000002
2022-09-13 17:06:55,239 epoch 22 - iter 771/2578 - loss 0.21104213 - samples/sec: 26.71 - lr: 0.000002
2022-09-13 17:07:33,180 epoch 22 - iter 1028/2578 - loss 0.21021245 - samples/sec: 27.10 - lr: 0.000002
2022-09-13 17:08:11,017 epoch 22 - iter 1285/2578 - loss 0.21160029 - samples/sec: 27.18 - lr: 0.000002
2022-09-13 17:08:48,849 epoch 22 - iter 1542/2578 - loss 0.21343176 - samples/sec: 27.18 - lr: 0.000002
2022-09-13 17:09:27,832 epoch 22 - iter 1799/2578 - loss 0.21364241 - samples/sec: 26.38 - lr: 0.000002
2022-09-13 17:10:05,562 epoch 22 - iter 2056/2578 - loss 0.21385366 - samples/sec: 27.26 - lr: 0.000002
2022-09-13 17:10:40,972 epoch 22 - iter 2313/2578 - loss 0.21341967 - samples/sec: 29.04 - lr: 0.000002
2022-09-13 17:11:21,072 epoch 22 - iter 2570/2578 - loss 0.21374209 - samples/sec: 25.64 - lr: 0.000002
2022-09-13 17:11:22,088 ----------------------------------------------------------------------------------------------------
2022-09-13 17:11:22,088 EPOCH 22 done: loss 0.2136 - lr 0.000002
2022-09-13 17:12:12,893 Evaluating as a multi-label problem: False
2022-09-13 17:12:12,941 DEV : loss 0.0348016694188118 - f1-score (micro avg)  0.9715
2022-09-13 17:12:13,312 BAD EPOCHS (no improvement): 4
2022-09-13 17:12:13,316 ----------------------------------------------------------------------------------------------------
2022-09-13 17:12:50,469 epoch 23 - iter 257/2578 - loss 0.21821723 - samples/sec: 27.69 - lr: 0.000002
2022-09-13 17:13:27,540 epoch 23 - iter 514/2578 - loss 0.21015027 - samples/sec: 27.74 - lr: 0.000002
2022-09-13 17:14:06,982 epoch 23 - iter 771/2578 - loss 0.21823829 - samples/sec: 26.07 - lr: 0.000002
2022-09-13 17:14:43,949 epoch 23 - iter 1028/2578 - loss 0.21614677 - samples/sec: 27.82 - lr: 0.000002
2022-09-13 17:15:23,895 epoch 23 - iter 1285/2578 - loss 0.21538493 - samples/sec: 25.74 - lr: 0.000002
2022-09-13 17:16:01,357 epoch 23 - iter 1542/2578 - loss 0.21449144 - samples/sec: 27.45 - lr: 0.000002
2022-09-13 17:16:40,571 epoch 23 - iter 1799/2578 - loss 0.21348794 - samples/sec: 26.22 - lr: 0.000002
2022-09-13 17:17:19,025 epoch 23 - iter 2056/2578 - loss 0.21302883 - samples/sec: 26.74 - lr: 0.000002
2022-09-13 17:17:55,624 epoch 23 - iter 2313/2578 - loss 0.21376824 - samples/sec: 28.10 - lr: 0.000002
2022-09-13 17:18:35,179 epoch 23 - iter 2570/2578 - loss 0.21378305 - samples/sec: 26.00 - lr: 0.000002
2022-09-13 17:18:36,194 ----------------------------------------------------------------------------------------------------
2022-09-13 17:18:36,195 EPOCH 23 done: loss 0.2138 - lr 0.000002
2022-09-13 17:19:28,043 Evaluating as a multi-label problem: False
2022-09-13 17:19:28,090 DEV : loss 0.03664853051304817 - f1-score (micro avg)  0.9697
2022-09-13 17:19:28,463 BAD EPOCHS (no improvement): 4
2022-09-13 17:19:28,467 ----------------------------------------------------------------------------------------------------
2022-09-13 17:20:08,935 epoch 24 - iter 257/2578 - loss 0.21236965 - samples/sec: 25.42 - lr: 0.000002
2022-09-13 17:20:47,156 epoch 24 - iter 514/2578 - loss 0.21035108 - samples/sec: 26.91 - lr: 0.000002
2022-09-13 17:21:24,404 epoch 24 - iter 771/2578 - loss 0.21290772 - samples/sec: 27.61 - lr: 0.000002
2022-09-13 17:22:01,775 epoch 24 - iter 1028/2578 - loss 0.21270616 - samples/sec: 27.52 - lr: 0.000002
2022-09-13 17:22:39,268 epoch 24 - iter 1285/2578 - loss 0.21195570 - samples/sec: 27.43 - lr: 0.000002
2022-09-13 17:23:17,801 epoch 24 - iter 1542/2578 - loss 0.21143702 - samples/sec: 26.69 - lr: 0.000002
2022-09-13 17:23:54,932 epoch 24 - iter 1799/2578 - loss 0.21349795 - samples/sec: 27.70 - lr: 0.000002
2022-09-13 17:24:31,770 epoch 24 - iter 2056/2578 - loss 0.21453376 - samples/sec: 27.92 - lr: 0.000002
2022-09-13 17:25:09,421 epoch 24 - iter 2313/2578 - loss 0.21477667 - samples/sec: 27.31 - lr: 0.000002
2022-09-13 17:25:49,200 epoch 24 - iter 2570/2578 - loss 0.21513875 - samples/sec: 25.85 - lr: 0.000002
2022-09-13 17:25:50,712 ----------------------------------------------------------------------------------------------------
2022-09-13 17:25:50,712 EPOCH 24 done: loss 0.2151 - lr 0.000002
2022-09-13 17:26:41,462 Evaluating as a multi-label problem: False
2022-09-13 17:26:41,510 DEV : loss 0.03687803074717522 - f1-score (micro avg)  0.971
2022-09-13 17:26:41,877 BAD EPOCHS (no improvement): 4
2022-09-13 17:26:41,881 ----------------------------------------------------------------------------------------------------
2022-09-13 17:27:21,363 epoch 25 - iter 257/2578 - loss 0.21565157 - samples/sec: 26.05 - lr: 0.000002
2022-09-13 17:28:01,087 epoch 25 - iter 514/2578 - loss 0.21600274 - samples/sec: 25.89 - lr: 0.000002
2022-09-13 17:28:40,346 epoch 25 - iter 771/2578 - loss 0.21412486 - samples/sec: 26.19 - lr: 0.000002
2022-09-13 17:29:18,073 epoch 25 - iter 1028/2578 - loss 0.21288997 - samples/sec: 27.26 - lr: 0.000002
2022-09-13 17:29:59,094 epoch 25 - iter 1285/2578 - loss 0.21260331 - samples/sec: 25.07 - lr: 0.000002
2022-09-13 17:30:36,575 epoch 25 - iter 1542/2578 - loss 0.21328814 - samples/sec: 27.44 - lr: 0.000002
2022-09-13 17:31:12,354 epoch 25 - iter 1799/2578 - loss 0.21359937 - samples/sec: 28.74 - lr: 0.000002
2022-09-13 17:31:49,913 epoch 25 - iter 2056/2578 - loss 0.21383488 - samples/sec: 27.38 - lr: 0.000002
2022-09-13 17:32:26,288 epoch 25 - iter 2313/2578 - loss 0.21395691 - samples/sec: 28.27 - lr: 0.000002
2022-09-13 17:33:04,464 epoch 25 - iter 2570/2578 - loss 0.21397936 - samples/sec: 26.94 - lr: 0.000002
2022-09-13 17:33:05,864 ----------------------------------------------------------------------------------------------------
2022-09-13 17:33:05,865 EPOCH 25 done: loss 0.2140 - lr 0.000002
2022-09-13 17:33:56,676 Evaluating as a multi-label problem: False
2022-09-13 17:33:56,724 DEV : loss 0.0389336496591568 - f1-score (micro avg)  0.9714
2022-09-13 17:33:57,093 BAD EPOCHS (no improvement): 4
2022-09-13 17:33:57,097 ----------------------------------------------------------------------------------------------------
2022-09-13 17:34:35,189 epoch 26 - iter 257/2578 - loss 0.20876590 - samples/sec: 27.00 - lr: 0.000002
2022-09-13 17:35:14,512 epoch 26 - iter 514/2578 - loss 0.21485556 - samples/sec: 26.15 - lr: 0.000002
2022-09-13 17:35:54,076 epoch 26 - iter 771/2578 - loss 0.21285730 - samples/sec: 25.99 - lr: 0.000002
2022-09-13 17:36:33,498 epoch 26 - iter 1028/2578 - loss 0.21185653 - samples/sec: 26.09 - lr: 0.000002
2022-09-13 17:37:11,773 epoch 26 - iter 1285/2578 - loss 0.21234837 - samples/sec: 26.87 - lr: 0.000002
2022-09-13 17:37:48,553 epoch 26 - iter 1542/2578 - loss 0.21300605 - samples/sec: 27.96 - lr: 0.000002
2022-09-13 17:38:23,523 epoch 26 - iter 1799/2578 - loss 0.21340625 - samples/sec: 29.41 - lr: 0.000002
2022-09-13 17:39:02,758 epoch 26 - iter 2056/2578 - loss 0.21259999 - samples/sec: 26.21 - lr: 0.000002
2022-09-13 17:39:39,374 epoch 26 - iter 2313/2578 - loss 0.21154297 - samples/sec: 28.09 - lr: 0.000002
2022-09-13 17:40:19,045 epoch 26 - iter 2570/2578 - loss 0.21208402 - samples/sec: 25.92 - lr: 0.000002
2022-09-13 17:40:20,320 ----------------------------------------------------------------------------------------------------
2022-09-13 17:40:20,321 EPOCH 26 done: loss 0.2122 - lr 0.000002
2022-09-13 17:41:11,127 Evaluating as a multi-label problem: False
2022-09-13 17:41:11,174 DEV : loss 0.03722994402050972 - f1-score (micro avg)  0.9708
2022-09-13 17:41:11,545 BAD EPOCHS (no improvement): 4
2022-09-13 17:41:11,549 ----------------------------------------------------------------------------------------------------
2022-09-13 17:41:49,683 epoch 27 - iter 257/2578 - loss 0.22088669 - samples/sec: 26.97 - lr: 0.000002
2022-09-13 17:42:27,519 epoch 27 - iter 514/2578 - loss 0.21758455 - samples/sec: 27.18 - lr: 0.000002
2022-09-13 17:43:06,504 epoch 27 - iter 771/2578 - loss 0.21992288 - samples/sec: 26.38 - lr: 0.000002
2022-09-13 17:43:43,550 epoch 27 - iter 1028/2578 - loss 0.21708269 - samples/sec: 27.76 - lr: 0.000002
2022-09-13 17:44:21,571 epoch 27 - iter 1285/2578 - loss 0.21698940 - samples/sec: 27.05 - lr: 0.000002
2022-09-13 17:44:59,740 epoch 27 - iter 1542/2578 - loss 0.21622629 - samples/sec: 26.94 - lr: 0.000002
2022-09-13 17:45:39,055 epoch 27 - iter 1799/2578 - loss 0.21460851 - samples/sec: 26.16 - lr: 0.000002
2022-09-13 17:46:17,543 epoch 27 - iter 2056/2578 - loss 0.21384608 - samples/sec: 26.72 - lr: 0.000002
2022-09-13 17:46:54,577 epoch 27 - iter 2313/2578 - loss 0.21378339 - samples/sec: 27.77 - lr: 0.000002
2022-09-13 17:47:33,080 epoch 27 - iter 2570/2578 - loss 0.21319116 - samples/sec: 26.71 - lr: 0.000002
2022-09-13 17:47:34,300 ----------------------------------------------------------------------------------------------------
2022-09-13 17:47:34,300 EPOCH 27 done: loss 0.2131 - lr 0.000002
2022-09-13 17:48:25,223 Evaluating as a multi-label problem: False
2022-09-13 17:48:25,271 DEV : loss 0.03703794628381729 - f1-score (micro avg)  0.971
2022-09-13 17:48:25,641 BAD EPOCHS (no improvement): 4
2022-09-13 17:48:25,645 ----------------------------------------------------------------------------------------------------
2022-09-13 17:49:03,737 epoch 28 - iter 257/2578 - loss 0.21611604 - samples/sec: 27.00 - lr: 0.000002
2022-09-13 17:49:40,845 epoch 28 - iter 514/2578 - loss 0.21376397 - samples/sec: 27.71 - lr: 0.000002
2022-09-13 17:50:20,372 epoch 28 - iter 771/2578 - loss 0.21501142 - samples/sec: 26.02 - lr: 0.000002
2022-09-13 17:50:58,037 epoch 28 - iter 1028/2578 - loss 0.21610178 - samples/sec: 27.30 - lr: 0.000002
2022-09-13 17:51:35,543 epoch 28 - iter 1285/2578 - loss 0.21306132 - samples/sec: 27.42 - lr: 0.000002
2022-09-13 17:52:12,866 epoch 28 - iter 1542/2578 - loss 0.21298628 - samples/sec: 27.55 - lr: 0.000002
2022-09-13 17:52:52,073 epoch 28 - iter 1799/2578 - loss 0.21309734 - samples/sec: 26.23 - lr: 0.000002
2022-09-13 17:53:30,585 epoch 28 - iter 2056/2578 - loss 0.21308282 - samples/sec: 26.70 - lr: 0.000002
2022-09-13 17:54:09,352 epoch 28 - iter 2313/2578 - loss 0.21407386 - samples/sec: 26.53 - lr: 0.000002
2022-09-13 17:54:48,697 epoch 28 - iter 2570/2578 - loss 0.21502803 - samples/sec: 26.14 - lr: 0.000002
2022-09-13 17:54:50,134 ----------------------------------------------------------------------------------------------------
2022-09-13 17:54:50,134 EPOCH 28 done: loss 0.2150 - lr 0.000002
2022-09-13 17:55:41,248 Evaluating as a multi-label problem: False
2022-09-13 17:55:41,296 DEV : loss 0.037820592522621155 - f1-score (micro avg)  0.97
2022-09-13 17:55:41,664 BAD EPOCHS (no improvement): 4
2022-09-13 17:55:41,668 ----------------------------------------------------------------------------------------------------
2022-09-13 17:56:17,851 epoch 29 - iter 257/2578 - loss 0.20875994 - samples/sec: 28.43 - lr: 0.000002
2022-09-13 17:56:56,316 epoch 29 - iter 514/2578 - loss 0.21034877 - samples/sec: 26.73 - lr: 0.000002
2022-09-13 17:57:34,755 epoch 29 - iter 771/2578 - loss 0.20929386 - samples/sec: 26.75 - lr: 0.000002
2022-09-13 17:58:12,155 epoch 29 - iter 1028/2578 - loss 0.20874324 - samples/sec: 27.50 - lr: 0.000002
2022-09-13 17:58:48,742 epoch 29 - iter 1285/2578 - loss 0.20830894 - samples/sec: 28.11 - lr: 0.000002
2022-09-13 17:59:28,657 epoch 29 - iter 1542/2578 - loss 0.20771461 - samples/sec: 25.76 - lr: 0.000002
2022-09-13 18:00:06,554 epoch 29 - iter 1799/2578 - loss 0.20988439 - samples/sec: 27.14 - lr: 0.000001
2022-09-13 18:00:44,989 epoch 29 - iter 2056/2578 - loss 0.21037398 - samples/sec: 26.76 - lr: 0.000001
2022-09-13 18:01:25,762 epoch 29 - iter 2313/2578 - loss 0.21016552 - samples/sec: 25.22 - lr: 0.000001
2022-09-13 18:02:03,438 epoch 29 - iter 2570/2578 - loss 0.20967827 - samples/sec: 27.30 - lr: 0.000001
2022-09-13 18:02:05,153 ----------------------------------------------------------------------------------------------------
2022-09-13 18:02:05,153 EPOCH 29 done: loss 0.2098 - lr 0.000001
2022-09-13 18:02:56,862 Evaluating as a multi-label problem: False
2022-09-13 18:02:56,910 DEV : loss 0.03824179247021675 - f1-score (micro avg)  0.9711
2022-09-13 18:02:57,276 BAD EPOCHS (no improvement): 4
2022-09-13 18:02:57,279 ----------------------------------------------------------------------------------------------------
2022-09-13 18:03:33,821 epoch 30 - iter 257/2578 - loss 0.21219038 - samples/sec: 28.15 - lr: 0.000001
2022-09-13 18:04:11,515 epoch 30 - iter 514/2578 - loss 0.21100103 - samples/sec: 27.28 - lr: 0.000001
2022-09-13 18:04:48,711 epoch 30 - iter 771/2578 - loss 0.20881594 - samples/sec: 27.65 - lr: 0.000001
2022-09-13 18:05:27,714 epoch 30 - iter 1028/2578 - loss 0.20899176 - samples/sec: 26.37 - lr: 0.000001
2022-09-13 18:06:04,681 epoch 30 - iter 1285/2578 - loss 0.20913491 - samples/sec: 27.82 - lr: 0.000001
2022-09-13 18:06:43,978 epoch 30 - iter 1542/2578 - loss 0.20806590 - samples/sec: 26.17 - lr: 0.000001
2022-09-13 18:07:22,423 epoch 30 - iter 1799/2578 - loss 0.20784874 - samples/sec: 26.75 - lr: 0.000001
2022-09-13 18:08:02,479 epoch 30 - iter 2056/2578 - loss 0.20700490 - samples/sec: 25.67 - lr: 0.000001
2022-09-13 18:08:38,986 epoch 30 - iter 2313/2578 - loss 0.20693983 - samples/sec: 28.17 - lr: 0.000001
2022-09-13 18:09:18,132 epoch 30 - iter 2570/2578 - loss 0.20759790 - samples/sec: 26.27 - lr: 0.000001
2022-09-13 18:09:19,186 ----------------------------------------------------------------------------------------------------
2022-09-13 18:09:19,186 EPOCH 30 done: loss 0.2075 - lr 0.000001
2022-09-13 18:10:09,939 Evaluating as a multi-label problem: False
2022-09-13 18:10:09,988 DEV : loss 0.038190729916095734 - f1-score (micro avg)  0.9708
2022-09-13 18:10:10,316 BAD EPOCHS (no improvement): 4
2022-09-13 18:10:10,363 ----------------------------------------------------------------------------------------------------
2022-09-13 18:10:48,688 epoch 31 - iter 257/2578 - loss 0.21254055 - samples/sec: 26.84 - lr: 0.000001
2022-09-13 18:11:29,893 epoch 31 - iter 514/2578 - loss 0.20943670 - samples/sec: 24.96 - lr: 0.000001
2022-09-13 18:12:08,540 epoch 31 - iter 771/2578 - loss 0.21119065 - samples/sec: 26.61 - lr: 0.000001
2022-09-13 18:12:45,864 epoch 31 - iter 1028/2578 - loss 0.20966998 - samples/sec: 27.55 - lr: 0.000001
2022-09-13 18:13:24,095 epoch 31 - iter 1285/2578 - loss 0.21077258 - samples/sec: 26.90 - lr: 0.000001
2022-09-13 18:14:00,263 epoch 31 - iter 1542/2578 - loss 0.21116066 - samples/sec: 28.43 - lr: 0.000001
2022-09-13 18:14:39,424 epoch 31 - iter 1799/2578 - loss 0.21094619 - samples/sec: 26.26 - lr: 0.000001
2022-09-13 18:15:17,432 epoch 31 - iter 2056/2578 - loss 0.21016416 - samples/sec: 27.06 - lr: 0.000001
2022-09-13 18:15:55,699 epoch 31 - iter 2313/2578 - loss 0.21083360 - samples/sec: 26.87 - lr: 0.000001
2022-09-13 18:16:31,711 epoch 31 - iter 2570/2578 - loss 0.21129880 - samples/sec: 28.56 - lr: 0.000001
2022-09-13 18:16:33,206 ----------------------------------------------------------------------------------------------------
2022-09-13 18:16:33,207 EPOCH 31 done: loss 0.2113 - lr 0.000001
2022-09-13 18:17:24,012 Evaluating as a multi-label problem: False
2022-09-13 18:17:24,059 DEV : loss 0.03855585306882858 - f1-score (micro avg)  0.9704
2022-09-13 18:17:24,428 BAD EPOCHS (no improvement): 4
2022-09-13 18:17:24,431 ----------------------------------------------------------------------------------------------------
2022-09-13 18:18:02,139 epoch 32 - iter 257/2578 - loss 0.21275656 - samples/sec: 27.28 - lr: 0.000001
2022-09-13 18:18:39,936 epoch 32 - iter 514/2578 - loss 0.20447908 - samples/sec: 27.21 - lr: 0.000001
2022-09-13 18:19:17,042 epoch 32 - iter 771/2578 - loss 0.20511345 - samples/sec: 27.71 - lr: 0.000001
2022-09-13 18:19:52,818 epoch 32 - iter 1028/2578 - loss 0.20690822 - samples/sec: 28.74 - lr: 0.000001
2022-09-13 18:20:32,110 epoch 32 - iter 1285/2578 - loss 0.20661777 - samples/sec: 26.17 - lr: 0.000001
2022-09-13 18:21:09,860 epoch 32 - iter 1542/2578 - loss 0.20761457 - samples/sec: 27.24 - lr: 0.000001
2022-09-13 18:21:47,885 epoch 32 - iter 1799/2578 - loss 0.20732416 - samples/sec: 27.04 - lr: 0.000001
2022-09-13 18:22:25,438 epoch 32 - iter 2056/2578 - loss 0.20635002 - samples/sec: 27.38 - lr: 0.000001
2022-09-13 18:23:04,685 epoch 32 - iter 2313/2578 - loss 0.20717398 - samples/sec: 26.20 - lr: 0.000001
2022-09-13 18:23:43,619 epoch 32 - iter 2570/2578 - loss 0.20779997 - samples/sec: 26.41 - lr: 0.000001
2022-09-13 18:23:44,739 ----------------------------------------------------------------------------------------------------
2022-09-13 18:23:44,739 EPOCH 32 done: loss 0.2077 - lr 0.000001
2022-09-13 18:24:35,536 Evaluating as a multi-label problem: False
2022-09-13 18:24:35,583 DEV : loss 0.03749196231365204 - f1-score (micro avg)  0.9698
2022-09-13 18:24:35,948 BAD EPOCHS (no improvement): 4
2022-09-13 18:24:35,952 ----------------------------------------------------------------------------------------------------
2022-09-13 18:25:13,762 epoch 33 - iter 257/2578 - loss 0.21336154 - samples/sec: 27.20 - lr: 0.000001
2022-09-13 18:25:53,018 epoch 33 - iter 514/2578 - loss 0.21415666 - samples/sec: 26.20 - lr: 0.000001
2022-09-13 18:26:32,402 epoch 33 - iter 771/2578 - loss 0.21366777 - samples/sec: 26.11 - lr: 0.000001
2022-09-13 18:27:10,003 epoch 33 - iter 1028/2578 - loss 0.21408928 - samples/sec: 27.35 - lr: 0.000001
2022-09-13 18:27:48,629 epoch 33 - iter 1285/2578 - loss 0.21390334 - samples/sec: 26.62 - lr: 0.000001
2022-09-13 18:28:25,359 epoch 33 - iter 1542/2578 - loss 0.21400011 - samples/sec: 28.00 - lr: 0.000001
2022-09-13 18:29:02,411 epoch 33 - iter 1799/2578 - loss 0.21367615 - samples/sec: 27.75 - lr: 0.000001
2022-09-13 18:29:42,296 epoch 33 - iter 2056/2578 - loss 0.21287540 - samples/sec: 25.78 - lr: 0.000001
2022-09-13 18:30:20,414 epoch 33 - iter 2313/2578 - loss 0.21282125 - samples/sec: 26.98 - lr: 0.000001
2022-09-13 18:30:54,651 epoch 33 - iter 2570/2578 - loss 0.21275903 - samples/sec: 30.04 - lr: 0.000001
2022-09-13 18:30:56,173 ----------------------------------------------------------------------------------------------------
2022-09-13 18:30:56,174 EPOCH 33 done: loss 0.2127 - lr 0.000001
2022-09-13 18:31:46,918 Evaluating as a multi-label problem: False
2022-09-13 18:31:46,965 DEV : loss 0.03925301507115364 - f1-score (micro avg)  0.9706
2022-09-13 18:31:47,333 BAD EPOCHS (no improvement): 4
2022-09-13 18:31:47,337 ----------------------------------------------------------------------------------------------------
2022-09-13 18:32:22,817 epoch 34 - iter 257/2578 - loss 0.21484611 - samples/sec: 28.99 - lr: 0.000001
2022-09-13 18:33:00,437 epoch 34 - iter 514/2578 - loss 0.20875893 - samples/sec: 27.34 - lr: 0.000001
2022-09-13 18:33:39,044 epoch 34 - iter 771/2578 - loss 0.21107856 - samples/sec: 26.64 - lr: 0.000001
2022-09-13 18:34:19,286 epoch 34 - iter 1028/2578 - loss 0.20694070 - samples/sec: 25.55 - lr: 0.000001
2022-09-13 18:34:58,791 epoch 34 - iter 1285/2578 - loss 0.20580662 - samples/sec: 26.03 - lr: 0.000001
2022-09-13 18:35:36,182 epoch 34 - iter 1542/2578 - loss 0.20510112 - samples/sec: 27.50 - lr: 0.000001
2022-09-13 18:36:11,530 epoch 34 - iter 1799/2578 - loss 0.20536478 - samples/sec: 29.09 - lr: 0.000001
2022-09-13 18:36:49,545 epoch 34 - iter 2056/2578 - loss 0.20759504 - samples/sec: 27.05 - lr: 0.000001
2022-09-13 18:37:26,512 epoch 34 - iter 2313/2578 - loss 0.20758337 - samples/sec: 27.82 - lr: 0.000001
2022-09-13 18:38:03,439 epoch 34 - iter 2570/2578 - loss 0.20770445 - samples/sec: 27.85 - lr: 0.000001
2022-09-13 18:38:05,273 ----------------------------------------------------------------------------------------------------
2022-09-13 18:38:05,274 EPOCH 34 done: loss 0.2076 - lr 0.000001
2022-09-13 18:38:56,828 Evaluating as a multi-label problem: False
2022-09-13 18:38:56,875 DEV : loss 0.039795421063899994 - f1-score (micro avg)  0.9713
2022-09-13 18:38:57,246 BAD EPOCHS (no improvement): 4
2022-09-13 18:38:57,250 ----------------------------------------------------------------------------------------------------
2022-09-13 18:39:33,839 epoch 35 - iter 257/2578 - loss 0.20040650 - samples/sec: 28.11 - lr: 0.000001
2022-09-13 18:40:12,477 epoch 35 - iter 514/2578 - loss 0.20345128 - samples/sec: 26.61 - lr: 0.000001
2022-09-13 18:40:48,585 epoch 35 - iter 771/2578 - loss 0.20717220 - samples/sec: 28.48 - lr: 0.000001
2022-09-13 18:41:24,817 epoch 35 - iter 1028/2578 - loss 0.20803040 - samples/sec: 28.38 - lr: 0.000001
2022-09-13 18:42:03,992 epoch 35 - iter 1285/2578 - loss 0.21008198 - samples/sec: 26.25 - lr: 0.000001
2022-09-13 18:42:43,695 epoch 35 - iter 1542/2578 - loss 0.20988370 - samples/sec: 25.90 - lr: 0.000001
2022-09-13 18:43:20,507 epoch 35 - iter 1799/2578 - loss 0.20945552 - samples/sec: 27.94 - lr: 0.000001
2022-09-13 18:44:01,293 epoch 35 - iter 2056/2578 - loss 0.21020908 - samples/sec: 25.21 - lr: 0.000001
2022-09-13 18:44:39,319 epoch 35 - iter 2313/2578 - loss 0.20895439 - samples/sec: 27.04 - lr: 0.000001
2022-09-13 18:45:16,777 epoch 35 - iter 2570/2578 - loss 0.20990498 - samples/sec: 27.45 - lr: 0.000001
2022-09-13 18:45:17,953 ----------------------------------------------------------------------------------------------------
2022-09-13 18:45:17,953 EPOCH 35 done: loss 0.2100 - lr 0.000001
2022-09-13 18:46:08,663 Evaluating as a multi-label problem: False
2022-09-13 18:46:08,711 DEV : loss 0.04001166298985481 - f1-score (micro avg)  0.9709
2022-09-13 18:46:09,080 BAD EPOCHS (no improvement): 4
2022-09-13 18:46:09,084 ----------------------------------------------------------------------------------------------------
2022-09-13 18:46:45,281 epoch 36 - iter 257/2578 - loss 0.22010810 - samples/sec: 28.42 - lr: 0.000001
2022-09-13 18:47:24,094 epoch 36 - iter 514/2578 - loss 0.21546457 - samples/sec: 26.49 - lr: 0.000001
2022-09-13 18:48:04,004 epoch 36 - iter 771/2578 - loss 0.21588684 - samples/sec: 25.77 - lr: 0.000001
2022-09-13 18:48:46,343 epoch 36 - iter 1028/2578 - loss 0.21448484 - samples/sec: 24.29 - lr: 0.000001
2022-09-13 18:49:22,382 epoch 36 - iter 1285/2578 - loss 0.21326380 - samples/sec: 28.54 - lr: 0.000001
2022-09-13 18:49:58,260 epoch 36 - iter 1542/2578 - loss 0.21266208 - samples/sec: 28.66 - lr: 0.000001
2022-09-13 18:50:37,123 epoch 36 - iter 1799/2578 - loss 0.21331254 - samples/sec: 26.46 - lr: 0.000001
2022-09-13 18:51:14,725 epoch 36 - iter 2056/2578 - loss 0.21319347 - samples/sec: 27.35 - lr: 0.000001
2022-09-13 18:51:51,762 epoch 36 - iter 2313/2578 - loss 0.21272310 - samples/sec: 27.77 - lr: 0.000001
2022-09-13 18:52:28,798 epoch 36 - iter 2570/2578 - loss 0.21218077 - samples/sec: 27.77 - lr: 0.000001
2022-09-13 18:52:29,783 ----------------------------------------------------------------------------------------------------
2022-09-13 18:52:29,783 EPOCH 36 done: loss 0.2122 - lr 0.000001
2022-09-13 18:53:20,631 Evaluating as a multi-label problem: False
2022-09-13 18:53:20,679 DEV : loss 0.039514701813459396 - f1-score (micro avg)  0.9705
2022-09-13 18:53:21,046 BAD EPOCHS (no improvement): 4
2022-09-13 18:53:21,050 ----------------------------------------------------------------------------------------------------
2022-09-13 18:54:00,299 epoch 37 - iter 257/2578 - loss 0.20342671 - samples/sec: 26.21 - lr: 0.000001
2022-09-13 18:54:37,667 epoch 37 - iter 514/2578 - loss 0.20401937 - samples/sec: 27.52 - lr: 0.000001
2022-09-13 18:55:16,253 epoch 37 - iter 771/2578 - loss 0.21029387 - samples/sec: 26.65 - lr: 0.000000
2022-09-13 18:55:55,082 epoch 37 - iter 1028/2578 - loss 0.21017464 - samples/sec: 26.48 - lr: 0.000000
2022-09-13 18:56:31,429 epoch 37 - iter 1285/2578 - loss 0.20865097 - samples/sec: 28.29 - lr: 0.000000
2022-09-13 18:57:08,788 epoch 37 - iter 1542/2578 - loss 0.20885419 - samples/sec: 27.53 - lr: 0.000000
2022-09-13 18:57:48,307 epoch 37 - iter 1799/2578 - loss 0.20888660 - samples/sec: 26.02 - lr: 0.000000
2022-09-13 18:58:24,777 epoch 37 - iter 2056/2578 - loss 0.21016126 - samples/sec: 28.20 - lr: 0.000000
2022-09-13 18:59:02,682 epoch 37 - iter 2313/2578 - loss 0.20997734 - samples/sec: 27.13 - lr: 0.000000
2022-09-13 18:59:40,501 epoch 37 - iter 2570/2578 - loss 0.20927118 - samples/sec: 27.19 - lr: 0.000000
2022-09-13 18:59:41,811 ----------------------------------------------------------------------------------------------------
2022-09-13 18:59:41,811 EPOCH 37 done: loss 0.2093 - lr 0.000000
2022-09-13 19:00:32,601 Evaluating as a multi-label problem: False
2022-09-13 19:00:32,649 DEV : loss 0.040031518787145615 - f1-score (micro avg)  0.9708
2022-09-13 19:00:32,972 BAD EPOCHS (no improvement): 4
2022-09-13 19:00:33,018 ----------------------------------------------------------------------------------------------------
2022-09-13 19:01:10,923 epoch 38 - iter 257/2578 - loss 0.21448932 - samples/sec: 27.14 - lr: 0.000000
2022-09-13 19:01:48,511 epoch 38 - iter 514/2578 - loss 0.20824599 - samples/sec: 27.36 - lr: 0.000000
2022-09-13 19:02:26,611 epoch 38 - iter 771/2578 - loss 0.20678244 - samples/sec: 26.99 - lr: 0.000000
2022-09-13 19:03:05,771 epoch 38 - iter 1028/2578 - loss 0.20886513 - samples/sec: 26.26 - lr: 0.000000
2022-09-13 19:03:44,825 epoch 38 - iter 1285/2578 - loss 0.20931235 - samples/sec: 26.33 - lr: 0.000000
2022-09-13 19:04:23,076 epoch 38 - iter 1542/2578 - loss 0.21017312 - samples/sec: 26.88 - lr: 0.000000
2022-09-13 19:05:01,694 epoch 38 - iter 1799/2578 - loss 0.20907056 - samples/sec: 26.63 - lr: 0.000000
2022-09-13 19:05:40,798 epoch 38 - iter 2056/2578 - loss 0.21058246 - samples/sec: 26.30 - lr: 0.000000
2022-09-13 19:06:17,704 epoch 38 - iter 2313/2578 - loss 0.21199707 - samples/sec: 27.86 - lr: 0.000000
2022-09-13 19:06:52,872 epoch 38 - iter 2570/2578 - loss 0.21147174 - samples/sec: 29.24 - lr: 0.000000
2022-09-13 19:06:53,814 ----------------------------------------------------------------------------------------------------
2022-09-13 19:06:53,815 EPOCH 38 done: loss 0.2115 - lr 0.000000
2022-09-13 19:07:44,603 Evaluating as a multi-label problem: False
2022-09-13 19:07:44,651 DEV : loss 0.04044714197516441 - f1-score (micro avg)  0.972
2022-09-13 19:07:45,017 BAD EPOCHS (no improvement): 4
2022-09-13 19:07:45,021 ----------------------------------------------------------------------------------------------------
2022-09-13 19:08:24,678 epoch 39 - iter 257/2578 - loss 0.20176943 - samples/sec: 25.94 - lr: 0.000000
2022-09-13 19:09:03,294 epoch 39 - iter 514/2578 - loss 0.20642761 - samples/sec: 26.63 - lr: 0.000000
2022-09-13 19:09:38,945 epoch 39 - iter 771/2578 - loss 0.20862683 - samples/sec: 28.85 - lr: 0.000000
2022-09-13 19:10:17,447 epoch 39 - iter 1028/2578 - loss 0.21002477 - samples/sec: 26.71 - lr: 0.000000
2022-09-13 19:10:55,407 epoch 39 - iter 1285/2578 - loss 0.20976806 - samples/sec: 27.09 - lr: 0.000000
2022-09-13 19:11:33,458 epoch 39 - iter 1542/2578 - loss 0.21008265 - samples/sec: 27.03 - lr: 0.000000
2022-09-13 19:12:10,048 epoch 39 - iter 1799/2578 - loss 0.20895888 - samples/sec: 28.11 - lr: 0.000000
2022-09-13 19:12:47,170 epoch 39 - iter 2056/2578 - loss 0.20907419 - samples/sec: 27.70 - lr: 0.000000
2022-09-13 19:13:23,882 epoch 39 - iter 2313/2578 - loss 0.20897784 - samples/sec: 28.01 - lr: 0.000000
2022-09-13 19:14:03,512 epoch 39 - iter 2570/2578 - loss 0.20940389 - samples/sec: 25.95 - lr: 0.000000
2022-09-13 19:14:04,530 ----------------------------------------------------------------------------------------------------
2022-09-13 19:14:04,530 EPOCH 39 done: loss 0.2094 - lr 0.000000
2022-09-13 19:14:56,278 Evaluating as a multi-label problem: False
2022-09-13 19:14:56,326 DEV : loss 0.04022205248475075 - f1-score (micro avg)  0.9718
2022-09-13 19:14:56,695 BAD EPOCHS (no improvement): 4
2022-09-13 19:14:56,698 ----------------------------------------------------------------------------------------------------
2022-09-13 19:15:34,228 epoch 40 - iter 257/2578 - loss 0.21043086 - samples/sec: 27.41 - lr: 0.000000
2022-09-13 19:16:12,805 epoch 40 - iter 514/2578 - loss 0.20777773 - samples/sec: 26.66 - lr: 0.000000
2022-09-13 19:16:48,124 epoch 40 - iter 771/2578 - loss 0.21028824 - samples/sec: 29.12 - lr: 0.000000
2022-09-13 19:17:27,710 epoch 40 - iter 1028/2578 - loss 0.20958100 - samples/sec: 25.98 - lr: 0.000000
2022-09-13 19:18:05,594 epoch 40 - iter 1285/2578 - loss 0.21031704 - samples/sec: 27.15 - lr: 0.000000
2022-09-13 19:18:43,508 epoch 40 - iter 1542/2578 - loss 0.20929234 - samples/sec: 27.12 - lr: 0.000000
2022-09-13 19:19:20,972 epoch 40 - iter 1799/2578 - loss 0.21017811 - samples/sec: 27.45 - lr: 0.000000
2022-09-13 19:19:57,975 epoch 40 - iter 2056/2578 - loss 0.21044785 - samples/sec: 27.79 - lr: 0.000000
2022-09-13 19:20:36,632 epoch 40 - iter 2313/2578 - loss 0.21026453 - samples/sec: 26.60 - lr: 0.000000
2022-09-13 19:21:15,152 epoch 40 - iter 2570/2578 - loss 0.21075932 - samples/sec: 26.70 - lr: 0.000000
2022-09-13 19:21:16,111 ----------------------------------------------------------------------------------------------------
2022-09-13 19:21:16,111 EPOCH 40 done: loss 0.2107 - lr 0.000000
2022-09-13 19:22:06,868 Evaluating as a multi-label problem: False
2022-09-13 19:22:06,915 DEV : loss 0.040449559688568115 - f1-score (micro avg)  0.9717
2022-09-13 19:22:07,279 BAD EPOCHS (no improvement): 4
2022-09-13 19:22:10,503 ----------------------------------------------------------------------------------------------------
2022-09-13 19:22:10,504 loading file experiments/corpus_sentence_bert_we_finetune/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto-cased_FT_True_Ly_-1_seed_12)_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/best-model.pt
2022-09-13 19:22:14,200 SequenceTagger predicts: Dictionary with 89 tags: O, S-TERRITORIO, B-TERRITORIO, E-TERRITORIO, I-TERRITORIO, S-FECHAS, B-FECHAS, E-FECHAS, I-FECHAS, S-EDAD_SUJETO_ASISTENCIA, B-EDAD_SUJETO_ASISTENCIA, E-EDAD_SUJETO_ASISTENCIA, I-EDAD_SUJETO_ASISTENCIA, S-NOMBRE_SUJETO_ASISTENCIA, B-NOMBRE_SUJETO_ASISTENCIA, E-NOMBRE_SUJETO_ASISTENCIA, I-NOMBRE_SUJETO_ASISTENCIA, S-NOMBRE_PERSONAL_SANITARIO, B-NOMBRE_PERSONAL_SANITARIO, E-NOMBRE_PERSONAL_SANITARIO, I-NOMBRE_PERSONAL_SANITARIO, S-SEXO_SUJETO_ASISTENCIA, B-SEXO_SUJETO_ASISTENCIA, E-SEXO_SUJETO_ASISTENCIA, I-SEXO_SUJETO_ASISTENCIA, S-CALLE, B-CALLE, E-CALLE, I-CALLE, S-PAIS, B-PAIS, E-PAIS, I-PAIS, S-ID_SUJETO_ASISTENCIA, B-ID_SUJETO_ASISTENCIA, E-ID_SUJETO_ASISTENCIA, I-ID_SUJETO_ASISTENCIA, S-ID_TITULACION_PERSONAL_SANITARIO, B-ID_TITULACION_PERSONAL_SANITARIO, E-ID_TITULACION_PERSONAL_SANITARIO, I-ID_TITULACION_PERSONAL_SANITARIO, S-CORREO_ELECTRONICO, B-CORREO_ELECTRONICO, E-CORREO_ELECTRONICO, I-CORREO_ELECTRONICO, S-ID_ASEGURAMIENTO, B-ID_ASEGURAMIENTO, E-ID_ASEGURAMIENTO, I-ID_ASEGURAMIENTO, S-HOSPITAL
2022-09-13 19:23:04,557 Evaluating as a multi-label problem: False
2022-09-13 19:23:04,604 0.9653	0.9769	0.971	0.9484
2022-09-13 19:23:04,604 
Results:
- F-score (micro) 0.971
- F-score (macro) 0.8645
- Accuracy 0.9484

By class:
                                  precision    recall  f1-score   support

                      TERRITORIO     0.9688    0.9749    0.9718       956
                          FECHAS     0.9759    0.9935    0.9846       611
          EDAD_SUJETO_ASISTENCIA     0.9810    0.9942    0.9875       518
       NOMBRE_PERSONAL_SANITARIO     0.9881    0.9960    0.9920       501
        NOMBRE_SUJETO_ASISTENCIA     1.0000    0.9980    0.9990       502
          SEXO_SUJETO_ASISTENCIA     0.9913    0.9892    0.9902       461
                           CALLE     0.9522    0.9637    0.9579       413
                            PAIS     0.9784    0.9972    0.9877       363
            ID_SUJETO_ASISTENCIA     0.9690    0.9929    0.9808       283
              CORREO_ELECTRONICO     0.9841    0.9920    0.9880       249
ID_TITULACION_PERSONAL_SANITARIO     0.9873    1.0000    0.9936       234
                ID_ASEGURAMIENTO     0.9949    0.9949    0.9949       198
                        HOSPITAL     0.8968    0.8692    0.8828       130
    FAMILIARES_SUJETO_ASISTENCIA     0.7253    0.8148    0.7674        81
                     INSTITUCION     0.5325    0.6119    0.5694        67
         ID_CONTACTO_ASISTENCIAL     0.9744    0.9744    0.9744        39
                 NUMERO_TELEFONO     0.9630    1.0000    0.9811        26
                       PROFESION     0.3684    0.7778    0.5000         9
                      NUMERO_FAX     1.0000    0.8571    0.9231         7
                    CENTRO_SALUD     0.8000    0.6667    0.7273         6
         OTROS_SUJETO_ASISTENCIA     0.0000    0.0000    0.0000         7

                       micro avg     0.9653    0.9769    0.9710      5661
                       macro avg     0.8586    0.8790    0.8645      5661
                    weighted avg     0.9662    0.9769    0.9713      5661

2022-09-13 19:23:04,604 ----------------------------------------------------------------------------------------------------
