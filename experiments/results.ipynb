{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The evaluation of automatic predictions had two different scenarios or sub-tracks:\n",
    "\n",
    "1.  **NER offset and entity type classification**: the first sub-track was focused\n",
    "on the identification and classification of sensitive information (e.g., patient\n",
    "names, telephones, addresses, etc.).  \n",
    "\n",
    "2.  **Sensitive span detection**: the second sub-track was focused on the detection\n",
    "of sensitive text more specific to the practical scenario necessary for the\n",
    "release of de-identified clinical documents, where the objective is to identify\n",
    "and to mask confidential data, regardless of the real type of entity or the\n",
    "correct identification of PHI type.\n",
    "\n",
    "We evaluate our models using the various evaluation scripts and report averaged F1-Score over treee runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create some code to automatically extract the evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable, DefaultDict, List, NamedTuple\n",
    "\n",
    "\n",
    "class SubtrackScores(NamedTuple):\n",
    "    precision: float\n",
    "    recall: float\n",
    "\n",
    "def _get_scores(folder_path: Path, filename: str, precision_line: int, recall_line: int) -> SubtrackScores:\n",
    "    fpth = Path(folder_path / filename)\n",
    "    if not fpth.exists():\n",
    "        raise FileNotFoundError(f\"{fpth} not found!\")\n",
    "\n",
    "    lines = fpth.read_text().split(\"\\n\")\n",
    "\n",
    "    precision = float(lines[precision_line].split(\"=\")[-1])\n",
    "    recall = float(lines[recall_line].split(\"=\")[-1])\n",
    "\n",
    "    return SubtrackScores(precision, recall)\n",
    "\n",
    "def get_subtrack1_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"ner\", -3, -2)\n",
    "\n",
    "def get_subtrack2_strict_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -6, -5)\n",
    "\n",
    "def get_subtrack2_merged_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -3, -2)\n",
    "\n",
    "def get_scores_as_df(seeds: List[int], get_folder: Callable[[int], Path]) -> pd.DataFrame:\n",
    "    subtracks_scores: DefaultDict[List, float] = defaultdict(list)\n",
    "\n",
    "    for seed in seeds:\n",
    "        fpth = get_folder(seed)\n",
    "\n",
    "        p, r = get_subtrack1_scores(fpth)\n",
    "        subtracks_scores[\"1_p\"].append(p)\n",
    "        subtracks_scores[\"1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_strict_scores(fpth)\n",
    "        subtracks_scores[\"2_1_p\"].append(p)\n",
    "        subtracks_scores[\"2_1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_merged_scores(fpth)\n",
    "        subtracks_scores[\"2_2_p\"].append(p)\n",
    "        subtracks_scores[\"2_2_r\"].append(r)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(subtracks_scores)\n",
    "    for col in [\"1\", \"2_1\", \"2_2\"]:\n",
    "        df[f\"{col}_f1\"] = 2*df[f\"{col}_p\"]*df[f\"{col}_r\"] / (df[f\"{col}_p\"] + df[f\"{col}_r\"])\n",
    "\n",
    "    # Reorder columns\n",
    "    new_columns = [\"1_p\", \"1_r\", \"1_f1\", \"2_1_p\", \"2_1_r\", \"2_1_f1\", \"2_2_p\", \"2_2_r\", \"2_2_f1\"]\n",
    "    df = df[new_columns]\n",
    "\n",
    "    # Prepare multi index names\n",
    "    multi_index = pd.MultiIndex.from_product(\n",
    "        [\n",
    "            [\"Subtrack 1\", \"Subtrack 2 [Strict]\", \"Subtrack 2 [Merged]\"],\n",
    "            [\"precision\", \"recall\", \"f1\"]\n",
    "        ],\n",
    "        names=[\"Track\", \"Scores\"]\n",
    "    )\n",
    "    # Give multi index to df\n",
    "    return pd.DataFrame(df.to_numpy().T, index=multi_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the root folder where all the results and the trained models are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(\"/home/wave/Project/MedDocAn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the evaluation for each model in a ``pandas.DataFrame``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.968385</td>\n",
       "      <td>0.001274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.973075</td>\n",
       "      <td>0.001142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.984384</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.968385  0.001274\n",
       "Subtrack 2 [Strict] f1      0.973075  0.001142\n",
       "Subtrack 2 [Merged] f1      0.984384  0.000787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 10, 25, 33, 42]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_flair_we_lstm_crf/results_seed_{seed}/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_FLAIR_WE = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_FLAIR_WE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.968768</td>\n",
       "      <td>0.001296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.976428</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.983721</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.968768  0.001296\n",
       "Subtrack 2 [Strict] f1      0.976428  0.001584\n",
       "Subtrack 2 [Merged] f1      0.983721  0.001211"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_flair_lstm_crf/an_wh_rs_True_dpt_0.08716810045694838_emb_seed_{seed}_Stack(0_lm-es-forward.pt, 1_lm-es-backward.pt)_hdn_sz_256_lr_0.1_it_150_bs_4_opti_SGD_pjct_emb_True_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_FLAIR = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.973673</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.979660</td>\n",
       "      <td>0.001506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.985812</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.973673  0.001587\n",
       "Subtrack 2 [Strict] f1      0.979660  0.001506\n",
       "Subtrack 2 [Merged] f1      0.985812  0.000989"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_finetune/an_wh_rs_False_dpt_0_emb_beto-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_150_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "FINE_TUNE_BETO_CONTEXT = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "FINE_TUNE_BETO_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.972018</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.977234</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.984776</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.972018  0.001341\n",
       "Subtrack 2 [Strict] f1      0.977234  0.001437\n",
       "Subtrack 2 [Merged] f1      0.984776  0.000964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_finetune/an_wh_rs_False_dpt_0_emb_beto-cased_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "FINE_TUNE_BETO = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "FINE_TUNE_BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.972018</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.977234</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.984776</td>\n",
       "      <td>0.000964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.972018  0.001341\n",
       "Subtrack 2 [Strict] f1      0.977234  0.001437\n",
       "Subtrack 2 [Merged] f1      0.984776  0.000964"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_finetune/an_wh_rs_False_dpt_0_emb_beto-cased_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.05/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "FINE_TUNE_BETO = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "FINE_TUNE_BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.971994</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.978217</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.985028</td>\n",
       "      <td>0.000503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.971994  0.000463\n",
       "Subtrack 2 [Strict] f1      0.978217  0.000734\n",
       "Subtrack 2 [Merged] f1      0.985028  0.000503"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_lstm_crf/an_wh_rs_False_dpt_0_emb_beto_Ly_all_mean_seed_{seed}_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_BETO = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_BETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.973711</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.979351</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.986297</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.973711  0.000714\n",
       "Subtrack 2 [Strict] f1      0.979351  0.000444\n",
       "Subtrack 2 [Merged] f1      0.986297  0.000630"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_we_lstm_crf/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto_Ly_all_mean_seed_{seed})_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_BETO_WE = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_BETO_WE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.974963</td>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.980899</td>\n",
       "      <td>0.000815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.986733</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.974963  0.000642\n",
       "Subtrack 2 [Strict] f1      0.980899  0.000815\n",
       "Subtrack 2 [Merged] f1      0.986733  0.000919"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_we_lstm_crf/an_wh_rs_False_dpt_0_emb_Stack(0_es-wiki-fasttext-300d-1M, 1_1-beto_Ly_all_mean_context_seed_{seed})_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_BETO_WE_CONTEXT = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_BETO_WE_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.970914</td>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.977782</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.984388</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.970914  0.000867\n",
       "Subtrack 2 [Strict] f1      0.977782  0.000641\n",
       "Subtrack 2 [Merged] f1      0.984388  0.001002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_bert_context_lstm_crf/an_wh_rs_False_dpt_0_emb_beto_Ly_all_mean_context_seed_{seed}_hdn_sz_256_lr_0.1_it_500_bs_4_opti_SGD_pjct_emb_False_rnn_ly_2_sdl_AnnealOnPlateau_use_crf_True_use_rnn_True/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "LSTM_CRF_BETO_CONTEXT = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "LSTM_CRF_BETO_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.974911</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.974911  0.000691\n",
       "Subtrack 2 [Strict] f1      0.980135  0.000723\n",
       "Subtrack 2 [Merged] f1      0.986529  0.000465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [1, 12, 33]\n",
    "get_folders = lambda seed: base_folder / f\"experiments/corpus_sentence_grid_search_flert_xlm-roberta_docstart/an_wh_rs_False_dpt_0_emb_xlm-roberta-large-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/test\"\n",
    "df = get_scores_as_df(seeds, get_folders)\n",
    "FINE_TUNE_XLMR_LARGE_CONTEXT = df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]\n",
    "FINE_TUNE_XLMR_LARGE_CONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the evaluation for all the models in a ``pandas.DataFrame``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"FINETUNE + XLMR LARGE + CONTEXT\": FINE_TUNE_XLMR_LARGE_CONTEXT,\n",
    "    \"FINETUNE + BETO + CONTEXT\": FINE_TUNE_BETO_CONTEXT,\n",
    "    \"FINETUNE + BETO\": FINE_TUNE_BETO,\n",
    "    # \"FINETUNE + BETO + WE\": TODO,\n",
    "    # \"FINETUNE + BETO + WE + CONTEXT\": TODO,\n",
    "    \"LSTM CRF + BETO + CONTEXT\": LSTM_CRF_BETO_CONTEXT,\n",
    "    \"LSTM CRF + BETO\": LSTM_CRF_BETO,\n",
    "    \"LSTM CRF + BETO + WE + CONTEXT\": LSTM_CRF_BETO_WE_CONTEXT,\n",
    "    \"LSTM CRF + BETO + WE\": LSTM_CRF_BETO_WE,\n",
    "    \"LSTM CRF + FLAIR + WE\": LSTM_CRF_FLAIR_WE,\n",
    "    \"LSTM CRF + FLAIR\": LSTM_CRF_FLAIR,\n",
    "\n",
    "}\n",
    "result_metrics = pd.concat(data.values(), axis=1, keys=data.keys(), names=[\"Model\", \"computation\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76803 .index_name {\n",
       "  font-style: italic;\n",
       "  color: darkgrey;\n",
       "  font-weight: normal;\n",
       "}\n",
       "#T_76803 th.col_heading {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_76803 th.col_heading.level0 {\n",
       "  font-size: 1.5em;\n",
       "}\n",
       "#T_76803 td {\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_76803_row0_col0 {\n",
       "  background-color: #023a5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row0_col1 {\n",
       "  background-color: #045382;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row0_col2 {\n",
       "  background-color: #034a74;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row1_col0, #T_76803_row6_col1 {\n",
       "  background-color: #0567a1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row1_col1 {\n",
       "  background-color: #046096;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row1_col2 {\n",
       "  background-color: #1b7eb7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row2_col0 {\n",
       "  background-color: #5a9ec9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row2_col1 {\n",
       "  background-color: #63a2cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row2_col2 {\n",
       "  background-color: #afc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row3_col0 {\n",
       "  background-color: #a2bcda;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row3_col1 {\n",
       "  background-color: #4295c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row3_col2, #T_76803_row7_col2 {\n",
       "  background-color: #d7d6e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row4_col0 {\n",
       "  background-color: #5c9fc9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row4_col1 {\n",
       "  background-color: #2987bc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row4_col2 {\n",
       "  background-color: #8eb3d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row5_col0, #T_76803_row5_col1, #T_76803_row5_col2 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row6_col0 {\n",
       "  background-color: #05659f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row6_col2 {\n",
       "  background-color: #045e93;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_76803_row7_col0, #T_76803_row7_col1, #T_76803_row8_col2 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row8_col0 {\n",
       "  background-color: #f7f0f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_76803_row8_col1 {\n",
       "  background-color: #91b5d6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76803\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Track</th>\n",
       "      <th id=\"T_76803_level0_col0\" class=\"col_heading level0 col0\" >Subtrack 1</th>\n",
       "      <th id=\"T_76803_level0_col1\" class=\"col_heading level0 col1\" >Subtrack 2 [Strict]</th>\n",
       "      <th id=\"T_76803_level0_col2\" class=\"col_heading level0 col2\" >Subtrack 2 [Merged]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row0\" class=\"row_heading level0 row0\" >FINETUNE + XLMR LARGE + CONTEXT</th>\n",
       "      <td id=\"T_76803_row0_col0\" class=\"data row0 col0\" >97.49</td>\n",
       "      <td id=\"T_76803_row0_col1\" class=\"data row0 col1\" >98.01</td>\n",
       "      <td id=\"T_76803_row0_col2\" class=\"data row0 col2\" >98.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row1\" class=\"row_heading level0 row1\" >FINETUNE + BETO + CONTEXT</th>\n",
       "      <td id=\"T_76803_row1_col0\" class=\"data row1 col0\" >97.37</td>\n",
       "      <td id=\"T_76803_row1_col1\" class=\"data row1 col1\" >97.97</td>\n",
       "      <td id=\"T_76803_row1_col2\" class=\"data row1 col2\" >98.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row2\" class=\"row_heading level0 row2\" >FINETUNE + BETO</th>\n",
       "      <td id=\"T_76803_row2_col0\" class=\"data row2 col0\" >97.20</td>\n",
       "      <td id=\"T_76803_row2_col1\" class=\"data row2 col1\" >97.72</td>\n",
       "      <td id=\"T_76803_row2_col2\" class=\"data row2 col2\" >98.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row3\" class=\"row_heading level0 row3\" >LSTM CRF + BETO + CONTEXT</th>\n",
       "      <td id=\"T_76803_row3_col0\" class=\"data row3 col0\" >97.09</td>\n",
       "      <td id=\"T_76803_row3_col1\" class=\"data row3 col1\" >97.78</td>\n",
       "      <td id=\"T_76803_row3_col2\" class=\"data row3 col2\" >98.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row4\" class=\"row_heading level0 row4\" >LSTM CRF + BETO</th>\n",
       "      <td id=\"T_76803_row4_col0\" class=\"data row4 col0\" >97.20</td>\n",
       "      <td id=\"T_76803_row4_col1\" class=\"data row4 col1\" >97.82</td>\n",
       "      <td id=\"T_76803_row4_col2\" class=\"data row4 col2\" >98.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row5\" class=\"row_heading level0 row5\" >LSTM CRF + BETO + WE + CONTEXT</th>\n",
       "      <td id=\"T_76803_row5_col0\" class=\"data row5 col0\" >97.50</td>\n",
       "      <td id=\"T_76803_row5_col1\" class=\"data row5 col1\" >98.09</td>\n",
       "      <td id=\"T_76803_row5_col2\" class=\"data row5 col2\" >98.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row6\" class=\"row_heading level0 row6\" >LSTM CRF + BETO + WE</th>\n",
       "      <td id=\"T_76803_row6_col0\" class=\"data row6 col0\" >97.37</td>\n",
       "      <td id=\"T_76803_row6_col1\" class=\"data row6 col1\" >97.94</td>\n",
       "      <td id=\"T_76803_row6_col2\" class=\"data row6 col2\" >98.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row7\" class=\"row_heading level0 row7\" >LSTM CRF + FLAIR + WE</th>\n",
       "      <td id=\"T_76803_row7_col0\" class=\"data row7 col0\" >96.84</td>\n",
       "      <td id=\"T_76803_row7_col1\" class=\"data row7 col1\" >97.31</td>\n",
       "      <td id=\"T_76803_row7_col2\" class=\"data row7 col2\" >98.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76803_level0_row8\" class=\"row_heading level0 row8\" >LSTM CRF + FLAIR</th>\n",
       "      <td id=\"T_76803_row8_col0\" class=\"data row8 col0\" >96.88</td>\n",
       "      <td id=\"T_76803_row8_col1\" class=\"data row8 col1\" >97.64</td>\n",
       "      <td id=\"T_76803_row8_col2\" class=\"data row8 col2\" >98.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2ff48694c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((result_metrics*100)\n",
    ".iloc[::2, ::]\n",
    ".style\n",
    ".background_gradient()\n",
    ".set_table_styles([\n",
    "    {'selector': '.index_name', 'props': 'font-style: italic; color: darkgrey; font-weight:normal;'},\n",
    "    {'selector': 'th.col_heading', 'props': 'text-align: center;'},\n",
    "    {'selector': 'th.col_heading.level0', 'props': 'font-size: 1.5em;'},\n",
    "    {'selector': 'td', 'props': 'text-align: center; font-weight: bold;'},\n",
    "], overwrite=False)\n",
    ".hide(axis=\"index\", level=1)\n",
    ".hide(axis=\"columns\", level=1)\n",
    ".format(precision=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f89559bc32b8577479c9159291558d358fde821c77c8596ffd3d3e81e733cec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
