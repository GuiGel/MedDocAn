{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive the scores obtained for Subtask 1 and 2 with XLM-R embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable, DefaultDict, List, NamedTuple\n",
    "\n",
    "\n",
    "class SubtrackScores(NamedTuple):\n",
    "    precision: float\n",
    "    recall: float\n",
    "\n",
    "def _get_scores(folder_path: Path, filename: str, precision_line: int, recall_line: int) -> SubtrackScores:\n",
    "    fpth = Path(folder_path / filename)\n",
    "    if not fpth.exists():\n",
    "        raise FileNotFoundError(f\"{fpth} not found!\")\n",
    "\n",
    "    lines = fpth.read_text().split(\"\\n\")\n",
    "\n",
    "    precision = float(lines[precision_line].split(\"=\")[-1])\n",
    "    recall = float(lines[recall_line].split(\"=\")[-1])\n",
    "\n",
    "    return SubtrackScores(precision, recall)\n",
    "\n",
    "def get_subtrack1_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"ner\", -3, -2)\n",
    "\n",
    "def get_subtrack2_strict_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -6, -5)\n",
    "\n",
    "def get_subtrack2_merged_scores(folder_path: Path) -> SubtrackScores:\n",
    "    return _get_scores(folder_path, \"spans\", -3, -2)\n",
    "\n",
    "def get_scores_as_df(seeds: List[int], get_folder: Callable[[int], Path]) -> pd.DataFrame:\n",
    "    subtracks_scores: DefaultDict[List, float] = defaultdict(list)\n",
    "\n",
    "    for seed in seeds:\n",
    "        fpth = get_folder(seed)\n",
    "\n",
    "        p, r = get_subtrack1_scores(fpth)\n",
    "        subtracks_scores[\"1_p\"].append(p)\n",
    "        subtracks_scores[\"1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_strict_scores(fpth)\n",
    "        subtracks_scores[\"2_1_p\"].append(p)\n",
    "        subtracks_scores[\"2_1_r\"].append(r)\n",
    "\n",
    "        p, r = get_subtrack2_merged_scores(fpth)\n",
    "        subtracks_scores[\"2_2_p\"].append(p)\n",
    "        subtracks_scores[\"2_2_r\"].append(r)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(subtracks_scores)\n",
    "    for col in [\"1\", \"2_1\", \"2_2\"]:\n",
    "        df[f\"{col}_f1\"] = 2*df[f\"{col}_p\"]*df[f\"{col}_r\"] / (df[f\"{col}_p\"] + df[f\"{col}_r\"])\n",
    "\n",
    "    # Reorder columns\n",
    "    new_columns = [\"1_p\", \"1_r\", \"1_f1\", \"2_1_p\", \"2_1_r\", \"2_1_f1\", \"2_2_p\", \"2_2_r\", \"2_2_f1\"]\n",
    "    df = df[new_columns]\n",
    "\n",
    "    # Prepare multi index names\n",
    "    multi_index = pd.MultiIndex.from_product(\n",
    "        [\n",
    "            [\"Subtrack 1\", \"Subtrack 2 [Strict]\", \"Subtrack 2 [Merged]\"],\n",
    "            [\"precision\", \"recall\", \"f1\"]\n",
    "        ],\n",
    "        names=[\"Track\", \"Scores\"]\n",
    "    )\n",
    "    # Give multi index to df\n",
    "    return pd.DataFrame(df.to_numpy().T, index=multi_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results obtained for the differents tracks on **dev** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 1</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.971696</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.978452</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.975062</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 2 [Strict]</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.976033</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.982819</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.979414</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 2 [Merged]</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.982832</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.987816</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.985318</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "Track               Scores                       \n",
       "Subtrack 1          precision  0.971696  0.000807\n",
       "                    recall     0.978452  0.001130\n",
       "                    f1         0.975062  0.000886\n",
       "Subtrack 2 [Strict] precision  0.976033  0.000948\n",
       "                    recall     0.982819  0.001122\n",
       "                    f1         0.979414  0.000948\n",
       "Subtrack 2 [Merged] precision  0.982832  0.000605\n",
       "                    recall     0.987816  0.000247\n",
       "                    f1         0.985318  0.000318"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_folder = Path(\"/home/wave/Project/MedDocAn/experiments/corpus_sentence_grid_search_flert_xlm-roberta_docstart\")\n",
    "\n",
    "df = get_scores_as_df(\n",
    "    [1, 33, 12],\n",
    "    lambda seed: base_folder / f\"an_wh_rs_False_dpt_0_emb_xlm-roberta-large-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/dev\"\n",
    ")\n",
    "df.T.describe().T[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same for the **test** sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 1</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.971690</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.978155</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.974911</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 2 [Strict]</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.976896</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.983395</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Subtrack 2 [Merged]</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.984255</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.988815</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "Track               Scores                       \n",
       "Subtrack 1          precision  0.971690  0.001203\n",
       "                    recall     0.978155  0.000204\n",
       "                    f1         0.974911  0.000691\n",
       "Subtrack 2 [Strict] precision  0.976896  0.001209\n",
       "                    recall     0.983395  0.000353\n",
       "                    f1         0.980135  0.000723\n",
       "Subtrack 2 [Merged] precision  0.984255  0.000097\n",
       "                    recall     0.988815  0.000937\n",
       "                    f1         0.986529  0.000465"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_folder = Path(\"/home/wave/Project/MedDocAn/experiments/corpus_sentence_grid_search_flert_xlm-roberta_docstart\")\n",
    "\n",
    "df = get_scores_as_df(\n",
    "    [1, 33, 12],\n",
    "    lambda seed: base_folder / f\"an_wh_rs_False_dpt_0_emb_xlm-roberta-large-cased-context_FT_True_Ly_-1_seed_{seed}_lr_5e-06_it_40_bs_4_opti_AdamW_pjct_emb_False_sdl_LinearSchedulerWithWarmup_use_crf_False_use_rnn_False_wup_0.1/0/evals/test\"\n",
    ")\n",
    "df.T.describe().T[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only want to see the f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.974911</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Strict]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtrack 2 [Merged]</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mean       std\n",
       "Track               Scores                    \n",
       "Subtrack 1          f1      0.974911  0.000691\n",
       "Subtrack 2 [Strict] f1      0.980135  0.000723\n",
       "Subtrack 2 [Merged] f1      0.986529  0.000465"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice[:, ['f1']], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Track</th>\n",
       "      <th>Scores</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subtrack 1</th>\n",
       "      <th>f1</th>\n",
       "      <td>0.974911</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       std\n",
       "Track      Scores                    \n",
       "Subtrack 1 f1      0.974911  0.000691"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T.describe().T[[\"mean\", \"std\"]].loc[pd.IndexSlice['Subtrack 1', ['f1']], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f89559bc32b8577479c9159291558d358fde821c77c8596ffd3d3e81e733cec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
