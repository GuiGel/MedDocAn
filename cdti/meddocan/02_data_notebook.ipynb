{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "from meddocan.data.docs_iterators import GsDocs\n",
    "from meddocan.data import ArchiveFolder, meddocan_zip\n",
    "from typing import Type\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Token\n",
    "from pathlib import Path\n",
    "\n",
    "def get_number_of_doc(archive_folder: Type[ArchiveFolder], attr: str) -> int:\n",
    "    total = sum([1 for _ in meddocan_zip.brat_files(getattr(archive_folder, attr))])\n",
    "    return total\n",
    "\n",
    "def get_labels(token: Token) -> str:\n",
    "    if token.ent_iob_ == \"O\":\n",
    "        return token.ent_iob_\n",
    "    else:\n",
    "        return f\"{token.ent_iob_}_{token.ent_type_}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a clinical case as well as the associated annotation at the **Brat** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "'Datos del paciente.\\nNombre:  Ernesto.\\nApellidos: Rivera Bueno.\\nNHC: 368503.\\nNASS: 26 63514095.\\nDomicilio:  Calle Miguel Benitez 90.\\nLocalidad/ Provincia: Madrid.\\nCP: 28016.\\nDatos asistenciales.\\nFecha de nacimiento: 03/03/1946.\\nPaís: España.\\nEdad: 70 años Sexo: H.\\nFecha de Ingreso: 12/12/2016.\\nMédico:  Ignacio Navarro Cuéllar NºCol: 28 28 70973.\\nInforme clínico del paciente: Paciente de 70 años de edad, minero jubilado, sin alergias medicamentosas conocidas, que presenta como antecedentes personales: accidente laboral antiguo con fracturas vertebrales y costales; intervenido de enfermedad de Dupuytren en mano derecha y by-pass iliofemoral izquierdo; Diabetes Mellitus tipo II, hipercolesterolemia e hiperuricemia; enolismo activo, fumador de 20 cigarrillos / día.\\nEs derivado desde Atención Primaria por presentar hematuria macroscópica postmiccional en una ocasión y microhematuria persistente posteriormente, con micciones normales.\\nEn la exploración física presenta un buen estado general, con abdomen y genitales normales; tacto rectal compatible con adenoma de próstata grado I/IV.\\nEn la analítica de orina destaca la existencia de 4 hematíes/ campo y 0-5 leucocitos/campo; resto de sedimento normal.\\nHemograma normal; en la bioquímica destaca una glucemia de 169 mg/dl y triglicéridos de 456 mg/dl; función hepática y renal normal. PSA de 1.16 ng/ml.\\nLas citologías de orina son repetidamente sospechosas de malignidad.\\nEn la placa simple de abdomen se valoran cambios degenerativos en columna lumbar y calcificaciones vasculares en ambos hipocondrios y en pelvis.\\nLa ecografía urológica pone de manifiesto la existencia de quistes corticales simples en riñón derecho, vejiga sin alteraciones con buena capacidad y próstata con un peso de 30 g.\\nEn la UIV se observa normofuncionalismo renal bilateral, calcificaciones sobre silueta renal derecha y uréteres arrosariados con imágenes de adición en el tercio superior de ambos uréteres, en relación a pseudodiverticulosis ureteral. El cistograma demuestra una vejiga con buena capacidad, pero paredes trabeculadas en relación a vejiga de esfuerzo. La TC abdominal es normal.\\nLa cistoscopia descubre la existencia de pequeñas tumoraciones vesicales, realizándose resección transuretral con el resultado anatomopatológico de carcinoma urotelial superficial de vejiga.\\nRemitido por: Ignacio Navarro Cuéllar c/ del Abedul 5-7, 2º dcha 28036 Madrid, España E-mail: nnavcu@hotmail.com.\\n'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "txt_ex"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "'T1\\tFECHAS 215 225\\t03/03/1946\\nT2\\tCORREO_ELECTRONICO 2421 2439\\tnnavcu@hotmail.com\\nT3\\tPAIS 2406 2412\\tEspaña\\nT4\\tTERRITORIO 2398 2404\\tMadrid\\nT5\\tTERRITORIO 2392 2397\\t28036\\nT6\\tCALLE 2365 2391\\tc/ del Abedul 5-7, 2º dcha\\nT7\\tNOMBRE_PERSONAL_SANITARIO 303 326\\tIgnacio Navarro Cuéllar\\nT8\\tNOMBRE_PERSONAL_SANITARIO 2341 2364\\tIgnacio Navarro Cuéllar\\nT9\\tEDAD_SUJETO_ASISTENCIA 389 396\\t70 años\\nT10\\tID_TITULACION_PERSONAL_SANITARIO 334 345\\t28 28 70973\\nT11\\tFECHAS 282 292\\t12/12/2016\\nT12\\tSEXO_SUJETO_ASISTENCIA 261 262\\tH\\nT13\\tEDAD_SUJETO_ASISTENCIA 247 254\\t70 años\\nT14\\tPAIS 233 239\\tEspaña\\nT15\\tTERRITORIO 166 171\\t28016\\nT16\\tTERRITORIO 154 160\\tMadrid\\nT17\\tCALLE 107 130\\tCalle Miguel Benitez 90\\nT18\\tID_ASEGURAMIENTO 82 93\\t26 63514095\\nT19\\tID_SUJETO_ASISTENCIA 68 74\\t368503\\nT20\\tNOMBRE_SUJETO_ASISTENCIA 49 61\\tRivera Bueno\\nT21\\tNOMBRE_SUJETO_ASISTENCIA 29 36\\tErnesto\\n'"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "brat_ex"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_docs = list(iter(GsDocs(ArchiveFolder.train)))  # Gold Standard Document\n",
    "doc = gs_docs[0].doc\n",
    "brat = gs_docs[0].brat_files_pair.ann.read_text()\n",
    "\n",
    "glue(\"txt_ex\", doc.text, display=False)\n",
    "glue(\"brat_ex\", brat, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the document as rendered by **spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy_ex = displacy.render(doc[17: 44], style=\"ent\", page=False, minify=True, jupyter=False)\n",
    "# glue(\"display_ex\", displacy_ex, display=False)\n",
    "\n",
    "# output_path = Path(\"../figures/displacy_ner.svg\") # you can keep there only \"dependency_plot.svg\" if you want to save it in the same folder where you run the script\n",
    "# output_path.touch(exist_ok=True)\n",
    "# output_path.open(\"w\", encoding=\"utf-8\").write(displacy_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data sentence, tokenization and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NHC: 368503.\\n</td>\n",
       "      <td>['NHC', ':', '368503', '.', '\\n']</td>\n",
       "      <td>['O', 'O', 'B_ID_SUJETO_ASISTENCIA', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASS: 26 63514095.\\n</td>\n",
       "      <td>['NASS', ':', '26', '63514095', '.', '\\n']</td>\n",
       "      <td>['O', 'O', 'B_ID_ASEGURAMIENTO', 'I_ID_ASEGURAMIENTO', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Domicilio:  Calle Miguel Benitez 90.\\n</td>\n",
       "      <td>['Domicilio', ':', ' ', 'Calle', 'Miguel', 'Benitez', '90', '.', '\\n']</td>\n",
       "      <td>['O', 'O', 'O', 'B_CALLE', 'I_CALLE', 'I_CALLE', 'I_CALLE', 'O', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Localidad/ Provincia: Madrid.\\n</td>\n",
       "      <td>['Localidad', '/', 'Provincia', ':', 'Madrid', '.', '\\n']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'B_TERRITORIO', 'O', 'O']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Sentence  \\\n",
       "Idx                                           \n",
       "0                            NHC: 368503.\\n   \n",
       "1                      NASS: 26 63514095.\\n   \n",
       "2    Domicilio:  Calle Miguel Benitez 90.\\n   \n",
       "3           Localidad/ Provincia: Madrid.\\n   \n",
       "\n",
       "                                                                     Tokens  \\\n",
       "Idx                                                                           \n",
       "0                                         ['NHC', ':', '368503', '.', '\\n']   \n",
       "1                                ['NASS', ':', '26', '63514095', '.', '\\n']   \n",
       "2    ['Domicilio', ':', ' ', 'Calle', 'Miguel', 'Benitez', '90', '.', '\\n']   \n",
       "3                 ['Localidad', '/', 'Provincia', ':', 'Madrid', '.', '\\n']   \n",
       "\n",
       "                                                                    Labels  \n",
       "Idx                                                                         \n",
       "0                           ['O', 'O', 'B_ID_SUJETO_ASISTENCIA', 'O', 'O']  \n",
       "1         ['O', 'O', 'B_ID_ASEGURAMIENTO', 'I_ID_ASEGURAMIENTO', 'O', 'O']  \n",
       "2    ['O', 'O', 'O', 'B_CALLE', 'I_CALLE', 'I_CALLE', 'I_CALLE', 'O', 'O']  \n",
       "3                           ['O', 'O', 'O', 'O', 'B_TERRITORIO', 'O', 'O']  "
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "data_preparation"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = list(doc.sents)[3:7]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Sentence\": [sentence.text for sentence in sentences],\n",
    "        \"Tokens\": [f\"{[token.text for token in sentence]}\" for sentence in sentences],\n",
    "        \"Labels\": [f\"{[get_labels(token) for token in sentence]}\" for sentence in sentences],\n",
    "        \"Idx\": range(len(sentences)),\n",
    "    },\n",
    ").set_index(\"Idx\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "glue(\"data_preparation\", df, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The special example of \"DominguezCorreo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'DominguezCorreo' -> ['Dominguez', 'Correo']\""
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "spacing_error_ex"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from meddocan.language.pipeline import meddocan_pipeline\n",
    "nlp = meddocan_pipeline()\n",
    "sentence = \"DominguezCorreo\"\n",
    "spacing_error_ex = f\"{sentence!r} -> {[token.text for token in nlp(sentence)]!r}\"\n",
    "spacing_error_ex = glue(\"spacing_error_ex\", spacing_error_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract statistics about corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-24 08:36:59,092 Reading data from /tmp/tmpaw7v9k6_\n",
      "2022-10-24 08:36:59,093 Train: /tmp/tmpaw7v9k6_/train\n",
      "2022-10-24 08:36:59,093 Dev: /tmp/tmpaw7v9k6_/dev\n",
      "2022-10-24 08:36:59,094 Test: /tmp/tmpaw7v9k6_/test\n"
     ]
    }
   ],
   "source": [
    "from meddocan.data.corpus import MEDDOCAN\n",
    "\n",
    "corpus = MEDDOCAN(sentences=True, document_separator_token=\"-DOCSTART-\", in_memory=True)\n",
    "stats = corpus.obtain_statistics(pretty_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>TEST</th>\n",
       "      <th>DEV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TERRITORIO</th>\n",
       "      <td>1875</td>\n",
       "      <td>956</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FECHAS</th>\n",
       "      <td>1231</td>\n",
       "      <td>611</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDAD_SUJETO_ASISTENCIA</th>\n",
       "      <td>1035</td>\n",
       "      <td>518</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOMBRE_SUJETO_ASISTENCIA</th>\n",
       "      <td>1009</td>\n",
       "      <td>502</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOMBRE_PERSONAL_SANITARIO</th>\n",
       "      <td>1000</td>\n",
       "      <td>501</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXO_SUJETO_ASISTENCIA</th>\n",
       "      <td>925</td>\n",
       "      <td>461</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALLE</th>\n",
       "      <td>862</td>\n",
       "      <td>413</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAIS</th>\n",
       "      <td>713</td>\n",
       "      <td>363</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_SUJETO_ASISTENCIA</th>\n",
       "      <td>567</td>\n",
       "      <td>283</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_TITULACION_PERSONAL_SANITARIO</th>\n",
       "      <td>471</td>\n",
       "      <td>234</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORREO_ELECTRONICO</th>\n",
       "      <td>469</td>\n",
       "      <td>249</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_ASEGURAMIENTO</th>\n",
       "      <td>391</td>\n",
       "      <td>198</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOSPITAL</th>\n",
       "      <td>255</td>\n",
       "      <td>130</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMILIARES_SUJETO_ASISTENCIA</th>\n",
       "      <td>243</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTITUCION</th>\n",
       "      <td>98</td>\n",
       "      <td>67</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_CONTACTO_ASISTENCIAL</th>\n",
       "      <td>77</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMERO_TELEFONO</th>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROFESION</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMERO_FAX</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTROS_SUJETO_ASISTENCIA</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTRO_SALUD</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_EMPLEO_PERSONAL_SANITARIO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>11333</td>\n",
       "      <td>5661</td>\n",
       "      <td>5801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TRAIN  TEST   DEV\n",
       "TERRITORIO                         1875   956   987\n",
       "FECHAS                             1231   611   724\n",
       "EDAD_SUJETO_ASISTENCIA             1035   518   521\n",
       "NOMBRE_SUJETO_ASISTENCIA           1009   502   503\n",
       "NOMBRE_PERSONAL_SANITARIO          1000   501   497\n",
       "SEXO_SUJETO_ASISTENCIA              925   461   455\n",
       "CALLE                               862   413   434\n",
       "PAIS                                713   363   347\n",
       "ID_SUJETO_ASISTENCIA                567   283   292\n",
       "ID_TITULACION_PERSONAL_SANITARIO    471   234   226\n",
       "CORREO_ELECTRONICO                  469   249   241\n",
       "ID_ASEGURAMIENTO                    391   198   194\n",
       "HOSPITAL                            255   130   140\n",
       "FAMILIARES_SUJETO_ASISTENCIA        243    81    92\n",
       "INSTITUCION                          98    67    72\n",
       "ID_CONTACTO_ASISTENCIAL              77    39    32\n",
       "NUMERO_TELEFONO                      58    26    25\n",
       "PROFESION                            24     9     4\n",
       "NUMERO_FAX                           15     7     6\n",
       "OTROS_SUJETO_ASISTENCIA               9     7     6\n",
       "CENTRO_SALUD                          6     6     2\n",
       "ID_EMPLEO_PERSONAL_SANITARIO          0     0     1\n",
       "TOTAL                             11333  5661  5801"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "phi_statistics"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "phi_class_num"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_name = \"number_of_documents_per_class\"\n",
    "df_phi_stats = (\n",
    "    pd.DataFrame({k: stats[k][v_name] for k in stats.keys()})\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .sort_values(by=[\"TRAIN\"], ascending=False)\n",
    ")\n",
    "df_phi_stats.loc[\"TOTAL\"] = df_phi_stats.sum()\n",
    "glue(\"phi_statistics\", df_phi_stats)\n",
    "unique_phi_classes = len(df_phi_stats) - 1\n",
    "glue(\"phi_class_num\", unique_phi_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num docs</th>\n",
       "      <th>num sentences</th>\n",
       "      <th>num tokens</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>Min token per sentence</th>\n",
       "      <th>Max token per sentence</th>\n",
       "      <th>Avg token per sentence</th>\n",
       "      <th>num PHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>500</td>\n",
       "      <td>10811</td>\n",
       "      <td>263963</td>\n",
       "      <td>22695</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>24</td>\n",
       "      <td>11333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEV</th>\n",
       "      <td>250</td>\n",
       "      <td>5518</td>\n",
       "      <td>139400</td>\n",
       "      <td>15466</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "      <td>25</td>\n",
       "      <td>5801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST</th>\n",
       "      <td>250</td>\n",
       "      <td>5405</td>\n",
       "      <td>132698</td>\n",
       "      <td>14933</td>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "      <td>24</td>\n",
       "      <td>5661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num docs  num sentences  num tokens  vocabulary  \\\n",
       "TRAIN       500          10811      263963       22695   \n",
       "DEV         250           5518      139400       15466   \n",
       "TEST        250           5405      132698       14933   \n",
       "\n",
       "       Min token per sentence  Max token per sentence  Avg token per sentence  \\\n",
       "TRAIN                       1                     712                      24   \n",
       "DEV                         1                     571                      25   \n",
       "TEST                        1                     477                      24   \n",
       "\n",
       "       num PHI  \n",
       "TRAIN    11333  \n",
       "DEV       5801  \n",
       "TEST      5661  "
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "doc_statistics"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num sentences</th>\n",
       "      <th>Min token per sentence</th>\n",
       "      <th>Max token per sentence</th>\n",
       "      <th>Avg token per sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN</th>\n",
       "      <td>10811</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEV</th>\n",
       "      <td>5518</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST</th>\n",
       "      <td>5405</td>\n",
       "      <td>1</td>\n",
       "      <td>477</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num sentences  Min token per sentence  Max token per sentence  \\\n",
       "TRAIN          10811                       1                     712   \n",
       "DEV             5518                       1                     571   \n",
       "TEST            5405                       1                     477   \n",
       "\n",
       "       Avg token per sentence  \n",
       "TRAIN                      24  \n",
       "DEV                        25  \n",
       "TEST                       24  "
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "sent_statistics"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from collections import Counter\n",
    "from flair.data import Dataset, _iter_dataset, Dictionary\n",
    "\n",
    "def _get_all_tokens(dataset: Dataset) -> List[str]:\n",
    "    assert dataset\n",
    "    tokens = list(map((lambda s: s.tokens), _iter_dataset(dataset)))\n",
    "    tokens = [token for sublist in tokens for token in sublist]\n",
    "    return list(map((lambda t: t.text), tokens))\n",
    "\n",
    "def _get_most_common_tokens(dataset: Dataset, max_tokens, min_freq) -> List[str]:\n",
    "    tokens_and_frequencies = Counter(_get_all_tokens(dataset))\n",
    "\n",
    "    tokens: List[str] = []\n",
    "    for token, freq in tokens_and_frequencies.most_common():\n",
    "        if (min_freq != -1 and freq < min_freq) or (max_tokens != -1 and len(tokens) == max_tokens):\n",
    "            break\n",
    "        tokens.append(token)\n",
    "    return tokens\n",
    "\n",
    "def make_vocab_dictionary(dataset: Dataset, max_tokens=-1, min_freq=1) -> Dictionary:\n",
    "    \"\"\"\n",
    "    Creates a dictionary of all tokens contained in the corpus.\n",
    "    By defining `max_tokens` you can set the maximum number of tokens that should be contained in the dictionary.\n",
    "    If there are more than `max_tokens` tokens in the corpus, the most frequent tokens are added first.\n",
    "    If `min_freq` is set the a value greater than 1 only tokens occurring more than `min_freq` times are considered\n",
    "    to be added to the dictionary.\n",
    "    :param max_tokens: the maximum number of tokens that should be added to the dictionary (-1 = take all tokens)\n",
    "    :param min_freq: a token needs to occur at least `min_freq` times to be added to the dictionary (-1 = there is no limitation)\n",
    "    :return: dictionary of tokens\n",
    "    \"\"\"\n",
    "    tokens = _get_most_common_tokens(dataset, max_tokens, min_freq)\n",
    "\n",
    "    vocab_dictionary: Dictionary = Dictionary()\n",
    "    for token in tokens:\n",
    "        vocab_dictionary.add_item(token)\n",
    "\n",
    "    return vocab_dictionary\n",
    "\n",
    "\n",
    "df_doc_stats = pd.DataFrame(\n",
    "    {k: {\n",
    "            \"num docs\": get_number_of_doc(ArchiveFolder, k.lower()),\n",
    "            \"num sentences\": stats[k][\"total_number_of_documents\"],\n",
    "            \"num tokens\": stats[k][\"number_of_tokens\"][\"total\"],\n",
    "            \"vocabulary\": len(make_vocab_dictionary(getattr(corpus, k.lower()))),\n",
    "            \"Min token per sentence\": stats[k][\"number_of_tokens\"][\"min\"],\n",
    "            \"Max token per sentence\": stats[k][\"number_of_tokens\"][\"max\"],\n",
    "            \"Avg token per sentence\": stats[k][\"number_of_tokens\"][\"avg\"],\n",
    "            \"num PHI\": df_phi_stats.loc[\"TOTAL\"][k]\n",
    "        } for k in [\"TRAIN\", \"DEV\", \"TEST\"]\n",
    "    }\n",
    ").astype(int).T\n",
    "\n",
    "df_sentence_stats = pd.DataFrame(\n",
    "    {k: {\n",
    "            \"num sentences\": stats[k][\"total_number_of_documents\"],\n",
    "            \"Min token per sentence\": stats[k][\"number_of_tokens\"][\"min\"],\n",
    "            \"Max token per sentence\": stats[k][\"number_of_tokens\"][\"max\"],\n",
    "            \"Avg token per sentence\": stats[k][\"number_of_tokens\"][\"avg\"],\n",
    "        } for k in [\"TRAIN\", \"DEV\", \"TEST\"]\n",
    "    }\n",
    ").astype(int).T\n",
    "\n",
    "glue(\"doc_statistics\", df_doc_stats)\n",
    "glue(\"sent_statistics\", df_sentence_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "48a4d93b740453e3ad69474668bda133ab2279ad03ac178307f9ab10aa409dfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
