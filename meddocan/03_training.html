
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3. Entrenamiento &#8212; Anonimización aplicada al ámbito médico</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="4. Referencias" href="bibliography.html" />
    <link rel="prev" title="2. Clinical Corpus" href="02_data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo-serikat.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Anonimización aplicada al ámbito médico</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Introducción
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_evaluation.html">
   1. Evaluación
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_data.html">
   2. Clinical Corpus
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Entrenamiento
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   4. Referencias
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="a.html">
   5. Apéndice
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="a_transfer_learning.html">
     5.1. El concepto de transfer learning en NLP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="a_training.html">
     5.2. Training
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="a_code.html">
     5.3. Código
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="a_transformers.html">
     5.4. Transformers para NER
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/GuiGel/MedDocAn"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/GuiGel/MedDocAn/issues/new?title=Issue%20on%20page%20%2Fmeddocan/03_training.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/meddocan/03_training.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   3.1. Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experimentos-con-parametros-de-referencia">
   3.2. Experimentos con parámetros de referencia
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuracion">
     3.2.1. Configuración
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#primera-estrategia-ajuste-fino">
     3.2.2. Primera estrategia: Ajuste fino
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#segunda-estrategia-basado-en-caracteristicas">
     3.2.3. Segunda estrategia: Basado en características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#flair-baseline">
     3.2.4. Flair baseline
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resultados-mejor-configuracion">
     3.2.5. Resultados: Mejor configuración
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluacion-comparativa">
   3.3. Evaluación comparativa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principales-resultados">
     3.3.1. Principales resultados
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   3.4. Conclusión
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Entrenamiento</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   3.1. Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experimentos-con-parametros-de-referencia">
   3.2. Experimentos con parámetros de referencia
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#configuracion">
     3.2.1. Configuración
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#primera-estrategia-ajuste-fino">
     3.2.2. Primera estrategia: Ajuste fino
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#segunda-estrategia-basado-en-caracteristicas">
     3.2.3. Segunda estrategia: Basado en características
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#flair-baseline">
     3.2.4. Flair baseline
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#resultados-mejor-configuracion">
     3.2.5. Resultados: Mejor configuración
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluacion-comparativa">
   3.3. Evaluación comparativa
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principales-resultados">
     3.3.1. Principales resultados
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   3.4. Conclusión
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="entrenamiento">
<h1><span class="section-number">3. </span>Entrenamiento<a class="headerlink" href="#entrenamiento" title="Permalink to this headline">#</a></h1>
<section id="introduccion">
<h2><span class="section-number">3.1. </span>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">#</a></h2>
<p>Como lo hemos visto en la primera parte, el reconocimiento entidades nombradas (NER) es una tarea de NLP muy estudiada que consiste en predecir etiquetas semánticas superficiales para una secuencia de palabras.</p>
<p>Los enfoques actuales para el NER consisten en aprovechar arquitecturas de transformadores pre-entrenados, como <span id="id1">[<a class="reference internal" href="bibliography.html#id5" title="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: pre-training of deep bidirectional transformers for language understanding. ArXiv, 2019.">Devlin <em>et al.</em>, 2019</a>]</span> o <span id="id2">[<a class="reference internal" href="bibliography.html#id8" title="Guillaume Lample and Alexis Conneau. Cross-lingual language model pretraining. In NeurIPS. 2019.">Lample and Conneau, 2019</a>]</span>. Esos transformadores han sido pre-entrenados en otras tareas sobre un corpus grande y sirven de base para entrenar modelos de NER transfiriendo su aprendizaje previo a esa tarea (véase la <a class="reference internal" href="a_transfer_learning.html#transfer-learning-anexo"><span class="std std-numref">Section 5.1</span></a> del anexo).</p>
<p>Esos enfoques suelen considerar el texto a nivel de frase, exactamente como lo hemos hecho en el dominio jurídico, y por lo tanto no modelan la información que cruza los límites de la frase (Por una introducción a este enfoque así como un ejemplo de uso completo véase <a class="reference internal" href="a_transformers.html#transformers"><span class="std std-numref">Section 5.4</span></a>). Podemos hacerlo pasando una frase con su contexto circundante. Sin embargo, el uso de un modelo basado en transformadores para NER ofrece una opción natural para capturar características a nivel de documento. Como muestra <a class="reference internal" href="#fig-flert-1"><span class="std std-numref">Fig. 3.1</span></a>, este contexto puede influir en la representación de las palabras de una frase: La frase de ejemplo: “I love Paris”, pasa por el transformador junto con la siguiente frase que comienza con “The city is”, ayudando potencialmente a resolver la ambigüedad de la palabra “Paris”.</p>
<figure class="align-default" id="fig-flert-1">
<img alt="../_images/flert-1.png" src="../_images/flert-1.png" />
<figcaption>
<p><span class="caption-number">Fig. 3.1 </span><span class="caption-text">Para obtener características a nivel de documento para una frase que deseamos etiquetar (“I love Paris”, sombreada en verde), añadimos 64 tokens a la izquierda y a la derecha (sombreados en azul). Como el transformador calcula la auto-atención sobre todos los tokens de entrada, la representación de los tokens de la frase está influida por el contexto izquierdo y derecho.</span><a class="headerlink" href="#fig-flert-1" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Esto es exactamente lo que propone el nuevo enfoque Flert <span id="id3">[<a class="reference internal" href="bibliography.html#id6" title="Stefan Schweter and A. Akbik. Flert: document-level features for named entity recognition. ArXiv, 2020.">Schweter and Akbik, 2020</a>]</span> disponible en la biblioteca <strong>Flair</strong> <span id="id4">[<a class="reference internal" href="bibliography.html#id7" title="A. Akbik, Tanja Bergmann, Duncan A. J. Blythe, Kashif Rasul, Stefan Schweter, and Roland Vollgraf. Flair: an easy-to-use framework for state-of-the-art nlp. In NAACL. 2019.">Akbik <em>et al.</em>, 2019</a>]</span> que roza el estado del arte.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Hacer respetar los límites de los documentos.</strong> Los autores de Flert <span id="id5">[<a class="reference internal" href="bibliography.html#id6" title="Stefan Schweter and A. Akbik. Flert: document-level features for named entity recognition. ArXiv, 2020.">Schweter and Akbik, 2020</a>]</span> demuestran que el respeto de los límites de los documentos aumenta el escore <span class="math notranslate nohighlight">\(F_{1} micro\)</span> en casi todos sus experimentos y recomiendan su cumplimiento si es posible. Su expectativa inicial de que los transformadores aprenderían automáticamente a respetar los límites de los documentos no se materializó.
La aplicación de los límites del documento consiste en una ablación en la que se truncan las características del documento en los bordes del mismo, lo que significa que el contexto sólo puede proceder del mismo documento.</p>
</div>
<p>En la literatura, hay dos enfoques conceptualmente muy diferentes para el NER basado en transformadores que se utilizan actualmente, los dos son basados en el Transfer Learning. Evaluaremos las características de los documentos en ambos:</p>
<ol class="simple">
<li><p>En el primero, <em>afinamos</em> el propio transformador en la tarea NER y solo añadimos una capa lineal para las predicciones a nivel de palabra <span id="id6">[<a class="reference internal" href="bibliography.html#id5" title="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: pre-training of deep bidirectional transformers for language understanding. ArXiv, 2019.">Devlin <em>et al.</em>, 2019</a>]</span> .</p></li>
<li><p>En el segundo, utilizamos el transformador solo para proporcionar <em>características</em> a una arquitectura de etiquetado de secuencias LSTM-CRF <span id="id7">[<a class="reference internal" href="bibliography.html#id9" title="Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional lstm-crf models for sequence tagging. ArXiv, 2015.">Huang <em>et al.</em>, 2015</a>]</span> estándar y, por tanto, no realizamos ningún ajuste fino. Hemos utilizado la arquitectura LSTM-CRF previamente para el dominio judicial pero con los words embeddings contextuales de Flair <span id="id8">[<a class="reference internal" href="bibliography.html#id10" title="A. Akbik, Duncan A. J. Blythe, and Roland Vollgraf. Contextual string embeddings for sequence labeling. In COLING. 2018.">Akbik <em>et al.</em>, 2018</a>]</span> y embeddings estáticos como word2vec <span id="id9">[<a class="reference internal" href="bibliography.html#id11" title="Tomas Mikolov, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In ICLR. 2013.">Mikolov <em>et al.</em>, 2013</a>]</span>.</p></li>
</ol>
<p>Discutimos las diferencias entre ambos enfoques y exploramos los mejores hiperparámetros para cada uno, manualmente y con ayuda de la biblioteca <a class="reference external" href="http://hyperopt.github.io/hyperopt/">Hyperopt</a>. En su mejor configuración determinada, realizamos una evaluación comparativa a la cual integramos los mejores modelos entrenados con embeddings contextuales de Flair <span id="id10">[<a class="reference internal" href="bibliography.html#id10" title="A. Akbik, Duncan A. J. Blythe, and Roland Vollgraf. Contextual string embeddings for sequence labeling. In COLING. 2018.">Akbik <em>et al.</em>, 2018</a>]</span> con o sin embeddings estáticos <span id="id11">[<a class="reference internal" href="bibliography.html#id11" title="Tomas Mikolov, Kai Chen, Gregory S. Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. In ICLR. 2013.">Mikolov <em>et al.</em>, 2013</a>]</span> junto con la arquitectura LSTM-CRF (i.e. la mejor arquitectura sobre la tarea de anonimización de documentos judiciales).</p>
<div class="tip admonition">
<p class="admonition-title">Características a nivel de documento</p>
<p>El enfoque de Flert, que consiste en crear un contexto por cada frase, tiene ventajas computacionales, ya que cada frase y su contexto sólo tienen que pasar por el transformador una vez y el contexto añadido se limita a una ventana relativamente pequeña. Además, sigue siendo posible seguir el procedimiento estándar de mezclar las frases en cada momento del entrenamiento, ya que el contexto se codifica por frases.</p>
</div>
</section>
<section id="experimentos-con-parametros-de-referencia">
<span id="experiments"></span><h2><span class="section-number">3.2. </span>Experimentos con parámetros de referencia<a class="headerlink" href="#experimentos-con-parametros-de-referencia" title="Permalink to this headline">#</a></h2>
<p>Como se ha mencionado en la introducción, existen dos arquitecturas comunes para el NER basado en transformadores, a saber, los enfoques de ajuste fino y los basados en características.
En esta sección, presentamos brevemente las diferencias entre ambos enfoques y realizamos un estudio para identificar los mejores hiperparámetros para cada uno. Las mejores configuraciones de cada se utilizan luego en la evaluación comparativa final en la sección <a class="reference internal" href="#comparative-study"><span class="std std-ref">Evaluación comparativa</span></a>.</p>
<section id="configuracion">
<h3><span class="section-number">3.2.1. </span>Configuración<a class="headerlink" href="#configuracion" title="Permalink to this headline">#</a></h3>
<dl class="simple myst">
<dt><strong>Dataset</strong></dt><dd><p>Utilizamos el conjunto de datos de desarrollo de MEDDOCAN <a class="footnote-reference brackets" href="#id30" id="id12">1</a>.</p>
</dd>
<dt><strong>Modelo de transformador</strong></dt><dd><p>En todos los experimentos de esta sección, empleamos 2 modelos de transformadores:</p>
</dd>
</dl>
<ol class="simple">
<li><p>El modelo de transformador XLM-Roberta (XLMR) propuesto por <span id="id13">[<a class="reference internal" href="bibliography.html#id8" title="Guillaume Lample and Alexis Conneau. Cross-lingual language model pretraining. In NeurIPS. 2019.">Lample and Conneau, 2019</a>]</span>. En nuestros experimentos utilizamos <em>xlm-roberta large</em>, entrenado en 2,5TB de datos del corpus limpio Commom Crawl <span id="id14">[<a class="reference internal" href="bibliography.html#id17" title="Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzm'an, Armand Joulin, and Edouard Grave. Ccnet: extracting high quality monolingual datasets from web crawl data. In LREC. 2020.">Wenzek <em>et al.</em>, 2020</a>]</span> para 100 idiomas diferentes.</p></li>
<li><p>El modelo de transformador BERT propuesto por <span id="id15">[<a class="reference internal" href="bibliography.html#id5" title="Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: pre-training of deep bidirectional transformers for language understanding. ArXiv, 2019.">Devlin <em>et al.</em>, 2019</a>]</span>. En nuestros experimentos utilizamos <em>BETO</em>, un modelo bert entrenado en el gran corpus español <span id="id16">[<a class="reference internal" href="bibliography.html#id18" title="José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, and Jorge Pérez. Spanish pre-trained bert model and evaluation data. In PML4DC at ICLR 2020. 2020.">Cañete <em>et al.</em>, 2020</a>]</span>.</p></li>
</ol>
<dl class="simple myst">
<dt><strong>Embeddings (+ WE)</strong></dt><dd><p>Para cada configuración experimentamos concatenando embeddings de palabras clásicas a las representaciones a nivel de palabra obtenidas del modelo transformador. Utilizamos los embeddings de FastText en español <span id="id17">[<a class="reference internal" href="bibliography.html#id20" title="Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135-146, 2017.">Bojanowski <em>et al.</em>, 2017</a>]</span> estabilizados <span id="id18">[<a class="reference internal" href="bibliography.html#id19" title="Maria Antoniak and David Mimno. Evaluating the stability of embedding-based word similarities. Transactions of the Association for Computational Linguistics, 6:107-119, 2018.">Antoniak and Mimno, 2018</a>]</span>.</p>
</dd>
</dl>
</section>
<section id="primera-estrategia-ajuste-fino">
<h3><span class="section-number">3.2.2. </span>Primera estrategia: Ajuste fino<a class="headerlink" href="#primera-estrategia-ajuste-fino" title="Permalink to this headline">#</a></h3>
<p>Las estrategias de ajuste fino suelen añadir una sola capa lineal a un transformador y ajustan toda la arquitectura en la tarea NER. Para hacer el puente entre el modelado de subtokens y las predicciones a nivel de tokens, aplican la agrupación de subpalabras para crear representaciones a nivel de tokens que luego se pasan a la capa lineal final. Conceptualmente, este enfoque tiene la ventaja de que todo se modela en una única arquitectura que se ajusta en su conjunto. En la <a class="reference internal" href="a_training.html#appendix-1"><span class="std std-numref">Section 5.2.1</span></a> del anexo se dan más detalles sobre los parámetros y la arquitectura.</p>
<p>Evaluamos esta estrategia con los transformadores BETO <span id="id19">[<a class="reference internal" href="bibliography.html#id18" title="José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, and Jorge Pérez. Spanish pre-trained bert model and evaluation data. In PML4DC at ICLR 2020. 2020.">Cañete <em>et al.</em>, 2020</a>]</span> y XLMR <span id="id20">[<a class="reference internal" href="bibliography.html#id8" title="Guillaume Lample and Alexis Conneau. Cross-lingual language model pretraining. In NeurIPS. 2019.">Lample and Conneau, 2019</a>]</span>. Los resultados figuran en la <a class="reference internal" href="#finetuning-approach"><span class="std std-numref">tabla 3.2</span></a>.</p>
<figure class="align-center" id="finetuning-approach" style="width: 800px">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_b974e .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_b974e th.level1 {
  text-align: left;
}
#T_b974e th.level0 {
  text-align: center;
}
#T_b974e th.col_heading {
  text-align: center;
}
#T_b974e th.col_heading.level0 {
  font-size: 1.5em;
}
#T_b974e td {
  text-align: center;
  font-weight: bold;
}
#T_b974e_row0_col0, #T_b974e_row0_col1, #T_b974e_row6_col2 {
  background-color: #fcce25;
}
#T_b974e_row0_col2 {
  background-color: #e56b5d;
}
#T_b974e_row1_col0 {
  background-color: #f48948;
}
#T_b974e_row1_col1 {
  background-color: #e56a5d;
}
#T_b974e_row1_col2 {
  background-color: #2f0596;
}
#T_b974e_row2_col0 {
  background-color: #f48849;
}
#T_b974e_row2_col1, #T_b974e_row3_col1 {
  background-color: #da5a6a;
}
#T_b974e_row2_col2 {
  background-color: #f79044;
}
#T_b974e_row3_col0 {
  background-color: #8a09a5;
}
#T_b974e_row3_col2 {
  background-color: #7701a8;
}
#T_b974e_row4_col0 {
  background-color: #2e0595;
}
#T_b974e_row4_col1 {
  background-color: #5601a4;
}
#T_b974e_row4_col2, #T_b974e_row5_col0, #T_b974e_row5_col1 {
  background-color: #0d0887;
}
#T_b974e_row5_col2 {
  background-color: #5c01a6;
}
#T_b974e_row6_col0 {
  background-color: #a01a9c;
}
#T_b974e_row6_col1 {
  background-color: #f0804e;
}
</style>
<table id="T_b974e">
  <thead>
    <tr>
      <th class="blank" >&nbsp;</th>
      <th class="index_name level0" >Track</th>
      <th id="T_b974e_level0_col0" class="col_heading level0 col0" >Subtrack 1</th>
      <th id="T_b974e_level0_col1" class="col_heading level0 col1" >Subtrack 2 [Strict]</th>
      <th id="T_b974e_level0_col2" class="col_heading level0 col2" >Subtrack 2 [Merged]</th>
    </tr>
    <tr>
      <th class="index_name level0" >Transformador</th>
      <th class="index_name level1" >Estrategia</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_b974e_level0_row0" class="row_heading level0 row0" rowspan="3">XLMR LARGE</th>
      <th id="T_b974e_level1_row0" class="row_heading level1 row0" >Transformador lineal</th>
      <td id="T_b974e_row0_col0" class="data row0 col0" >97.56 ± 0.16</td>
      <td id="T_b974e_row0_col1" class="data row0 col1" >98.0 ± 0.17</td>
      <td id="T_b974e_row0_col2" class="data row0 col2" >98.62 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b974e_level1_row1" class="row_heading level1 row1" >+ Context</th>
      <td id="T_b974e_row1_col0" class="data row1 col0" >97.51 ± 0.09</td>
      <td id="T_b974e_row1_col1" class="data row1 col1" >97.94 ± 0.09</td>
      <td id="T_b974e_row1_col2" class="data row1 col2" >98.53 ± 0.03</td>
    </tr>
    <tr>
      <th id="T_b974e_level1_row2" class="row_heading level1 row2" >+ WE</th>
      <td id="T_b974e_row2_col0" class="data row2 col0" >97.51 ± 0.12</td>
      <td id="T_b974e_row2_col1" class="data row2 col1" >97.93 ± 0.13</td>
      <td id="T_b974e_row2_col2" class="data row2 col2" >98.63 ± 0.09</td>
    </tr>
    <tr>
      <th id="T_b974e_level0_row3" class="row_heading level0 row3" rowspan="4">BETO</th>
      <th id="T_b974e_level1_row3" class="row_heading level1 row3" >Transformador lineal</th>
      <td id="T_b974e_row3_col0" class="data row3 col0" >97.38 ± 0.21</td>
      <td id="T_b974e_row3_col1" class="data row3 col1" >97.93 ± 0.16</td>
      <td id="T_b974e_row3_col2" class="data row3 col2" >98.56 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b974e_level1_row4" class="row_heading level1 row4" >+ Context</th>
      <td id="T_b974e_row4_col0" class="data row4 col0" >97.32 ± 0.1</td>
      <td id="T_b974e_row4_col1" class="data row4 col1" >97.84 ± 0.1</td>
      <td id="T_b974e_row4_col2" class="data row4 col2" >98.52 ± 0.03</td>
    </tr>
    <tr>
      <th id="T_b974e_level1_row5" class="row_heading level1 row5" >+ WE</th>
      <td id="T_b974e_row5_col0" class="data row5 col0" >97.3 ± 0.08</td>
      <td id="T_b974e_row5_col1" class="data row5 col1" >97.8 ± 0.1</td>
      <td id="T_b974e_row5_col2" class="data row5 col2" >98.55 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b974e_level1_row6" class="row_heading level1 row6" >+ WE + Context</th>
      <td id="T_b974e_row6_col0" class="data row6 col0" >97.4 ± 0.16</td>
      <td id="T_b974e_row6_col1" class="data row6 col1" >97.96 ± 0.18</td>
      <td id="T_b974e_row6_col2" class="data row6 col2" >98.66 ± 0.06</td>
    </tr>
  </tbody>
</table>
</div></div>
<figcaption>
<p><span class="caption-number">Fig. 3.2 </span><span class="caption-text">Evaluación de diferentes transformadores mediante el proceso de ajuste fino. La evaluación se realiza contra el conjunto de desarrollo.</span><a class="headerlink" href="#finetuning-approach" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="segunda-estrategia-basado-en-caracteristicas">
<h3><span class="section-number">3.2.3. </span>Segunda estrategia: Basado en características<a class="headerlink" href="#segunda-estrategia-basado-en-caracteristicas" title="Permalink to this headline">#</a></h3>
<p>En cambio, los enfoques basados en características utilizan el transformador solo para generar embeddings para cada palabra de una frase y las utilizan como entrada en una arquitectura de etiquetado de secuencias estándar, normalmente una LSTM-CRF <span id="id21">[<a class="reference internal" href="bibliography.html#id9" title="Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional lstm-crf models for sequence tagging. ArXiv, 2015.">Huang <em>et al.</em>, 2015</a>]</span>. Los pesos del transformador se congelan para que el entrenamiento se limite al LSTM-CRF. Conceptualmente, este enfoque se beneficia de un procedimiento de entrenamiento del modelo bien entendido que incluye un criterio de parada real. En la <a class="reference internal" href="a_training.html#appendix-2"><span class="std std-numref">Section 5.2.2</span></a> del anexo se dan más detalles sobre los parámetros y la arquitectura. En nuestros experimentos solo evaluamos una variante de las dos propuestas en <span id="id22">[<a class="reference internal" href="bibliography.html#id6" title="Stefan Schweter and A. Akbik. Flert: document-level features for named entity recognition. ArXiv, 2020.">Schweter and Akbik, 2020</a>]</span> porque suele dar los mejores resultados.</p>
<dl class="simple myst">
<dt><strong>Media de todas las capas</strong></dt><dd><p>Obtenemos embeddings para cada token utilizando la media de todas las capas producidas por el transformador, incluida la capa de embeddings de palabras. Esta representación tiene la misma longitud que el tamaño oculto de cada capa transformadora. Este enfoque se inspira del “scalar mix” del estilo ELMO <span id="id23">[<a class="reference internal" href="bibliography.html#id24" title="Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In NAACL. 2018.">Peters <em>et al.</em>, 2018</a>]</span>.</p>
</dd>
</dl>
<p>Los resultados se encuentran en la <a class="reference internal" href="#feature-based-approach"><span class="std std-numref">tabla 3.3</span></a>.</p>
<figure class="align-center" id="feature-based-approach" style="width: 800px">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_0820c .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_0820c th.level1 {
  text-align: left;
}
#T_0820c th.level0 {
  text-align: center;
}
#T_0820c th.col_heading {
  text-align: center;
}
#T_0820c th.col_heading.level0 {
  font-size: 1.5em;
}
#T_0820c td {
  text-align: center;
  font-weight: bold;
}
#T_0820c_row0_col0 {
  background-color: #c23c81;
}
#T_0820c_row0_col1 {
  background-color: #e76e5b;
}
#T_0820c_row0_col2 {
  background-color: #bb3488;
}
#T_0820c_row1_col0, #T_0820c_row1_col1, #T_0820c_row1_col2 {
  background-color: #0d0887;
}
#T_0820c_row2_col0 {
  background-color: #ed7a52;
}
#T_0820c_row2_col1 {
  background-color: #f68d45;
}
#T_0820c_row2_col2 {
  background-color: #fca338;
}
#T_0820c_row3_col0, #T_0820c_row3_col1, #T_0820c_row3_col2 {
  background-color: #fcce25;
}
</style>
<table id="T_0820c">
  <thead>
    <tr>
      <th class="blank" >&nbsp;</th>
      <th class="index_name level0" >Track</th>
      <th id="T_0820c_level0_col0" class="col_heading level0 col0" >Subtrack 1</th>
      <th id="T_0820c_level0_col1" class="col_heading level0 col1" >Subtrack 2 [Strict]</th>
      <th id="T_0820c_level0_col2" class="col_heading level0 col2" >Subtrack 2 [Merged]</th>
    </tr>
    <tr>
      <th class="index_name level0" >Estrategia</th>
      <th class="index_name level1" >computation</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_0820c_level0_row0" class="row_heading level0 row0" rowspan="4">LSTM CRF</th>
      <th id="T_0820c_level1_row0" class="row_heading level1 row0" >BETO (Ultimas 4 capas)</th>
      <td id="T_0820c_row0_col0" class="data row0 col0" >97.25 ± 0.07</td>
      <td id="T_0820c_row0_col1" class="data row0 col1" >97.9 ± 0.02</td>
      <td id="T_0820c_row0_col2" class="data row0 col2" >98.47 ± 0.06</td>
    </tr>
    <tr>
      <th id="T_0820c_level1_row1" class="row_heading level1 row1" >+ Context</th>
      <td id="T_0820c_row1_col0" class="data row1 col0" >97.04 ± 0.08</td>
      <td id="T_0820c_row1_col1" class="data row1 col1" >97.6 ± 0.1</td>
      <td id="T_0820c_row1_col2" class="data row1 col2" >98.36 ± 0.13</td>
    </tr>
    <tr>
      <th id="T_0820c_level1_row2" class="row_heading level1 row2" >+ WE</th>
      <td id="T_0820c_row2_col0" class="data row2 col0" >97.35 ± 0.18</td>
      <td id="T_0820c_row2_col1" class="data row2 col1" >97.94 ± 0.17</td>
      <td id="T_0820c_row2_col2" class="data row2 col2" >98.56 ± 0.14</td>
    </tr>
    <tr>
      <th id="T_0820c_level1_row3" class="row_heading level1 row3" >+ WE + Context</th>
      <td id="T_0820c_row3_col0" class="data row3 col0" >97.46 ± 0.1</td>
      <td id="T_0820c_row3_col1" class="data row3 col1" >98.02 ± 0.11</td>
      <td id="T_0820c_row3_col2" class="data row3 col2" >98.59 ± 0.04</td>
    </tr>
  </tbody>
</table>
</div></div>
<figcaption>
<p><span class="caption-number">Fig. 3.3 </span><span class="caption-text">Evaluación de la estrategia basada en características. La evaluación se realiza contra el conjunto de desarrollo.</span><a class="headerlink" href="#feature-based-approach" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="flair-baseline">
<h3><span class="section-number">3.2.4. </span>Flair baseline<a class="headerlink" href="#flair-baseline" title="Permalink to this headline">#</a></h3>
<p>De la misma mañera usamos los embeddings contextuales de Flair <span id="id24">[<a class="reference internal" href="bibliography.html#id10" title="A. Akbik, Duncan A. J. Blythe, and Roland Vollgraf. Contextual string embeddings for sequence labeling. In COLING. 2018.">Akbik <em>et al.</em>, 2018</a>]</span> como entrada de la arquitectura LSTM-CRF <span id="id25">[<a class="reference internal" href="bibliography.html#id9" title="Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional lstm-crf models for sequence tagging. ArXiv, 2015.">Huang <em>et al.</em>, 2015</a>]</span>. En la <a class="reference internal" href="a_training.html#appendix-3"><span class="std std-numref">Section 5.2.2.2</span></a> del anexo se dan más detalles sobre los parámetros y la arquitectura. Esa arquitectura nos sirve de referencia con los resultados anteriores obtenidos con los datos jurídicos.</p>
<p>Los resultados se encuentran en la <a class="reference internal" href="#flair-approach"><span class="std std-numref">tabla 3.4</span></a>.</p>
<figure class="align-center" id="flair-approach" style="width: 800px">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_99765 .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_99765 th.level1 {
  text-align: left;
}
#T_99765 th.level0 {
  text-align: center;
}
#T_99765 th.col_heading {
  text-align: center;
}
#T_99765 th.col_heading.level0 {
  font-size: 1.5em;
}
#T_99765 td {
  text-align: center;
  font-weight: bold;
}
#T_99765_row0_col0, #T_99765_row0_col1, #T_99765_row0_col2 {
  background-color: #fcce25;
}
#T_99765_row1_col0, #T_99765_row1_col1, #T_99765_row1_col2 {
  background-color: #0d0887;
}
</style>
<table id="T_99765">
  <thead>
    <tr>
      <th class="blank" >&nbsp;</th>
      <th class="index_name level0" >Track</th>
      <th id="T_99765_level0_col0" class="col_heading level0 col0" >Subtrack 1</th>
      <th id="T_99765_level0_col1" class="col_heading level0 col1" >Subtrack 2 [Strict]</th>
      <th id="T_99765_level0_col2" class="col_heading level0 col2" >Subtrack 2 [Merged]</th>
    </tr>
    <tr>
      <th class="index_name level0" >Estrategia</th>
      <th class="index_name level1" >Embeddings</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_99765_level0_row0" class="row_heading level0 row0" rowspan="2">LSTM CRF</th>
      <th id="T_99765_level1_row0" class="row_heading level1 row0" >FLAIR</th>
      <td id="T_99765_row0_col0" class="data row0 col0" >97.32 ± 0.08</td>
      <td id="T_99765_row0_col1" class="data row0 col1" >97.93 ± 0.06</td>
      <td id="T_99765_row0_col2" class="data row0 col2" >98.53 ± 0.05</td>
    </tr>
    <tr>
      <th id="T_99765_level1_row1" class="row_heading level1 row1" >+ WE</th>
      <td id="T_99765_row1_col0" class="data row1 col0" >96.75 ± 0.07</td>
      <td id="T_99765_row1_col1" class="data row1 col1" >97.24 ± 0.1</td>
      <td id="T_99765_row1_col2" class="data row1 col2" >98.27 ± 0.06</td>
    </tr>
  </tbody>
</table>
</div></div>
<figcaption>
<p><span class="caption-number">Fig. 3.4 </span><span class="caption-text">Evaluación de la estrategia basada en características con los embeddings de Flair. La evaluación se realiza contra el conjunto de desarrollo.</span><a class="headerlink" href="#flair-approach" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="resultados-mejor-configuracion">
<h3><span class="section-number">3.2.5. </span>Resultados: Mejor configuración<a class="headerlink" href="#resultados-mejor-configuracion" title="Permalink to this headline">#</a></h3>
<p>Evaluamos ambos enfoques en cada variante en todas las combinaciones posibles añadiendo embeddings de palabras estándar “(+ WE)” y características a nivel de documento “(+ Contexto)”. Cada configuración se ejecuta tres veces para reportar el promedio de <span class="math notranslate nohighlight">\(F_{1} micro\)</span> y la desviación estándar para cada una de las 3 opciones: NER, Span y Span Merged.</p>
<dl class="simple myst">
<dt><strong>Results</strong></dt><dd><p>Para el ajuste fino, vemos que la adición de embeddings estáticos, así como el uso del contexto, no parecen mejorar los resultados tanto para BETO como para XLMR (véase <a class="reference internal" href="#finetuning-approach"><span class="std std-numref">tabla 3.2</span></a>). La configuración “WE + CONTEXT” parece dar los mejores resultados. Sin embargo, hay que señalar que, por falta de recursos, no hemos podido realizar el entrenamiento con la configuración “XLMR + WE + CONTEXT” que podía haber dado buenos resultados. Vemos que el uso de XLMR permite mejorar los resultados en comparación con BETO.
Para el enfoque basado en características, encontramos también que la configuración “WE + CONTEXT” produce muy claramente los mejores resultados (véase <a class="reference internal" href="#feature-based-approach"><span class="std std-numref">tabla 3.3</span></a>).
Para el modelo de referencia con “Flair + LSTM CRF” la adición de embeddings estáticos “(+ WE)” tiene un impacto negativo (véase <a class="reference internal" href="#flair-approach"><span class="std std-numref">tabla 3.4</span></a>).</p>
</dd>
</dl>
</section>
</section>
<section id="evaluacion-comparativa">
<span id="comparative-study"></span><h2><span class="section-number">3.3. </span>Evaluación comparativa<a class="headerlink" href="#evaluacion-comparativa" title="Permalink to this headline">#</a></h2>
<p>Con las configuraciones identificadas en <a class="reference internal" href="#experiments"><span class="std std-ref">Experimentos con parámetros de referencia</span></a> en los datos de desarrollo, realizamos una evaluación comparativa final en los datos de test, con y sin características de los documentos.</p>
<section id="principales-resultados">
<h3><span class="section-number">3.3.1. </span>Principales resultados<a class="headerlink" href="#principales-resultados" title="Permalink to this headline">#</a></h3>
<p>Los resultados de la evaluación se recogen en la <a class="reference internal" href="#table-test"><span class="std std-numref">Tabla 3.5</span></a>. Hacemos las siguientes observaciones:</p>
<figure class="align-default" id="table-test">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_b70fb .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_b70fb th.level1 {
  text-align: left;
}
#T_b70fb th.level0 {
  text-align: center;
}
#T_b70fb th.col_heading {
  text-align: center;
}
#T_b70fb th.col_heading.level0 {
  font-size: 1.5em;
}
#T_b70fb td {
  text-align: center;
  font-weight: bold;
}
#T_b70fb_row0_col0 {
  background-color: #b6308b;
}
#T_b70fb_row0_col1, #T_b70fb_row8_col1 {
  background-color: #cd4a76;
}
#T_b70fb_row0_col2 {
  background-color: #9613a1;
}
#T_b70fb_row1_col0 {
  background-color: #e76f5a;
}
#T_b70fb_row1_col1 {
  background-color: #f48849;
}
#T_b70fb_row1_col2 {
  background-color: #d14e72;
}
#T_b70fb_row2_col0 {
  background-color: #d9586a;
}
#T_b70fb_row2_col1 {
  background-color: #e66c5c;
}
#T_b70fb_row2_col2 {
  background-color: #e97158;
}
#T_b70fb_row3_col0 {
  background-color: #d35171;
}
#T_b70fb_row3_col1, #T_b70fb_row9_col0 {
  background-color: #e87059;
}
#T_b70fb_row3_col2 {
  background-color: #b32c8e;
}
#T_b70fb_row4_col0, #T_b70fb_row4_col1, #T_b70fb_row5_col2 {
  background-color: #fcce25;
}
#T_b70fb_row4_col2 {
  background-color: #fdc827;
}
#T_b70fb_row5_col0 {
  background-color: #fdab33;
}
#T_b70fb_row5_col1 {
  background-color: #fec029;
}
#T_b70fb_row6_col0 {
  background-color: #fba139;
}
#T_b70fb_row6_col1 {
  background-color: #f99a3e;
}
#T_b70fb_row6_col2 {
  background-color: #f3854b;
}
#T_b70fb_row7_col0 {
  background-color: #ba3388;
}
#T_b70fb_row7_col1 {
  background-color: #d8576b;
}
#T_b70fb_row7_col2 {
  background-color: #9a169f;
}
#T_b70fb_row8_col0 {
  background-color: #910ea3;
}
#T_b70fb_row8_col2, #T_b70fb_row12_col2 {
  background-color: #5c01a6;
}
#T_b70fb_row9_col1 {
  background-color: #ef7c51;
}
#T_b70fb_row9_col2 {
  background-color: #e97257;
}
#T_b70fb_row10_col0 {
  background-color: #fca338;
}
#T_b70fb_row10_col1 {
  background-color: #feb82c;
}
#T_b70fb_row10_col2 {
  background-color: #f9973f;
}
#T_b70fb_row11_col0 {
  background-color: #280592;
}
#T_b70fb_row11_col1 {
  background-color: #a51f99;
}
#T_b70fb_row11_col2, #T_b70fb_row12_col0, #T_b70fb_row12_col1 {
  background-color: #0d0887;
}
</style>
<table id="T_b70fb">
  <thead>
    <tr>
      <th class="blank" >&nbsp;</th>
      <th class="index_name level0" >Track</th>
      <th id="T_b70fb_level0_col0" class="col_heading level0 col0" >Subtrack 1</th>
      <th id="T_b70fb_level0_col1" class="col_heading level0 col1" >Subtrack 2 [Strict]</th>
      <th id="T_b70fb_level0_col2" class="col_heading level0 col2" >Subtrack 2 [Merged]</th>
    </tr>
    <tr>
      <th class="index_name level0" >Estrategia</th>
      <th class="index_name level1" >Embeddings</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_b70fb_level0_row0" class="row_heading level0 row0" rowspan="7">FINETUNE</th>
      <th id="T_b70fb_level1_row0" class="row_heading level1 row0" >BETO</th>
      <td id="T_b70fb_row0_col0" class="data row0 col0" >97.19 ± 0.05</td>
      <td id="T_b70fb_row0_col1" class="data row0 col1" >97.78 ± 0.07</td>
      <td id="T_b70fb_row0_col2" class="data row0 col2" >98.5 ± 0.15</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row1" class="row_heading level1 row1" >BETO + CONTEXT</th>
      <td id="T_b70fb_row1_col0" class="data row1 col0" >97.37 ± 0.16</td>
      <td id="T_b70fb_row1_col1" class="data row1 col1" >97.97 ± 0.15</td>
      <td id="T_b70fb_row1_col2" class="data row1 col2" >98.58 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row2" class="row_heading level1 row2" >BETO + WE</th>
      <td id="T_b70fb_row2_col0" class="data row2 col0" >97.31 ± 0.09</td>
      <td id="T_b70fb_row2_col1" class="data row2 col1" >97.89 ± 0.02</td>
      <td id="T_b70fb_row2_col2" class="data row2 col2" >98.63 ± 0.07</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row3" class="row_heading level1 row3" >BETO + WE + CONTEXT</th>
      <td id="T_b70fb_row3_col0" class="data row3 col0" >97.28 ± 0.12</td>
      <td id="T_b70fb_row3_col1" class="data row3 col1" >97.9 ± 0.03</td>
      <td id="T_b70fb_row3_col2" class="data row3 col2" >98.54 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row4" class="row_heading level1 row4" >XLMRL</th>
      <td id="T_b70fb_row4_col0" class="data row4 col0" >97.59 ± 0.13</td>
      <td id="T_b70fb_row4_col1" class="data row4 col1" >98.14 ± 0.09</td>
      <td id="T_b70fb_row4_col2" class="data row4 col2" >98.72 ± 0.08</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row5" class="row_heading level1 row5" >XLMRL + WE</th>
      <td id="T_b70fb_row5_col0" class="data row5 col0" >97.51 ± 0.14</td>
      <td id="T_b70fb_row5_col1" class="data row5 col1" >98.11 ± 0.14</td>
      <td id="T_b70fb_row5_col2" class="data row5 col2" >98.73 ± 0.09</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row6" class="row_heading level1 row6" >XLMRL + CONTEXT</th>
      <td id="T_b70fb_row6_col0" class="data row6 col0" >97.49 ± 0.07</td>
      <td id="T_b70fb_row6_col1" class="data row6 col1" >98.01 ± 0.07</td>
      <td id="T_b70fb_row6_col2" class="data row6 col2" >98.65 ± 0.05</td>
    </tr>
    <tr>
      <th id="T_b70fb_level0_row7" class="row_heading level0 row7" rowspan="6">LSTM CRF</th>
      <th id="T_b70fb_level1_row7" class="row_heading level1 row7" >BETO</th>
      <td id="T_b70fb_row7_col0" class="data row7 col0" >97.2 ± 0.05</td>
      <td id="T_b70fb_row7_col1" class="data row7 col1" >97.82 ± 0.07</td>
      <td id="T_b70fb_row7_col2" class="data row7 col2" >98.5 ± 0.05</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row8" class="row_heading level1 row8" >BETO + CONTEXT</th>
      <td id="T_b70fb_row8_col0" class="data row8 col0" >97.09 ± 0.09</td>
      <td id="T_b70fb_row8_col1" class="data row8 col1" >97.78 ± 0.06</td>
      <td id="T_b70fb_row8_col2" class="data row8 col2" >98.44 ± 0.1</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row9" class="row_heading level1 row9" >BETO + WE</th>
      <td id="T_b70fb_row9_col0" class="data row9 col0" >97.37 ± 0.07</td>
      <td id="T_b70fb_row9_col1" class="data row9 col1" >97.94 ± 0.04</td>
      <td id="T_b70fb_row9_col2" class="data row9 col2" >98.63 ± 0.06</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row10" class="row_heading level1 row10" >BETO + WE + CONTEXT</th>
      <td id="T_b70fb_row10_col0" class="data row10 col0" >97.5 ± 0.06</td>
      <td id="T_b70fb_row10_col1" class="data row10 col1" >98.09 ± 0.08</td>
      <td id="T_b70fb_row10_col2" class="data row10 col2" >98.67 ± 0.09</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row11" class="row_heading level1 row11" >FLAIR</th>
      <td id="T_b70fb_row11_col0" class="data row11 col0" >96.88 ± 0.13</td>
      <td id="T_b70fb_row11_col1" class="data row11 col1" >97.64 ± 0.16</td>
      <td id="T_b70fb_row11_col2" class="data row11 col2" >98.37 ± 0.12</td>
    </tr>
    <tr>
      <th id="T_b70fb_level1_row12" class="row_heading level1 row12" >FLAIR + WE</th>
      <td id="T_b70fb_row12_col0" class="data row12 col0" >96.84 ± 0.13</td>
      <td id="T_b70fb_row12_col1" class="data row12 col1" >97.31 ± 0.11</td>
      <td id="T_b70fb_row12_col2" class="data row12 col2" >98.44 ± 0.08</td>
    </tr>
  </tbody>
</table>
</div></div>
<figcaption>
<p><span class="caption-number">Fig. 3.5 </span><span class="caption-text">Evaluación comparativa de las mejores configuraciones de los enfoques de ajuste fino y basados en características en los datos de test.</span><a class="headerlink" href="#table-test" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>El uso de Transformers sobre el dataset Meddocan nos permite una ganancia en todas las configuraciones en comparación con el uso de Flair (véase la <a class="reference internal" href="#flair-comparison"><span class="std std-numref">Tabla 3.6</span></a>). El mejor modelo se obtiene con la configuración “FINETUNE + XMLR”.</p>
<div class="tip admonition">
<p class="admonition-title">Note</p>
<p>Con los resultados obtenidos, Flert habría ganado la competición <span id="id26">[<a class="reference internal" href="bibliography.html#id2" title="Montserrat Marimon, Aitor Gonzalez-Agirre, Ander Intxaurrondo, Heidy Rodriguez, Jose Lopez Martin, Marta Villegas, and Martin Krallinger. Automatic de-identification of medical texts in spanish: the meddocan track, corpus, guidelines, methods and evaluation of results. In IberLEF&#64;SEPLN. 2019.">Marimon <em>et al.</em>, 2019</a>]</span> por delante del actual ganador Lukas Lange <span id="id27">[<a class="reference internal" href="bibliography.html#id3" title="Lukas Lange, Heike Adel, and Jannik Strötgen. Nlnde: the neither-language-nor-domain-experts' way of spanish medical document de-identification. In IberLEF&#64;SEPLN. 2019.">Lange <em>et al.</em>, 2019</a>]</span> (véase <a class="reference internal" href="#lukas-lange"><span class="std std-numref">Tabla 3.1</span></a>) que uso la libraría FLair también.</p>
<table class="colwidths-auto table" id="lukas-lange">
<caption><span class="caption-number">Table 3.1 </span><span class="caption-text">Mejor score <span class="math notranslate nohighlight">\(F_{1} micro\)</span> sobres cada una de las 3 Subtracks obtenidos por Luckas Lange.</span><a class="headerlink" href="#lukas-lange" title="Permalink to this table">#</a></caption>
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Subtrack1</p></th>
<th class="text-align:left head"><p>Subtrack2 [Strict]</p></th>
<th class="text-align:left head"><p>Subtrack2 [Merged]</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>96.96</p></td>
<td class="text-align:left"><p>97.49</p></td>
<td class="text-align:left"><p>98.53</p></td>
</tr>
</tbody>
</table>
</div>
<p>En cuanto a los enfoques de “FINETUNE + LINEAR” y basado en “FEATURE BASED + LSTM CRF”, los resultados son bastante similares, aunque el segundo enfoque se ve afectado negativamente por el contexto y el primero positivamente.
Por otro lado, la estrategia “FEATURE BASED + LSTM CRF + CONTEXTO + WE” es la más beneficiada con la mejor puntuación <span class="math notranslate nohighlight">\(F_{1} micro\)</span> en las 3 tareas si usamos BETO. Como no hemos usado la estrategia “FEATURE BASED + LSTM CRF” para XLMR nos podemos concluir.
Al contrario de los resultados obtenidos por los autores de Flert <span id="id28">[<a class="reference internal" href="bibliography.html#id6" title="Stefan Schweter and A. Akbik. Flert: document-level features for named entity recognition. ArXiv, 2020.">Schweter and Akbik, 2020</a>]</span> los resultados no son tan claros entre cada opción como en el caso del dataset CONLL03 <span id="id29">[<a class="reference internal" href="bibliography.html#id29" title="Erik Tjong Kim Sang and Fien De Meulder. Introduction to the conll-2003 shared task: language-independent named entity recognition. In CoNLL. 2003.">Sang and Meulder, 2003</a>]</span>.</p>
<figure class="align-default" id="flair-comparison">
<div class="cell_output docutils container">
<div class="output text_html"><style type="text/css">
#T_2e9d3 .index_name {
  font-style: italic;
  color: darkgrey;
  font-weight: normal;
}
#T_2e9d3 th.level1 {
  text-align: left;
}
#T_2e9d3 th.level0 {
  text-align: center;
}
#T_2e9d3 th.col_heading {
  text-align: center;
}
#T_2e9d3 th.col_heading.level0 {
  font-size: 1.5em;
}
#T_2e9d3 td {
  text-align: center;
  font-weight: bold;
}
#T_2e9d3_row0_col0 {
  background-color: #6700a8;
  color: #f1f1f1;
}
#T_2e9d3_row0_col1, #T_2e9d3_row8_col0, #T_2e9d3_row8_col1, #T_2e9d3_row8_col2 {
  background-color: #0d0887;
  color: #f1f1f1;
}
#T_2e9d3_row0_col2 {
  background-color: #6c00a8;
  color: #f1f1f1;
}
#T_2e9d3_row1_col0 {
  background-color: #d8576b;
  color: #f1f1f1;
}
#T_2e9d3_row1_col1 {
  background-color: #d04d73;
  color: #f1f1f1;
}
#T_2e9d3_row1_col2 {
  background-color: #c9447a;
  color: #f1f1f1;
}
#T_2e9d3_row2_col0 {
  background-color: #ba3388;
  color: #f1f1f1;
}
#T_2e9d3_row2_col1 {
  background-color: #910ea3;
  color: #f1f1f1;
}
#T_2e9d3_row2_col2, #T_2e9d3_row6_col1 {
  background-color: #ea7457;
  color: #f1f1f1;
}
#T_2e9d3_row3_col0 {
  background-color: #ac2694;
  color: #f1f1f1;
}
#T_2e9d3_row3_col1, #T_2e9d3_row3_col2 {
  background-color: #9a169f;
  color: #f1f1f1;
}
#T_2e9d3_row4_col0, #T_2e9d3_row4_col1, #T_2e9d3_row5_col2 {
  background-color: #f0f921;
  color: #000000;
}
#T_2e9d3_row4_col2 {
  background-color: #f3f027;
  color: #000000;
}
#T_2e9d3_row5_col0 {
  background-color: #feba2c;
  color: #000000;
}
#T_2e9d3_row5_col1 {
  background-color: #fcd225;
  color: #000000;
}
#T_2e9d3_row6_col0, #T_2e9d3_row10_col2 {
  background-color: #fca934;
  color: #000000;
}
#T_2e9d3_row6_col2 {
  background-color: #f79044;
  color: #f1f1f1;
}
#T_2e9d3_row7_col0 {
  background-color: #7100a8;
  color: #f1f1f1;
}
#T_2e9d3_row7_col1 {
  background-color: #4903a0;
  color: #f1f1f1;
}
#T_2e9d3_row7_col2 {
  background-color: #7201a8;
  color: #f1f1f1;
}
#T_2e9d3_row9_col0 {
  background-color: #da5a6a;
  color: #f1f1f1;
}
#T_2e9d3_row9_col1 {
  background-color: #bb3488;
  color: #f1f1f1;
}
#T_2e9d3_row9_col2 {
  background-color: #eb7556;
  color: #f1f1f1;
}
#T_2e9d3_row10_col0 {
  background-color: #fdac33;
  color: #000000;
}
#T_2e9d3_row10_col1 {
  background-color: #febe2a;
  color: #000000;
}
</style>
<table id="T_2e9d3">
  <thead>
    <tr>
      <th class="blank" >&nbsp;</th>
      <th class="index_name level0" >Track</th>
      <th id="T_2e9d3_level0_col0" class="col_heading level0 col0" >Subtrack 1</th>
      <th id="T_2e9d3_level0_col1" class="col_heading level0 col1" >Subtrack 2 [Strict]</th>
      <th id="T_2e9d3_level0_col2" class="col_heading level0 col2" >Subtrack 2 [Merged]</th>
    </tr>
    <tr>
      <th class="index_name level0" >Estrategia</th>
      <th class="index_name level1" >Embeddings</th>
      <th class="blank col0" >&nbsp;</th>
      <th class="blank col1" >&nbsp;</th>
      <th class="blank col2" >&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_2e9d3_level0_row0" class="row_heading level0 row0" rowspan="7">FINETUNE</th>
      <th id="T_2e9d3_level1_row0" class="row_heading level1 row0" >BETO</th>
      <td id="T_2e9d3_row0_col0" class="data row0 col0" >0.31</td>
      <td id="T_2e9d3_row0_col1" class="data row0 col1" >0.14</td>
      <td id="T_2e9d3_row0_col2" class="data row0 col2" >0.13</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row1" class="row_heading level1 row1" >BETO + CONTEXT</th>
      <td id="T_2e9d3_row1_col0" class="data row1 col0" >0.49</td>
      <td id="T_2e9d3_row1_col1" class="data row1 col1" >0.32</td>
      <td id="T_2e9d3_row1_col2" class="data row1 col2" >0.21</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row2" class="row_heading level1 row2" >BETO + WE</th>
      <td id="T_2e9d3_row2_col0" class="data row2 col0" >0.43</td>
      <td id="T_2e9d3_row2_col1" class="data row2 col1" >0.24</td>
      <td id="T_2e9d3_row2_col2" class="data row2 col2" >0.26</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row3" class="row_heading level1 row3" >BETO + WE + CONTEXT</th>
      <td id="T_2e9d3_row3_col0" class="data row3 col0" >0.40</td>
      <td id="T_2e9d3_row3_col1" class="data row3 col1" >0.25</td>
      <td id="T_2e9d3_row3_col2" class="data row3 col2" >0.16</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row4" class="row_heading level1 row4" >XLMRL</th>
      <td id="T_2e9d3_row4_col0" class="data row4 col0" >0.71</td>
      <td id="T_2e9d3_row4_col1" class="data row4 col1" >0.50</td>
      <td id="T_2e9d3_row4_col2" class="data row4 col2" >0.35</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row5" class="row_heading level1 row5" >XLMRL + WE</th>
      <td id="T_2e9d3_row5_col0" class="data row5 col0" >0.64</td>
      <td id="T_2e9d3_row5_col1" class="data row5 col1" >0.46</td>
      <td id="T_2e9d3_row5_col2" class="data row5 col2" >0.36</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row6" class="row_heading level1 row6" >XLMRL + CONTEXT</th>
      <td id="T_2e9d3_row6_col0" class="data row6 col0" >0.61</td>
      <td id="T_2e9d3_row6_col1" class="data row6 col1" >0.37</td>
      <td id="T_2e9d3_row6_col2" class="data row6 col2" >0.28</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level0_row7" class="row_heading level0 row7" rowspan="4">LSTM CRF</th>
      <th id="T_2e9d3_level1_row7" class="row_heading level1 row7" >BETO</th>
      <td id="T_2e9d3_row7_col0" class="data row7 col0" >0.32</td>
      <td id="T_2e9d3_row7_col1" class="data row7 col1" >0.18</td>
      <td id="T_2e9d3_row7_col2" class="data row7 col2" >0.13</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row8" class="row_heading level1 row8" >BETO + CONTEXT</th>
      <td id="T_2e9d3_row8_col0" class="data row8 col0" >0.21</td>
      <td id="T_2e9d3_row8_col1" class="data row8 col1" >0.14</td>
      <td id="T_2e9d3_row8_col2" class="data row8 col2" >0.07</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row9" class="row_heading level1 row9" >BETO + WE</th>
      <td id="T_2e9d3_row9_col0" class="data row9 col0" >0.49</td>
      <td id="T_2e9d3_row9_col1" class="data row9 col1" >0.29</td>
      <td id="T_2e9d3_row9_col2" class="data row9 col2" >0.26</td>
    </tr>
    <tr>
      <th id="T_2e9d3_level1_row10" class="row_heading level1 row10" >BETO + WE + CONTEXT</th>
      <td id="T_2e9d3_row10_col0" class="data row10 col0" >0.62</td>
      <td id="T_2e9d3_row10_col1" class="data row10 col1" >0.45</td>
      <td id="T_2e9d3_row10_col2" class="data row10 col2" >0.30</td>
    </tr>
  </tbody>
</table>
</div></div>
<figcaption>
<p><span class="caption-number">Fig. 3.6 </span><span class="caption-text">Evaluación de las mejoras en score <span class="math notranslate nohighlight">\(F_{1} micro\)</span> en los datos de test en comparación con la opción FLAIR + WE + LSTM CRF.</span><a class="headerlink" href="#flair-comparison" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="conclusion">
<h2><span class="section-number">3.4. </span>Conclusión<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<p>El sistema basado en Transfer Learning y el uso de Transformadores (BERT / XLMR-Large) nos ha permitido obtener muy buenos resultados sobre el conjunto de datos MEDDOCAN, nos ha mostrado un score <span class="math notranslate nohighlight">\(F_{1} micro\)</span> superior en comparación con el uso de las tecnologías precedentes como los embeddings contextuales de Flair. No obstante esa mejora conlleva un tiempo de entrenamiento más largo (véase la <a class="reference internal" href="a_training.html#model-parameters"><span class="std std-numref">Tabla 5.6</span></a>) así que modelos con más parámetros y entonces más voluminosos (véase la <a class="reference internal" href="a_training.html#id11"><span class="std std-numref">Tabla 5.7</span></a>) .</p>
<p>La anonimización de un documento en bruto utilizando uno de nuestros modelos se trata en la <a class="reference internal" href="a_code.html#meddocan-pipeline"><span class="std std-numref">Section 5.3.1</span></a> del apéndice.</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id12">1</a></span></dt>
<dd><p><a class="reference external" href="https://github.com/PlanTL-GOB-ES/SPACCC_MEDDOCAN/tree/master/corpus">https://github.com/PlanTL-GOB-ES/SPACCC_MEDDOCAN/tree/master/corpus</a></p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./meddocan"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="02_data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2. </span>Clinical Corpus</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bibliography.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Referencias</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Guillaume Gelabert<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>